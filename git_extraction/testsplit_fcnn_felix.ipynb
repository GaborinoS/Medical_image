{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the CSV file into a DataFrame.\n",
    "2. Parse the \"Radiomics\" column, as it contains JSON data.\n",
    "3. Remove columns with the same values across all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(309, 103)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# create random seed for reproducibility\n",
    "ran_seed = 42\n",
    "\n",
    "# Load the data from DF_Radiomics_noduls_with_diagnose.csv\n",
    "file_path = \"DF_Radiomics_noduls_with_diagnose.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Convert the 'Labels' column to an integer\n",
    "data['Labels'] = data['Labels'].astype(int)\n",
    "\n",
    "# drop all rows where the label == 0\n",
    "data = data[data.Labels != 0]\n",
    "\n",
    "# Parse the JSON in the 'Radiomics' column\n",
    "data['Radiomics'] = data['Radiomics'].apply(json.loads)\n",
    "\n",
    "# Convert the 'Radiomics' column into separate columns\n",
    "radiomics_data = pd.json_normalize(data['Radiomics'])\n",
    "\n",
    "\n",
    "# Drop the original 'Radiomics' column\n",
    "data = data.drop('Radiomics', axis=1)\n",
    "\n",
    "\n",
    "# Reset the indices of both DataFrames\n",
    "data = data.reset_index(drop=True)\n",
    "radiomics_data = radiomics_data.reset_index(drop=True)\n",
    "\n",
    "# Combine the data with the new radiomics columns\n",
    "data = pd.concat([data, radiomics_data], axis=1)\n",
    "\n",
    "# Remove columns with the same value across all rows\n",
    "data = data.loc[:, (data != data.iloc[0]).any()]\n",
    "\n",
    "#remove columns with all NaN values\n",
    "data = data.dropna(axis=1, how='all')\n",
    "\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Node</th>\n",
       "      <th>Labels</th>\n",
       "      <th>diagnostics_Image-original_Hash</th>\n",
       "      <th>diagnostics_Image-original_Spacing</th>\n",
       "      <th>diagnostics_Image-original_Size</th>\n",
       "      <th>diagnostics_Image-original_Mean</th>\n",
       "      <th>diagnostics_Image-original_Minimum</th>\n",
       "      <th>diagnostics_Image-original_Maximum</th>\n",
       "      <th>diagnostics_Mask-original_Hash</th>\n",
       "      <th>...</th>\n",
       "      <th>original_gldm_GrayLevelNonUniformity</th>\n",
       "      <th>original_gldm_GrayLevelVariance</th>\n",
       "      <th>original_gldm_HighGrayLevelEmphasis</th>\n",
       "      <th>original_gldm_LargeDependenceEmphasis</th>\n",
       "      <th>original_gldm_LargeDependenceHighGrayLevelEmphasis</th>\n",
       "      <th>original_gldm_LargeDependenceLowGrayLevelEmphasis</th>\n",
       "      <th>original_gldm_LowGrayLevelEmphasis</th>\n",
       "      <th>original_gldm_SmallDependenceEmphasis</th>\n",
       "      <th>original_gldm_SmallDependenceHighGrayLevelEmphasis</th>\n",
       "      <th>original_gldm_SmallDependenceLowGrayLevelEmphasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIDC-IDRI-0068</td>\n",
       "      <td>Node_N1</td>\n",
       "      <td>3</td>\n",
       "      <td>bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28</td>\n",
       "      <td>[0.683594, 0.683594, 1.25]</td>\n",
       "      <td>[512, 512, 261]</td>\n",
       "      <td>-1026.065264</td>\n",
       "      <td>-3024.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>0506d1d0d6522eddd1640c8ea75c2fc5a9266270</td>\n",
       "      <td>...</td>\n",
       "      <td>7.355556</td>\n",
       "      <td>60.706173</td>\n",
       "      <td>469.644444</td>\n",
       "      <td>23.444444</td>\n",
       "      <td>16578.377778</td>\n",
       "      <td>0.053875</td>\n",
       "      <td>0.021012</td>\n",
       "      <td>0.488461</td>\n",
       "      <td>152.929922</td>\n",
       "      <td>0.019809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIDC-IDRI-0068</td>\n",
       "      <td>Node_N1</td>\n",
       "      <td>3</td>\n",
       "      <td>bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28</td>\n",
       "      <td>[0.683594, 0.683594, 1.25]</td>\n",
       "      <td>[512, 512, 261]</td>\n",
       "      <td>-1026.065264</td>\n",
       "      <td>-3024.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>9d7da356d43e2f7ad7f374f6c193e97f6088d7c7</td>\n",
       "      <td>...</td>\n",
       "      <td>7.467153</td>\n",
       "      <td>72.801002</td>\n",
       "      <td>471.051095</td>\n",
       "      <td>17.496350</td>\n",
       "      <td>13573.328467</td>\n",
       "      <td>0.110650</td>\n",
       "      <td>0.024328</td>\n",
       "      <td>0.494688</td>\n",
       "      <td>165.356306</td>\n",
       "      <td>0.010062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIDC-IDRI-0068</td>\n",
       "      <td>Node_N1</td>\n",
       "      <td>3</td>\n",
       "      <td>bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28</td>\n",
       "      <td>[0.683594, 0.683594, 1.25]</td>\n",
       "      <td>[512, 512, 261]</td>\n",
       "      <td>-1026.065264</td>\n",
       "      <td>-3024.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>c0a43747a23d26b107e21614525f2fd8870ffefc</td>\n",
       "      <td>...</td>\n",
       "      <td>7.685185</td>\n",
       "      <td>43.527006</td>\n",
       "      <td>277.787037</td>\n",
       "      <td>20.370370</td>\n",
       "      <td>9310.490741</td>\n",
       "      <td>0.084481</td>\n",
       "      <td>0.031811</td>\n",
       "      <td>0.463956</td>\n",
       "      <td>84.174037</td>\n",
       "      <td>0.027819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LIDC-IDRI-0068</td>\n",
       "      <td>Node_N1</td>\n",
       "      <td>3</td>\n",
       "      <td>bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28</td>\n",
       "      <td>[0.683594, 0.683594, 1.25]</td>\n",
       "      <td>[512, 512, 261]</td>\n",
       "      <td>-1026.065264</td>\n",
       "      <td>-3024.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>72a09dc3f5d5d146b13402b8ef109422cc3f38a5</td>\n",
       "      <td>...</td>\n",
       "      <td>6.780220</td>\n",
       "      <td>35.367709</td>\n",
       "      <td>229.219780</td>\n",
       "      <td>18.780220</td>\n",
       "      <td>7065.923077</td>\n",
       "      <td>0.084783</td>\n",
       "      <td>0.026368</td>\n",
       "      <td>0.465301</td>\n",
       "      <td>67.725183</td>\n",
       "      <td>0.021973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIDC-IDRI-0072</td>\n",
       "      <td>Node_N1</td>\n",
       "      <td>1</td>\n",
       "      <td>54705f26f9320581c90452445aa820fe9630d5e9</td>\n",
       "      <td>[0.732422, 0.732422, 1.25]</td>\n",
       "      <td>[512, 512, 305]</td>\n",
       "      <td>-871.936330</td>\n",
       "      <td>-3024.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>05efcefff38c73903c3d7839bb987a49176f6068</td>\n",
       "      <td>...</td>\n",
       "      <td>629.334146</td>\n",
       "      <td>45.147393</td>\n",
       "      <td>1253.131545</td>\n",
       "      <td>28.918031</td>\n",
       "      <td>43475.541623</td>\n",
       "      <td>0.020967</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.262518</td>\n",
       "      <td>254.476429</td>\n",
       "      <td>0.000632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Patient     Node  Labels           diagnostics_Image-original_Hash  \\\n",
       "0  LIDC-IDRI-0068  Node_N1       3  bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28   \n",
       "1  LIDC-IDRI-0068  Node_N1       3  bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28   \n",
       "2  LIDC-IDRI-0068  Node_N1       3  bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28   \n",
       "3  LIDC-IDRI-0068  Node_N1       3  bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28   \n",
       "4  LIDC-IDRI-0072  Node_N1       1  54705f26f9320581c90452445aa820fe9630d5e9   \n",
       "\n",
       "  diagnostics_Image-original_Spacing diagnostics_Image-original_Size  \\\n",
       "0         [0.683594, 0.683594, 1.25]                 [512, 512, 261]   \n",
       "1         [0.683594, 0.683594, 1.25]                 [512, 512, 261]   \n",
       "2         [0.683594, 0.683594, 1.25]                 [512, 512, 261]   \n",
       "3         [0.683594, 0.683594, 1.25]                 [512, 512, 261]   \n",
       "4         [0.732422, 0.732422, 1.25]                 [512, 512, 305]   \n",
       "\n",
       "   diagnostics_Image-original_Mean  diagnostics_Image-original_Minimum  \\\n",
       "0                     -1026.065264                             -3024.0   \n",
       "1                     -1026.065264                             -3024.0   \n",
       "2                     -1026.065264                             -3024.0   \n",
       "3                     -1026.065264                             -3024.0   \n",
       "4                      -871.936330                             -3024.0   \n",
       "\n",
       "   diagnostics_Image-original_Maximum  \\\n",
       "0                              3071.0   \n",
       "1                              3071.0   \n",
       "2                              3071.0   \n",
       "3                              3071.0   \n",
       "4                              3071.0   \n",
       "\n",
       "             diagnostics_Mask-original_Hash  ...  \\\n",
       "0  0506d1d0d6522eddd1640c8ea75c2fc5a9266270  ...   \n",
       "1  9d7da356d43e2f7ad7f374f6c193e97f6088d7c7  ...   \n",
       "2  c0a43747a23d26b107e21614525f2fd8870ffefc  ...   \n",
       "3  72a09dc3f5d5d146b13402b8ef109422cc3f38a5  ...   \n",
       "4  05efcefff38c73903c3d7839bb987a49176f6068  ...   \n",
       "\n",
       "  original_gldm_GrayLevelNonUniformity original_gldm_GrayLevelVariance  \\\n",
       "0                             7.355556                       60.706173   \n",
       "1                             7.467153                       72.801002   \n",
       "2                             7.685185                       43.527006   \n",
       "3                             6.780220                       35.367709   \n",
       "4                           629.334146                       45.147393   \n",
       "\n",
       "  original_gldm_HighGrayLevelEmphasis  original_gldm_LargeDependenceEmphasis  \\\n",
       "0                          469.644444                              23.444444   \n",
       "1                          471.051095                              17.496350   \n",
       "2                          277.787037                              20.370370   \n",
       "3                          229.219780                              18.780220   \n",
       "4                         1253.131545                              28.918031   \n",
       "\n",
       "   original_gldm_LargeDependenceHighGrayLevelEmphasis  \\\n",
       "0                                       16578.377778    \n",
       "1                                       13573.328467    \n",
       "2                                        9310.490741    \n",
       "3                                        7065.923077    \n",
       "4                                       43475.541623    \n",
       "\n",
       "  original_gldm_LargeDependenceLowGrayLevelEmphasis  \\\n",
       "0                                          0.053875   \n",
       "1                                          0.110650   \n",
       "2                                          0.084481   \n",
       "3                                          0.084783   \n",
       "4                                          0.020967   \n",
       "\n",
       "  original_gldm_LowGrayLevelEmphasis  original_gldm_SmallDependenceEmphasis  \\\n",
       "0                           0.021012                               0.488461   \n",
       "1                           0.024328                               0.494688   \n",
       "2                           0.031811                               0.463956   \n",
       "3                           0.026368                               0.465301   \n",
       "4                           0.001319                               0.262518   \n",
       "\n",
       "   original_gldm_SmallDependenceHighGrayLevelEmphasis  \\\n",
       "0                                         152.929922    \n",
       "1                                         165.356306    \n",
       "2                                          84.174037    \n",
       "3                                          67.725183    \n",
       "4                                         254.476429    \n",
       "\n",
       "   original_gldm_SmallDependenceLowGrayLevelEmphasis  \n",
       "0                                           0.019809  \n",
       "1                                           0.010062  \n",
       "2                                           0.027819  \n",
       "3                                           0.021973  \n",
       "4                                           0.000632  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove hash columns\n",
    "data = data.drop(['diagnostics_Image-original_Hash', 'diagnostics_Mask-original_Hash'], axis=1)\n",
    "\n",
    "# ok looks like all the objeckt columns except of \"Patient\" & \"Node\" are in this form [0.683594, 0.683594, 1.25] which is a list of multiple floats\n",
    "# exploade them into multiple columns\n",
    "\n",
    "object_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove 'Patient' and 'Node' from the list\n",
    "object_columns.remove('Patient')\n",
    "object_columns.remove('Node')\n",
    "\n",
    "# Explode the lists in each object column into multiple columns\n",
    "for column in object_columns:\n",
    "    # Convert each list to a Series and expand it into multiple columns\n",
    "    expanded_columns = data[column].apply(pd.Series)\n",
    "    \n",
    "    # Rename the expanded columns to have the original column name as a prefix\n",
    "    expanded_columns = expanded_columns.rename(columns=lambda x: f\"{column}_{x}\")\n",
    "    \n",
    "    # Drop the original column from the DataFrame\n",
    "    data = data.drop(column, axis=1)\n",
    "    \n",
    "    # Concatenate the expanded columns to the DataFrame\n",
    "    data = pd.concat([data, expanded_columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already exist, skipping this step\n"
     ]
    }
   ],
   "source": [
    "# Create a stratified split\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['Labels'], random_state=ran_seed)\n",
    "\n",
    "# if the files already exist, skip this step\n",
    "if os.path.isfile('DF_Radiomics_noduls_with_diagnose_train_data.csv') and os.path.isfile('DF_Radiomics_noduls_with_diagnose_test_data.csv'):\n",
    "    print(\"Files already exist, skipping this step\")\n",
    "else:\n",
    "    # Save the data to CSV files\n",
    "    train_data.to_csv('DF_Radiomics_noduls_with_diagnose_train_data.csv', index=False)\n",
    "    test_data.to_csv('DF_Radiomics_noduls_with_diagnose_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (247, 118)\n",
      "Test data: (62, 118)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data:\", train_data.shape)\n",
    "print(\"Test data:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Node</th>\n",
       "      <th>Labels</th>\n",
       "      <th>diagnostics_Image-original_Mean</th>\n",
       "      <th>diagnostics_Image-original_Minimum</th>\n",
       "      <th>diagnostics_Image-original_Maximum</th>\n",
       "      <th>diagnostics_Mask-original_VoxelNum</th>\n",
       "      <th>diagnostics_Mask-original_VolumeNum</th>\n",
       "      <th>original_firstorder_10Percentile</th>\n",
       "      <th>original_firstorder_90Percentile</th>\n",
       "      <th>...</th>\n",
       "      <th>diagnostics_Mask-original_BoundingBox_2</th>\n",
       "      <th>diagnostics_Mask-original_BoundingBox_3</th>\n",
       "      <th>diagnostics_Mask-original_BoundingBox_4</th>\n",
       "      <th>diagnostics_Mask-original_BoundingBox_5</th>\n",
       "      <th>diagnostics_Mask-original_CenterOfMassIndex_0</th>\n",
       "      <th>diagnostics_Mask-original_CenterOfMassIndex_1</th>\n",
       "      <th>diagnostics_Mask-original_CenterOfMassIndex_2</th>\n",
       "      <th>diagnostics_Mask-original_CenterOfMass_0</th>\n",
       "      <th>diagnostics_Mask-original_CenterOfMass_1</th>\n",
       "      <th>diagnostics_Mask-original_CenterOfMass_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LIDC-IDRI-0137</td>\n",
       "      <td>Node_N1</td>\n",
       "      <td>3</td>\n",
       "      <td>-671.885608</td>\n",
       "      <td>-2048.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>175.5</td>\n",
       "      <td>850.5</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>332.692308</td>\n",
       "      <td>389.538462</td>\n",
       "      <td>30.307692</td>\n",
       "      <td>53.215868</td>\n",
       "      <td>83.626926</td>\n",
       "      <td>-321.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>LIDC-IDRI-0377</td>\n",
       "      <td>Node_N1</td>\n",
       "      <td>2</td>\n",
       "      <td>-882.321409</td>\n",
       "      <td>-3024.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>2402</td>\n",
       "      <td>1</td>\n",
       "      <td>-307.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>169</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>382.402998</td>\n",
       "      <td>308.854288</td>\n",
       "      <td>173.039550</td>\n",
       "      <td>92.739302</td>\n",
       "      <td>28.898399</td>\n",
       "      <td>-68.460564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LIDC-IDRI-0167</td>\n",
       "      <td>Node_N1</td>\n",
       "      <td>1</td>\n",
       "      <td>-664.766231</td>\n",
       "      <td>-2048.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>-444.5</td>\n",
       "      <td>-66.5</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>70.267857</td>\n",
       "      <td>174.964286</td>\n",
       "      <td>50.321429</td>\n",
       "      <td>-136.237780</td>\n",
       "      <td>-53.812866</td>\n",
       "      <td>-234.696429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>LIDC-IDRI-0272</td>\n",
       "      <td>Node_N1</td>\n",
       "      <td>3</td>\n",
       "      <td>-824.358062</td>\n",
       "      <td>-2048.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>-447.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>209.313725</td>\n",
       "      <td>390.941176</td>\n",
       "      <td>81.568627</td>\n",
       "      <td>-47.673652</td>\n",
       "      <td>80.722794</td>\n",
       "      <td>-109.078431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>LIDC-IDRI-0234</td>\n",
       "      <td>Node_N1</td>\n",
       "      <td>1</td>\n",
       "      <td>-708.012378</td>\n",
       "      <td>-2048.0</td>\n",
       "      <td>3029.0</td>\n",
       "      <td>251</td>\n",
       "      <td>1</td>\n",
       "      <td>-569.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>367.756972</td>\n",
       "      <td>310.848606</td>\n",
       "      <td>41.689243</td>\n",
       "      <td>65.179121</td>\n",
       "      <td>43.765426</td>\n",
       "      <td>-236.276892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Patient     Node  Labels  diagnostics_Image-original_Mean  \\\n",
       "23   LIDC-IDRI-0137  Node_N1       3                      -671.885608   \n",
       "263  LIDC-IDRI-0377  Node_N1       2                      -882.321409   \n",
       "44   LIDC-IDRI-0167  Node_N1       1                      -664.766231   \n",
       "219  LIDC-IDRI-0272  Node_N1       3                      -824.358062   \n",
       "143  LIDC-IDRI-0234  Node_N1       1                      -708.012378   \n",
       "\n",
       "     diagnostics_Image-original_Minimum  diagnostics_Image-original_Maximum  \\\n",
       "23                              -2048.0                              3071.0   \n",
       "263                             -3024.0                              3071.0   \n",
       "44                              -2048.0                              3071.0   \n",
       "219                             -2048.0                              3071.0   \n",
       "143                             -2048.0                              3029.0   \n",
       "\n",
       "     diagnostics_Mask-original_VoxelNum  diagnostics_Mask-original_VolumeNum  \\\n",
       "23                                   26                                    1   \n",
       "263                                2402                                    1   \n",
       "44                                   56                                    1   \n",
       "219                                  51                                    1   \n",
       "143                                 251                                    1   \n",
       "\n",
       "     original_firstorder_10Percentile  original_firstorder_90Percentile  ...  \\\n",
       "23                              175.5                             850.5  ...   \n",
       "263                            -307.0                              61.0  ...   \n",
       "44                             -444.5                             -66.5  ...   \n",
       "219                            -447.0                             102.0  ...   \n",
       "143                            -569.0                              82.0  ...   \n",
       "\n",
       "     diagnostics_Mask-original_BoundingBox_2  \\\n",
       "23                                        30   \n",
       "263                                      169   \n",
       "44                                        50   \n",
       "219                                       81   \n",
       "143                                       41   \n",
       "\n",
       "     diagnostics_Mask-original_BoundingBox_3  \\\n",
       "23                                         4   \n",
       "263                                       29   \n",
       "44                                         6   \n",
       "219                                        6   \n",
       "143                                       11   \n",
       "\n",
       "     diagnostics_Mask-original_BoundingBox_4  \\\n",
       "23                                         6   \n",
       "263                                       24   \n",
       "44                                         9   \n",
       "219                                        7   \n",
       "143                                       14   \n",
       "\n",
       "     diagnostics_Mask-original_BoundingBox_5  \\\n",
       "23                                         2   \n",
       "263                                        9   \n",
       "44                                         2   \n",
       "219                                        2   \n",
       "143                                        3   \n",
       "\n",
       "     diagnostics_Mask-original_CenterOfMassIndex_0  \\\n",
       "23                                      332.692308   \n",
       "263                                     382.402998   \n",
       "44                                       70.267857   \n",
       "219                                     209.313725   \n",
       "143                                     367.756972   \n",
       "\n",
       "     diagnostics_Mask-original_CenterOfMassIndex_1  \\\n",
       "23                                      389.538462   \n",
       "263                                     308.854288   \n",
       "44                                      174.964286   \n",
       "219                                     390.941176   \n",
       "143                                     310.848606   \n",
       "\n",
       "     diagnostics_Mask-original_CenterOfMassIndex_2  \\\n",
       "23                                       30.307692   \n",
       "263                                     173.039550   \n",
       "44                                       50.321429   \n",
       "219                                      81.568627   \n",
       "143                                      41.689243   \n",
       "\n",
       "     diagnostics_Mask-original_CenterOfMass_0  \\\n",
       "23                                  53.215868   \n",
       "263                                 92.739302   \n",
       "44                                -136.237780   \n",
       "219                                -47.673652   \n",
       "143                                 65.179121   \n",
       "\n",
       "     diagnostics_Mask-original_CenterOfMass_1  \\\n",
       "23                                  83.626926   \n",
       "263                                 28.898399   \n",
       "44                                 -53.812866   \n",
       "219                                 80.722794   \n",
       "143                                 43.765426   \n",
       "\n",
       "     diagnostics_Mask-original_CenterOfMass_2  \n",
       "23                                -321.730769  \n",
       "263                                -68.460564  \n",
       "44                                -234.696429  \n",
       "219                               -109.078431  \n",
       "143                               -236.276892  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled data already exists\n"
     ]
    }
   ],
   "source": [
    "# if DF_Radiomics_noduls_with_diagnose_train_data_scaled.csv and DF_Radiomics_noduls_with_diagnose_test_data_scaled.csv already exist, skip this step\n",
    "# otherwise scale the data and save it to CSV files\n",
    "if os.path.isfile('DF_Radiomics_noduls_with_diagnose_train_data_scaled.csv') and os.path.isfile('DF_Radiomics_noduls_with_diagnose_test_data_scaled.csv'):\n",
    "    print(\"Scaled data already exists\")\n",
    "else:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Get all column names\n",
    "    all_columns = train_data.columns.tolist()\n",
    "\n",
    "    # Exclude the first three columns\n",
    "    features = all_columns[3:]\n",
    "\n",
    "    # Create a stratified split\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['Labels'])\n",
    "\n",
    "    # Create a scaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the scaler on the training data and transform both training and test data\n",
    "    train_data[features] = scaler.fit_transform(train_data[features])\n",
    "    test_data[features] = scaler.transform(test_data[features])\n",
    "\n",
    "    # Save the data to CSV files\n",
    "    train_data.to_csv('DF_Radiomics_noduls_with_diagnose_train_data_scaled.csv', index=False)\n",
    "    test_data.to_csv('DF_Radiomics_noduls_with_diagnose_test_data_scaled.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'data' is your pandas DataFrame\n",
    "# Ensure the DataFrame only contains numeric values\n",
    "data = pd.read_csv('DF_Radiomics_noduls_with_diagnose_train_data_scaled.csv')\n",
    "#drop patient and node columns\n",
    "data = data.drop(['Patient', 'Node'], axis=1)\n",
    "# TODO maybe add the columns later to see if it helps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and labels\n",
    "X = data.drop('Labels', axis=1).values\n",
    "y = data['Labels'].values\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X).float()\n",
    "y_tensor = torch.tensor(y).float()\n",
    "\n",
    "# Stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, stratify=y_tensor, random_state=ran_seed)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: torch.Size([197, 115])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data:\", train_dataset.tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class FCNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FCNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Dropout for regularization\n",
    "            nn.Linear(hidden_size, hidden_size*3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Dropout for regularization\n",
    "            nn.Linear(hidden_size*3, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = train_dataset.tensors[0].shape[1]  # Get the number of features from your dataset\n",
    "hidden_size = input_size*2  # You can tune this\n",
    "output_size = 4   # 3 labels \n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 50  # Adjust based on your runtime requirement\n",
    "early_stopping_factor = 10\n",
    "clip_value = 1  # for gradient clipping\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = FCNN(input_size, hidden_size, output_size).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)  # L2 regularization\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "#check if cuda is available, print the gpu model name\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cuda\":\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    # Move model to the device\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.3161638123648507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 1.1103165319987707\n",
      "Epoch 3/50, Loss: 1.061109789780208\n",
      "Epoch 4/50, Loss: 0.9316324251038688\n",
      "Epoch 5/50, Loss: 0.8823548044477191\n",
      "Epoch 6/50, Loss: 0.8529685054506574\n",
      "Epoch 7/50, Loss: 0.8263313259397235\n",
      "Epoch 8/50, Loss: 0.7748461961746216\n",
      "Epoch 9/50, Loss: 0.5953145793506077\n",
      "Epoch 10/50, Loss: 0.6545434466430119\n",
      "Epoch 11/50, Loss: 0.4847463071346283\n",
      "Epoch 12/50, Loss: 0.4685256523745401\n",
      "Epoch 13/50, Loss: 0.42902148621422903\n",
      "Epoch 14/50, Loss: 0.3549581340381077\n",
      "Epoch 15/50, Loss: 0.3122115901538304\n",
      "Epoch 16/50, Loss: 0.3605520214353289\n",
      "Epoch 17/50, Loss: 0.24528947871710574\n",
      "Epoch 18/50, Loss: 0.2521818493093763\n",
      "Epoch 19/50, Loss: 0.3162717765995434\n",
      "Epoch 20/50, Loss: 0.19414080679416656\n",
      "Epoch 21/50, Loss: 0.18455803553972924\n",
      "Epoch 22/50, Loss: 0.1031641678086349\n",
      "Epoch 23/50, Loss: 0.10012213672910418\n",
      "Epoch 24/50, Loss: 0.12945130680288588\n",
      "Epoch 25/50, Loss: 0.0779217980535967\n",
      "Epoch 26/50, Loss: 0.08692797805581774\n",
      "Epoch 27/50, Loss: 0.12372213947985854\n",
      "Epoch 28/50, Loss: 0.06563483444707734\n",
      "Epoch 29/50, Loss: 0.07226794080010482\n",
      "Epoch 30/50, Loss: 0.027681291036839997\n",
      "Epoch 31/50, Loss: 0.057473314992551296\n",
      "Epoch 32/50, Loss: 0.06812339129724673\n",
      "Epoch 33/50, Loss: 0.09351414728111454\n",
      "Epoch 34/50, Loss: 0.09860823250242642\n",
      "Early stopping at epoch 35/50, best loss: 0.027681291036839997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize best loss to infinity for comparison in the first epoch\n",
    "best_loss = float('inf')\n",
    "\n",
    "# Patience counter\n",
    "patience_counter = 0\n",
    "\n",
    "# Patience limit\n",
    "patience_limit = 5\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for inputs, targets in train_loader:\n",
    "    \n",
    "        # Move inputs and targets to the device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        targets = targets.long()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Average epoch loss\n",
    "    epoch_loss = epoch_loss / len(train_loader)\n",
    "\n",
    "    # If the training loss has improved, save the model and reset the patience counter\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        # If the training loss has not improved, increment the patience counter\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience_limit:\n",
    "            print(f\"Early stopping at epoch {epoch+1}/{epochs}, best loss: {best_loss}\")\n",
    "            break\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss}\")\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "Since Confusion Matrix is 3x3 calculate Sensitivity & Specificity for each class by considering that class as the positive class and the other two as the negative class.\n",
    "\n",
    "Sensitivity, also known as the true positive rate (TPR), measures the proportion of actual positives that are correctly identified as such. In other words, it measures the ability of the model to correctly identify positive instances.\n",
    "\n",
    "Specificity, on the other hand, measures the proportion of actual negatives that are correctly identified as such. It measures the ability of the model to correctly identify negative instances.\n",
    "\n",
    "The false positive rate (FPR) is the complement of specificity. It measures the proportion of actual negatives that are incorrectly identified as positives. In other words, it measures the rate at which the model makes false alarms.\n",
    "\n",
    "Here's how they relate:\n",
    "\n",
    "- TPR = Sensitivity = TP / (TP + FN)\n",
    "- FPR = 1 - Specificity = FP / (FP + TN)\n",
    "- Specificity = TN / (TN + FP)\n",
    "\n",
    "Where:\n",
    "- TP = True Positives\n",
    "- FN = False Negatives\n",
    "- FP = False Positives\n",
    "- TN = True Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Get the index of the max log-probability\n",
    "\n",
    "            total_predictions += targets.size(0)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "    # Calculate sensitivity and specificity for each class\n",
    "    sensitivity = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "    specificity = (np.sum(cm) - np.sum(cm, axis = 0) - np.sum(cm, axis = 1) + np.diag(cm)) / (np.sum(cm) - np.sum(cm, axis = 0))\n",
    "\n",
    "    return accuracy, sensitivity, specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.0%\n",
      "Class 0: Sensitivity: 93.75%, Specificity: 97.05882352941177%\n",
      "Class 1: Sensitivity: 61.53846153846154%, Specificity: 87.5%\n",
      "Class 2: Sensitivity: 95.23809523809523%, Specificity: 96.15384615384616%\n"
     ]
    }
   ],
   "source": [
    "# Use the function\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "accuracy, sensitivity, specificity = evaluate(model, test_loader, device)\n",
    "print(f'Accuracy: {accuracy * 100}%')\n",
    "for i, (sens, spec) in enumerate(zip(sensitivity, specificity)):\n",
    "    print(f'Class {i}: Sensitivity: {sens * 100}%, Specificity: {spec * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.87096774193549%\n",
      "Class 0: Sensitivity: 100.0%, Specificity: 100.0%\n",
      "Class 1: Sensitivity: 81.25%, Specificity: 93.75%\n",
      "Class 2: Sensitivity: 73.07692307692307%, Specificity: 82.5%\n"
     ]
    }
   ],
   "source": [
    "validation_data = pd.read_csv('DF_Radiomics_noduls_with_diagnose_test_data_scaled.csv')\n",
    "\n",
    "#create the tensor dataset\n",
    "X_test = validation_data.drop(['Patient', 'Node', 'Labels'], axis=1).values\n",
    "y_test = validation_data['Labels'].values\n",
    "validation_dataset = TensorDataset(torch.tensor(X_test).float(), torch.tensor(y_test).float())\n",
    "\n",
    "# Use the function\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "accuracy, sensitivity, specificity = evaluate(model, validation_loader, device)\n",
    "print(f'Accuracy: {accuracy * 100}%')\n",
    "for i, (sens, spec) in enumerate(zip(sensitivity, specificity)):\n",
    "    print(f'Class {i}: Sensitivity: {sens * 100}%, Specificity: {spec * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.3454635313579015\n",
      "Epoch 2/50, Loss: 1.3167026042938232\n",
      "Epoch 3/50, Loss: 1.285611288888114\n",
      "Epoch 4/50, Loss: 1.25153534752982\n",
      "Epoch 5/50, Loss: 1.2033532346997942\n",
      "Epoch 6/50, Loss: 1.1678636074066162\n",
      "Epoch 7/50, Loss: 1.1284824098859514\n",
      "Epoch 8/50, Loss: 1.0850892577852522\n",
      "Epoch 9/50, Loss: 1.0776778970445906\n",
      "Epoch 10/50, Loss: 1.0600791828972953\n",
      "Epoch 11/50, Loss: 1.025188045842307\n",
      "Epoch 12/50, Loss: 1.0128569432667323\n",
      "Epoch 13/50, Loss: 0.9578045010566711\n",
      "Epoch 14/50, Loss: 0.9453005790710449\n",
      "Epoch 15/50, Loss: 0.9404930642672947\n",
      "Epoch 16/50, Loss: 0.9296838896615165\n",
      "Epoch 17/50, Loss: 0.8556567600795201\n",
      "Epoch 18/50, Loss: 0.8651800155639648\n",
      "Epoch 19/50, Loss: 0.8177476355007717\n",
      "Epoch 20/50, Loss: 0.7845604334558759\n",
      "Epoch 21/50, Loss: 0.8354665807315281\n",
      "Epoch 22/50, Loss: 0.7701520068304879\n",
      "Epoch 23/50, Loss: 0.6963127510888236\n",
      "Epoch 24/50, Loss: 0.6831142050879342\n",
      "Epoch 25/50, Loss: 0.5921354080949511\n",
      "Epoch 26/50, Loss: 0.6591327701296125\n",
      "Epoch 27/50, Loss: 0.6178333589008876\n",
      "Epoch 28/50, Loss: 0.5847633906773159\n",
      "Epoch 29/50, Loss: 0.49842386160578045\n",
      "Epoch 30/50, Loss: 0.6356379900659833\n",
      "Epoch 31/50, Loss: 0.6158750908715385\n",
      "Epoch 32/50, Loss: 0.5020908117294312\n",
      "Epoch 33/50, Loss: 0.5833404575075422\n",
      "Epoch 34/50, Loss: 0.49369955914361136\n",
      "Epoch 35/50, Loss: 0.4727637895515987\n",
      "Epoch 36/50, Loss: 0.4738517275878361\n",
      "Epoch 37/50, Loss: 0.46993243268557955\n",
      "Epoch 38/50, Loss: 0.42100694349833895\n",
      "Epoch 39/50, Loss: 0.3840712862355368\n",
      "Epoch 40/50, Loss: 0.3582352910723005\n",
      "Epoch 41/50, Loss: 0.3437292341675077\n",
      "Epoch 42/50, Loss: 0.3315103564943586\n",
      "Epoch 43/50, Loss: 0.2966575622558594\n",
      "Epoch 44/50, Loss: 0.33192795515060425\n",
      "Epoch 45/50, Loss: 0.3197794663054602\n",
      "Epoch 46/50, Loss: 0.32119746931961607\n",
      "Epoch 47/50, Loss: 0.24745797153030122\n",
      "Epoch 48/50, Loss: 0.23904092822756087\n",
      "Epoch 49/50, Loss: 0.20976589620113373\n",
      "Epoch 50/50, Loss: 0.22527347292218888\n",
      "Epoch 1/50, Loss: 1.3792593479156494\n",
      "Epoch 2/50, Loss: 1.3502167463302612\n",
      "Epoch 3/50, Loss: 1.3093260015760149\n",
      "Epoch 4/50, Loss: 1.28116808618818\n",
      "Epoch 5/50, Loss: 1.2526624543326241\n",
      "Epoch 6/50, Loss: 1.20253620828901\n",
      "Epoch 7/50, Loss: 1.1522420304162162\n",
      "Epoch 8/50, Loss: 1.1307771035603114\n",
      "Epoch 9/50, Loss: 1.0826684747423445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_615/3107658289.py:105: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, pd.DataFrame([[epoch, epoch_loss, best_loss, hidden_size, learning_rate, weight_decay, accuracy, sensitivity, specificity]], columns=results.columns)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 1.0762375252587455\n",
      "Epoch 11/50, Loss: 1.0379269804273332\n",
      "Epoch 12/50, Loss: 1.0104449561664037\n",
      "Epoch 13/50, Loss: 0.9853711128234863\n",
      "Epoch 14/50, Loss: 0.9943097914968219\n",
      "Epoch 15/50, Loss: 0.899771009172712\n",
      "Epoch 16/50, Loss: 0.9013293981552124\n",
      "Epoch 17/50, Loss: 0.8978519099099296\n",
      "Epoch 18/50, Loss: 0.8660790749958583\n",
      "Epoch 19/50, Loss: 0.8968273912157331\n",
      "Epoch 20/50, Loss: 0.8084292922701154\n",
      "Epoch 21/50, Loss: 0.7549840126718793\n",
      "Epoch 22/50, Loss: 0.7241312776293073\n",
      "Epoch 23/50, Loss: 0.8019224149840218\n",
      "Epoch 24/50, Loss: 0.7224840436662946\n",
      "Epoch 25/50, Loss: 0.690648785659245\n",
      "Epoch 26/50, Loss: 0.6805309653282166\n",
      "Epoch 27/50, Loss: 0.7047263128416879\n",
      "Epoch 28/50, Loss: 0.6441679682050433\n",
      "Epoch 29/50, Loss: 0.6807772942951748\n",
      "Epoch 30/50, Loss: 0.6607847724642072\n",
      "Epoch 31/50, Loss: 0.6026772899287087\n",
      "Epoch 32/50, Loss: 0.5874284250395638\n",
      "Epoch 33/50, Loss: 0.5601909160614014\n",
      "Epoch 34/50, Loss: 0.573265518460955\n",
      "Epoch 35/50, Loss: 0.5169649124145508\n",
      "Epoch 36/50, Loss: 0.4985768709863935\n",
      "Epoch 37/50, Loss: 0.5243909912449973\n",
      "Epoch 38/50, Loss: 0.48703423355306896\n",
      "Epoch 39/50, Loss: 0.5397039481571743\n",
      "Epoch 40/50, Loss: 0.4450950878007071\n",
      "Epoch 41/50, Loss: 0.38814967019217356\n",
      "Epoch 42/50, Loss: 0.4051319680043629\n",
      "Epoch 43/50, Loss: 0.34750249130385263\n",
      "Epoch 44/50, Loss: 0.38554663743291584\n",
      "Epoch 45/50, Loss: 0.41475334763526917\n",
      "Epoch 46/50, Loss: 0.461703006710325\n",
      "Epoch 47/50, Loss: 0.3233544485909598\n",
      "Epoch 48/50, Loss: 0.4094595227922712\n",
      "Epoch 49/50, Loss: 0.2721804018531527\n",
      "Epoch 50/50, Loss: 0.23926624549286707\n",
      "Epoch 1/50, Loss: 1.3723776170185633\n",
      "Epoch 2/50, Loss: 1.3492811407361711\n",
      "Epoch 3/50, Loss: 1.316013148852757\n",
      "Epoch 4/50, Loss: 1.2813411610467094\n",
      "Epoch 5/50, Loss: 1.2575752053942\n",
      "Epoch 6/50, Loss: 1.2093971456800188\n",
      "Epoch 7/50, Loss: 1.1659833363124303\n",
      "Epoch 8/50, Loss: 1.1369355406079973\n",
      "Epoch 9/50, Loss: 1.1157455784933907\n",
      "Epoch 10/50, Loss: 1.0822710990905762\n",
      "Epoch 11/50, Loss: 1.0665138363838196\n",
      "Epoch 12/50, Loss: 1.0371104904583521\n",
      "Epoch 13/50, Loss: 0.9894198434693473\n",
      "Epoch 14/50, Loss: 0.9956588319369725\n",
      "Epoch 15/50, Loss: 0.9278041464941842\n",
      "Epoch 16/50, Loss: 0.9295142718723842\n",
      "Epoch 17/50, Loss: 0.9149939332689557\n",
      "Epoch 18/50, Loss: 0.8578967366899762\n",
      "Epoch 19/50, Loss: 0.8812583344323295\n",
      "Epoch 20/50, Loss: 0.831691563129425\n",
      "Epoch 21/50, Loss: 0.7954688583101545\n",
      "Epoch 22/50, Loss: 0.7782507879393441\n",
      "Epoch 23/50, Loss: 0.7470634749957493\n",
      "Epoch 24/50, Loss: 0.6681735685893467\n",
      "Epoch 25/50, Loss: 0.715823803629194\n",
      "Epoch 26/50, Loss: 0.6926931398255485\n",
      "Epoch 27/50, Loss: 0.6932037472724915\n",
      "Epoch 28/50, Loss: 0.6453066042491368\n",
      "Epoch 29/50, Loss: 0.6622032863753182\n",
      "Epoch 30/50, Loss: 0.6987981072493962\n",
      "Epoch 31/50, Loss: 0.5777822349752698\n",
      "Epoch 32/50, Loss: 0.547595202922821\n",
      "Epoch 33/50, Loss: 0.5058692097663879\n",
      "Epoch 34/50, Loss: 0.6042559615203312\n",
      "Epoch 35/50, Loss: 0.4932202015604292\n",
      "Epoch 36/50, Loss: 0.45499372482299805\n",
      "Epoch 37/50, Loss: 0.45683956146240234\n",
      "Epoch 38/50, Loss: 0.43890547113759176\n",
      "Epoch 39/50, Loss: 0.4624031271253313\n",
      "Epoch 40/50, Loss: 0.46348325269562857\n",
      "Epoch 41/50, Loss: 0.3864986853940146\n",
      "Epoch 42/50, Loss: 0.4066547964300428\n",
      "Epoch 43/50, Loss: 0.3637902992112296\n",
      "Epoch 44/50, Loss: 0.2756876583610262\n",
      "Epoch 45/50, Loss: 0.320822326200349\n",
      "Epoch 46/50, Loss: 0.3021085794482912\n",
      "Epoch 47/50, Loss: 0.2550301913704191\n",
      "Epoch 48/50, Loss: 0.24088485538959503\n",
      "Epoch 49/50, Loss: 0.2465534827538899\n",
      "Epoch 50/50, Loss: 0.2947790686573301\n",
      "Epoch 1/50, Loss: 1.2537346226828439\n",
      "Epoch 2/50, Loss: 1.0862518548965454\n",
      "Epoch 3/50, Loss: 1.0425261769975935\n",
      "Epoch 4/50, Loss: 0.8597268206732613\n",
      "Epoch 5/50, Loss: 0.7343505024909973\n",
      "Epoch 6/50, Loss: 0.6734759637287685\n",
      "Epoch 7/50, Loss: 0.5799341797828674\n",
      "Epoch 8/50, Loss: 0.46006760001182556\n",
      "Epoch 9/50, Loss: 0.4120806987796511\n",
      "Epoch 10/50, Loss: 0.40288948374135153\n",
      "Epoch 11/50, Loss: 0.23169139958918095\n",
      "Epoch 12/50, Loss: 0.21082392015627452\n",
      "Epoch 13/50, Loss: 0.2066987348454339\n",
      "Epoch 14/50, Loss: 0.22801202588847705\n",
      "Epoch 15/50, Loss: 0.27797379797058447\n",
      "Epoch 16/50, Loss: 0.23227240570953914\n",
      "Epoch 17/50, Loss: 0.2598259172269276\n",
      "Epoch 18/50, Loss: 0.15766153324927604\n",
      "Epoch 19/50, Loss: 0.13437751254865102\n",
      "Epoch 20/50, Loss: 0.13996041592742717\n",
      "Epoch 21/50, Loss: 0.10168597682578755\n",
      "Epoch 22/50, Loss: 0.07149496035916465\n",
      "Epoch 23/50, Loss: 0.08351343204932553\n",
      "Epoch 24/50, Loss: 0.06558027451059648\n",
      "Epoch 25/50, Loss: 0.07294359873048961\n",
      "Epoch 26/50, Loss: 0.03827523740307827\n",
      "Epoch 27/50, Loss: 0.061870290249186964\n",
      "Epoch 28/50, Loss: 0.021606983001609997\n",
      "Epoch 29/50, Loss: 0.014922332263917528\n",
      "Epoch 30/50, Loss: 0.02211435905857278\n",
      "Epoch 31/50, Loss: 0.012194156172751849\n",
      "Epoch 32/50, Loss: 0.022419432094985887\n",
      "Epoch 33/50, Loss: 0.46566030526134583\n",
      "Epoch 34/50, Loss: 0.020197092472309514\n",
      "Epoch 35/50, Loss: 0.1476798648696526\n",
      "Early stopping at epoch 36/50, best loss: 0.012194156172751849\n",
      "Epoch 1/50, Loss: 1.2483210393360682\n",
      "Epoch 2/50, Loss: 1.068436520440238\n",
      "Epoch 3/50, Loss: 0.9693744097437177\n",
      "Epoch 4/50, Loss: 0.8252389771597726\n",
      "Epoch 5/50, Loss: 0.7203072479793003\n",
      "Epoch 6/50, Loss: 0.6892609255654472\n",
      "Epoch 7/50, Loss: 0.5999736487865448\n",
      "Epoch 8/50, Loss: 0.5513762491089957\n",
      "Epoch 9/50, Loss: 0.3878192050116403\n",
      "Epoch 10/50, Loss: 0.3056178997669901\n",
      "Epoch 11/50, Loss: 0.24835939598934992\n",
      "Epoch 12/50, Loss: 0.22405353720699037\n",
      "Epoch 13/50, Loss: 0.1545866376587323\n",
      "Epoch 14/50, Loss: 0.18009016077433312\n",
      "Epoch 15/50, Loss: 0.16018065810203552\n",
      "Epoch 16/50, Loss: 0.12333484506234527\n",
      "Epoch 17/50, Loss: 0.16320124215313367\n",
      "Epoch 18/50, Loss: 0.1284931834254946\n",
      "Epoch 19/50, Loss: 0.10069893034441131\n",
      "Epoch 20/50, Loss: 0.0906152776109853\n",
      "Epoch 21/50, Loss: 0.05302581819705665\n",
      "Epoch 22/50, Loss: 0.10350978268044335\n",
      "Epoch 23/50, Loss: 0.08160764165222645\n",
      "Epoch 24/50, Loss: 0.0890197066723236\n",
      "Epoch 25/50, Loss: 0.037796237372926304\n",
      "Epoch 26/50, Loss: 0.071821591717058\n",
      "Epoch 27/50, Loss: 0.13153903041633644\n",
      "Epoch 28/50, Loss: 0.06290508746834737\n",
      "Epoch 29/50, Loss: 0.1066152162716857\n",
      "Early stopping at epoch 30/50, best loss: 0.037796237372926304\n",
      "Epoch 1/50, Loss: 1.258209569113595\n",
      "Epoch 2/50, Loss: 1.052902204649789\n",
      "Epoch 3/50, Loss: 0.9858033571924482\n",
      "Epoch 4/50, Loss: 0.9473483477319989\n",
      "Epoch 5/50, Loss: 0.848196804523468\n",
      "Epoch 6/50, Loss: 0.6285496992724282\n",
      "Epoch 7/50, Loss: 0.6404923030308315\n",
      "Epoch 8/50, Loss: 0.46456084081104826\n",
      "Epoch 9/50, Loss: 0.47156499539102825\n",
      "Epoch 10/50, Loss: 0.36807505573545185\n",
      "Epoch 11/50, Loss: 0.3076431942837579\n",
      "Epoch 12/50, Loss: 0.18746306321450643\n",
      "Epoch 13/50, Loss: 0.18567798818860734\n",
      "Epoch 14/50, Loss: 0.21900163165160588\n",
      "Epoch 15/50, Loss: 0.23424722786460603\n",
      "Epoch 16/50, Loss: 0.23306910494076355\n",
      "Epoch 17/50, Loss: 0.12397917998688561\n",
      "Epoch 18/50, Loss: 0.22068495702530658\n",
      "Epoch 19/50, Loss: 0.09420489573052951\n",
      "Epoch 20/50, Loss: 0.18058936138238227\n",
      "Epoch 21/50, Loss: 0.07650461899382728\n",
      "Epoch 22/50, Loss: 0.0641525989132268\n",
      "Epoch 23/50, Loss: 0.03431257592248065\n",
      "Epoch 24/50, Loss: 0.027099862162555968\n",
      "Epoch 25/50, Loss: 0.01789649755560926\n",
      "Epoch 26/50, Loss: 0.029901204896824702\n",
      "Epoch 27/50, Loss: 0.027268206733944162\n",
      "Epoch 28/50, Loss: 0.06499215210455336\n",
      "Epoch 29/50, Loss: 0.17357522129480327\n",
      "Early stopping at epoch 30/50, best loss: 0.01789649755560926\n",
      "Epoch 1/50, Loss: 1.7654637268611364\n",
      "Epoch 2/50, Loss: 1.6401227968079704\n",
      "Epoch 3/50, Loss: 1.3255719627652849\n",
      "Epoch 4/50, Loss: 1.1690073098455156\n",
      "Epoch 5/50, Loss: 1.0643229569707597\n",
      "Epoch 6/50, Loss: 1.1433628712381636\n",
      "Epoch 7/50, Loss: 1.0454999974795751\n",
      "Epoch 8/50, Loss: 1.2324091025761195\n",
      "Epoch 9/50, Loss: 1.0599602971758162\n",
      "Epoch 10/50, Loss: 0.8989190970148359\n",
      "Epoch 11/50, Loss: 0.8563985058239528\n",
      "Epoch 12/50, Loss: 1.0628769482885088\n",
      "Epoch 13/50, Loss: 0.8081458125795636\n",
      "Epoch 14/50, Loss: 1.0150052649634225\n",
      "Epoch 15/50, Loss: 1.0240961057799203\n",
      "Epoch 16/50, Loss: 0.9780744910240173\n",
      "Epoch 17/50, Loss: 0.9732753038406372\n",
      "Early stopping at epoch 18/50, best loss: 0.8081458125795636\n",
      "Epoch 1/50, Loss: 1.6773041657039098\n",
      "Epoch 2/50, Loss: 1.4392037902559554\n",
      "Epoch 3/50, Loss: 1.1951594948768616\n",
      "Epoch 4/50, Loss: 1.331092391695295\n",
      "Epoch 5/50, Loss: 1.0414063334465027\n",
      "Epoch 6/50, Loss: 1.0894460763250078\n",
      "Epoch 7/50, Loss: 0.9822615810803005\n",
      "Epoch 8/50, Loss: 1.070202146257673\n",
      "Epoch 9/50, Loss: 0.9621366688183376\n",
      "Epoch 10/50, Loss: 0.9762014491217477\n",
      "Epoch 11/50, Loss: 0.9025263616016933\n",
      "Epoch 12/50, Loss: 1.1392205953598022\n",
      "Epoch 13/50, Loss: 1.0401363968849182\n",
      "Epoch 14/50, Loss: 0.9414136494909014\n",
      "Epoch 15/50, Loss: 1.0430228284427099\n",
      "Early stopping at epoch 16/50, best loss: 0.9025263616016933\n",
      "Epoch 1/50, Loss: 1.9194001129695348\n",
      "Epoch 2/50, Loss: 2.200425624847412\n",
      "Epoch 3/50, Loss: 1.2316009317125594\n",
      "Epoch 4/50, Loss: 1.062207613672529\n",
      "Epoch 5/50, Loss: 1.0080603190830775\n",
      "Epoch 6/50, Loss: 0.9905256969588143\n",
      "Epoch 7/50, Loss: 1.040056049823761\n",
      "Epoch 8/50, Loss: 1.2860383306230818\n",
      "Epoch 9/50, Loss: 1.0857384034565516\n",
      "Epoch 10/50, Loss: 1.1660728539739336\n",
      "Epoch 11/50, Loss: 0.8891459447996957\n",
      "Epoch 12/50, Loss: 1.2000788365091597\n",
      "Epoch 13/50, Loss: 1.0911049587385995\n",
      "Epoch 14/50, Loss: 0.9452720029013497\n",
      "Epoch 15/50, Loss: 0.9270343439919608\n",
      "Early stopping at epoch 16/50, best loss: 0.8891459447996957\n",
      "Epoch 1/50, Loss: 1.3672725473131453\n",
      "Epoch 2/50, Loss: 1.3255444594791956\n",
      "Epoch 3/50, Loss: 1.2873661518096924\n",
      "Epoch 4/50, Loss: 1.2410379307610648\n",
      "Epoch 5/50, Loss: 1.1770682845796858\n",
      "Epoch 6/50, Loss: 1.1328396797180176\n",
      "Epoch 7/50, Loss: 1.0934101343154907\n",
      "Epoch 8/50, Loss: 1.0634345667702811\n",
      "Epoch 9/50, Loss: 1.0221807530948095\n",
      "Epoch 10/50, Loss: 0.9816897256033761\n",
      "Epoch 11/50, Loss: 0.9642436078616551\n",
      "Epoch 12/50, Loss: 0.9492448483194623\n",
      "Epoch 13/50, Loss: 0.8892355135508946\n",
      "Epoch 14/50, Loss: 0.8784688626016889\n",
      "Epoch 15/50, Loss: 0.8738217949867249\n",
      "Epoch 16/50, Loss: 0.8115585957254682\n",
      "Epoch 17/50, Loss: 0.7365003739084516\n",
      "Epoch 18/50, Loss: 0.7743571145193917\n",
      "Epoch 19/50, Loss: 0.7594904388700213\n",
      "Epoch 20/50, Loss: 0.8610574688230243\n",
      "Epoch 21/50, Loss: 0.6649700147765023\n",
      "Epoch 22/50, Loss: 0.6497231466429574\n",
      "Epoch 23/50, Loss: 0.6594119242259434\n",
      "Epoch 24/50, Loss: 0.5970275912966047\n",
      "Epoch 25/50, Loss: 0.6173043761934552\n",
      "Epoch 26/50, Loss: 0.603927744286401\n",
      "Epoch 27/50, Loss: 0.522391540663583\n",
      "Epoch 28/50, Loss: 0.47893097145216806\n",
      "Epoch 29/50, Loss: 0.49520614743232727\n",
      "Epoch 30/50, Loss: 0.45433081899370464\n",
      "Epoch 31/50, Loss: 0.42920453207833426\n",
      "Epoch 32/50, Loss: 0.41324664439473835\n",
      "Epoch 33/50, Loss: 0.4170441840376173\n",
      "Epoch 34/50, Loss: 0.3523698662008558\n",
      "Epoch 35/50, Loss: 0.3842650992529733\n",
      "Epoch 36/50, Loss: 0.3077199139765331\n",
      "Epoch 37/50, Loss: 0.32201152188437326\n",
      "Epoch 38/50, Loss: 0.2919507218258722\n",
      "Epoch 39/50, Loss: 0.2562544771603176\n",
      "Epoch 40/50, Loss: 0.2385428888457162\n",
      "Epoch 41/50, Loss: 0.24809305369853973\n",
      "Epoch 42/50, Loss: 0.29007051033633097\n",
      "Epoch 43/50, Loss: 0.22716401730264937\n",
      "Epoch 44/50, Loss: 0.1831397180046354\n",
      "Epoch 45/50, Loss: 0.16790398636034556\n",
      "Epoch 46/50, Loss: 0.182745330833963\n",
      "Epoch 47/50, Loss: 0.1472282207437924\n",
      "Epoch 48/50, Loss: 0.12781366067273275\n",
      "Epoch 49/50, Loss: 0.10714249206440789\n",
      "Epoch 50/50, Loss: 0.11540270383868899\n",
      "Epoch 1/50, Loss: 1.38343232018607\n",
      "Epoch 2/50, Loss: 1.3388575996671404\n",
      "Epoch 3/50, Loss: 1.294543010847909\n",
      "Epoch 4/50, Loss: 1.2440702063696725\n",
      "Epoch 5/50, Loss: 1.1874313524791174\n",
      "Epoch 6/50, Loss: 1.1387157951082503\n",
      "Epoch 7/50, Loss: 1.1113464151109969\n",
      "Epoch 8/50, Loss: 1.0434178965432304\n",
      "Epoch 9/50, Loss: 1.0075051614216395\n",
      "Epoch 10/50, Loss: 0.9799437863486153\n",
      "Epoch 11/50, Loss: 0.9541588595935276\n",
      "Epoch 12/50, Loss: 0.9219714488301959\n",
      "Epoch 13/50, Loss: 0.8829296060970852\n",
      "Epoch 14/50, Loss: 0.913902929850987\n",
      "Epoch 15/50, Loss: 0.7987522993768964\n",
      "Epoch 16/50, Loss: 0.8655226571219308\n",
      "Epoch 17/50, Loss: 0.8382959536143711\n",
      "Epoch 18/50, Loss: 0.7273351039205279\n",
      "Epoch 19/50, Loss: 0.762390502861568\n",
      "Epoch 20/50, Loss: 0.6825661063194275\n",
      "Epoch 21/50, Loss: 0.7363345878464835\n",
      "Epoch 22/50, Loss: 0.6896806103842599\n",
      "Epoch 23/50, Loss: 0.6088993038449969\n",
      "Epoch 24/50, Loss: 0.6209976502827236\n",
      "Epoch 25/50, Loss: 0.6074691031660352\n",
      "Epoch 26/50, Loss: 0.6159354065145765\n",
      "Epoch 27/50, Loss: 0.5529670928205762\n",
      "Epoch 28/50, Loss: 0.5987880868571145\n",
      "Epoch 29/50, Loss: 0.47817819884845186\n",
      "Epoch 30/50, Loss: 0.5043230695383889\n",
      "Epoch 31/50, Loss: 0.4921048241002219\n",
      "Epoch 32/50, Loss: 0.3689016955239432\n",
      "Epoch 33/50, Loss: 0.36631194182804655\n",
      "Epoch 34/50, Loss: 0.379913330078125\n",
      "Epoch 35/50, Loss: 0.32453006505966187\n",
      "Epoch 36/50, Loss: 0.32901005872658323\n",
      "Epoch 37/50, Loss: 0.3401935526302883\n",
      "Epoch 38/50, Loss: 0.3245324896914618\n",
      "Epoch 39/50, Loss: 0.2719701166663851\n",
      "Epoch 40/50, Loss: 0.2383783757686615\n",
      "Epoch 41/50, Loss: 0.2629090292113168\n",
      "Epoch 42/50, Loss: 0.23849876863615854\n",
      "Epoch 43/50, Loss: 0.2025418473141534\n",
      "Epoch 44/50, Loss: 0.1904096624680928\n",
      "Epoch 45/50, Loss: 0.20801523540701186\n",
      "Epoch 46/50, Loss: 0.1922474056482315\n",
      "Epoch 47/50, Loss: 0.14105478993483953\n",
      "Epoch 48/50, Loss: 0.11444645853979248\n",
      "Epoch 49/50, Loss: 0.1453648805618286\n",
      "Epoch 50/50, Loss: 0.11808525345155171\n",
      "Epoch 1/50, Loss: 1.3801558869225639\n",
      "Epoch 2/50, Loss: 1.331427471978324\n",
      "Epoch 3/50, Loss: 1.2814116477966309\n",
      "Epoch 4/50, Loss: 1.227359448160444\n",
      "Epoch 5/50, Loss: 1.1906109877995081\n",
      "Epoch 6/50, Loss: 1.1150584391185216\n",
      "Epoch 7/50, Loss: 1.0831551551818848\n",
      "Epoch 8/50, Loss: 1.0663042579378401\n",
      "Epoch 9/50, Loss: 1.043606962476458\n",
      "Epoch 10/50, Loss: 1.0199372257505144\n",
      "Epoch 11/50, Loss: 0.9966788632529122\n",
      "Epoch 12/50, Loss: 0.9657641053199768\n",
      "Epoch 13/50, Loss: 0.9199465087481907\n",
      "Epoch 14/50, Loss: 0.9430589931351798\n",
      "Epoch 15/50, Loss: 0.911814204284123\n",
      "Epoch 16/50, Loss: 0.8260366831507001\n",
      "Epoch 17/50, Loss: 0.7650401166507176\n",
      "Epoch 18/50, Loss: 0.7603278841291156\n",
      "Epoch 19/50, Loss: 0.6962802878447941\n",
      "Epoch 20/50, Loss: 0.7268621666090829\n",
      "Epoch 21/50, Loss: 0.6720074713230133\n",
      "Epoch 22/50, Loss: 0.760771129812513\n",
      "Epoch 23/50, Loss: 0.6810903038297381\n",
      "Epoch 24/50, Loss: 0.612937697342464\n",
      "Epoch 25/50, Loss: 0.5886158261980329\n",
      "Epoch 26/50, Loss: 0.5870247440678733\n",
      "Epoch 27/50, Loss: 0.5816628379481179\n",
      "Epoch 28/50, Loss: 0.5365589729377201\n",
      "Epoch 29/50, Loss: 0.5861158413546426\n",
      "Epoch 30/50, Loss: 0.4716115083013262\n",
      "Epoch 31/50, Loss: 0.41539054257529123\n",
      "Epoch 32/50, Loss: 0.39383124453680857\n",
      "Epoch 33/50, Loss: 0.4717016816139221\n",
      "Epoch 34/50, Loss: 0.3561284435646875\n",
      "Epoch 35/50, Loss: 0.3742973676749638\n",
      "Epoch 36/50, Loss: 0.3262702226638794\n",
      "Epoch 37/50, Loss: 0.283720646585737\n",
      "Epoch 38/50, Loss: 0.2781134992837906\n",
      "Epoch 39/50, Loss: 0.2655784072620528\n",
      "Epoch 40/50, Loss: 0.219108197838068\n",
      "Epoch 41/50, Loss: 0.21128021819250925\n",
      "Epoch 42/50, Loss: 0.22068560974938528\n",
      "Epoch 43/50, Loss: 0.1963791964309556\n",
      "Epoch 44/50, Loss: 0.18660395991589343\n",
      "Epoch 45/50, Loss: 0.1561975298183305\n",
      "Epoch 46/50, Loss: 0.18637619486876897\n",
      "Epoch 47/50, Loss: 0.16096805781126022\n",
      "Epoch 48/50, Loss: 0.14166650282485144\n",
      "Epoch 49/50, Loss: 0.17703446532998765\n",
      "Epoch 50/50, Loss: 0.13885887499366487\n",
      "Epoch 1/50, Loss: 1.2524971791676112\n",
      "Epoch 2/50, Loss: 1.0437264357294356\n",
      "Epoch 3/50, Loss: 0.8467012984412057\n",
      "Epoch 4/50, Loss: 0.9329902103969029\n",
      "Epoch 5/50, Loss: 0.8183699931417193\n",
      "Epoch 6/50, Loss: 0.7150858470371791\n",
      "Epoch 7/50, Loss: 0.5052547752857208\n",
      "Epoch 8/50, Loss: 0.41166114594255176\n",
      "Epoch 9/50, Loss: 0.3311218661921365\n",
      "Epoch 10/50, Loss: 0.2542749233543873\n",
      "Epoch 11/50, Loss: 0.22116471827030182\n",
      "Epoch 12/50, Loss: 0.2417100008044924\n",
      "Epoch 13/50, Loss: 0.17530480452946254\n",
      "Epoch 14/50, Loss: 0.2716883825404303\n",
      "Epoch 15/50, Loss: 0.20612578306879317\n",
      "Epoch 16/50, Loss: 0.17072730830737523\n",
      "Epoch 17/50, Loss: 0.1315929288310664\n",
      "Epoch 18/50, Loss: 0.18201420509389468\n",
      "Epoch 19/50, Loss: 0.16954946890473366\n",
      "Epoch 20/50, Loss: 0.13120167450896197\n",
      "Epoch 21/50, Loss: 0.16314432237829482\n",
      "Epoch 22/50, Loss: 0.173488656857184\n",
      "Epoch 23/50, Loss: 0.03985243942588568\n",
      "Epoch 24/50, Loss: 0.1370844848986183\n",
      "Epoch 25/50, Loss: 0.0760747352947614\n",
      "Epoch 26/50, Loss: 0.08112018315919808\n",
      "Epoch 27/50, Loss: 0.08370774212692465\n",
      "Early stopping at epoch 28/50, best loss: 0.03985243942588568\n",
      "Epoch 1/50, Loss: 1.2202483415603638\n",
      "Epoch 2/50, Loss: 1.0436365263802665\n",
      "Epoch 3/50, Loss: 1.0118057557514735\n",
      "Epoch 4/50, Loss: 0.8759176049913678\n",
      "Epoch 5/50, Loss: 0.6662743559905461\n",
      "Epoch 6/50, Loss: 0.6980374200003487\n",
      "Epoch 7/50, Loss: 0.5467605803694043\n",
      "Epoch 8/50, Loss: 0.42722831879343304\n",
      "Epoch 9/50, Loss: 0.30498012261731283\n",
      "Epoch 10/50, Loss: 0.33765434686626705\n",
      "Epoch 11/50, Loss: 0.4039511818970953\n",
      "Epoch 12/50, Loss: 0.21778259319918497\n",
      "Epoch 13/50, Loss: 0.19487444204943521\n",
      "Epoch 14/50, Loss: 0.13934300440762723\n",
      "Epoch 15/50, Loss: 0.20290493539401463\n",
      "Epoch 16/50, Loss: 0.08680060505867004\n",
      "Epoch 17/50, Loss: 0.102809680093612\n",
      "Epoch 18/50, Loss: 0.10333412270327764\n",
      "Epoch 19/50, Loss: 0.06755408391888652\n",
      "Epoch 20/50, Loss: 0.06536812318622001\n",
      "Epoch 21/50, Loss: 0.08770328786756311\n",
      "Epoch 22/50, Loss: 0.05668953061103821\n",
      "Epoch 23/50, Loss: 0.0500636856138174\n",
      "Epoch 24/50, Loss: 0.02789303757682709\n",
      "Epoch 25/50, Loss: 0.03965479281863996\n",
      "Epoch 26/50, Loss: 0.04840897534242166\n",
      "Epoch 27/50, Loss: 0.08333642195378031\n",
      "Epoch 28/50, Loss: 0.11523701643039073\n",
      "Early stopping at epoch 29/50, best loss: 0.02789303757682709\n",
      "Epoch 1/50, Loss: 1.2137502772467477\n",
      "Epoch 2/50, Loss: 1.086705207824707\n",
      "Epoch 3/50, Loss: 0.9381619095802307\n",
      "Epoch 4/50, Loss: 0.7826762795448303\n",
      "Epoch 5/50, Loss: 0.7741507036345345\n",
      "Epoch 6/50, Loss: 0.5787389640297208\n",
      "Epoch 7/50, Loss: 0.575874503169741\n",
      "Epoch 8/50, Loss: 0.4717399222510202\n",
      "Epoch 9/50, Loss: 0.4436132737568447\n",
      "Epoch 10/50, Loss: 0.3754251684461321\n",
      "Epoch 11/50, Loss: 0.3472930874143328\n",
      "Epoch 12/50, Loss: 0.25727370913539616\n",
      "Epoch 13/50, Loss: 0.15272358804941177\n",
      "Epoch 14/50, Loss: 0.14845311961003713\n",
      "Epoch 15/50, Loss: 0.09779365410629128\n",
      "Epoch 16/50, Loss: 0.13076766500515596\n",
      "Epoch 17/50, Loss: 0.18437016861779348\n",
      "Epoch 18/50, Loss: 0.19730752892792225\n",
      "Epoch 19/50, Loss: 0.12140970783574241\n",
      "Early stopping at epoch 20/50, best loss: 0.09779365410629128\n",
      "Epoch 1/50, Loss: 2.7604051998683383\n",
      "Epoch 2/50, Loss: 1.33890472139631\n",
      "Epoch 3/50, Loss: 1.1145920753479004\n",
      "Epoch 4/50, Loss: 1.1761455621038164\n",
      "Epoch 5/50, Loss: 1.1708487101963587\n",
      "Epoch 6/50, Loss: 0.9512321352958679\n",
      "Epoch 7/50, Loss: 0.9759468521390643\n",
      "Epoch 8/50, Loss: 0.9909067153930664\n",
      "Epoch 9/50, Loss: 1.021733547960009\n",
      "Epoch 10/50, Loss: 1.2747827427727836\n",
      "Early stopping at epoch 11/50, best loss: 0.9512321352958679\n",
      "Epoch 1/50, Loss: 2.431994676589966\n",
      "Epoch 2/50, Loss: 1.282446094921657\n",
      "Epoch 3/50, Loss: 1.2910809346607752\n",
      "Epoch 4/50, Loss: 1.3178708808762687\n",
      "Epoch 5/50, Loss: 1.1479314735957555\n",
      "Epoch 6/50, Loss: 1.1512413280350822\n",
      "Epoch 7/50, Loss: 1.1532830425671168\n",
      "Epoch 8/50, Loss: 1.4923196349825179\n",
      "Epoch 9/50, Loss: 1.1339362689426966\n",
      "Epoch 10/50, Loss: 1.0766271352767944\n",
      "Epoch 11/50, Loss: 1.1076600977352686\n",
      "Epoch 12/50, Loss: 1.1574543884822301\n",
      "Epoch 13/50, Loss: 0.9696106910705566\n",
      "Epoch 14/50, Loss: 1.0061799372945512\n",
      "Epoch 15/50, Loss: 1.0302230715751648\n",
      "Epoch 16/50, Loss: 0.9911246299743652\n",
      "Epoch 17/50, Loss: 0.9966648646763393\n",
      "Early stopping at epoch 18/50, best loss: 0.9696106910705566\n",
      "Epoch 1/50, Loss: 2.4681595223290578\n",
      "Epoch 2/50, Loss: 1.2352335112435477\n",
      "Epoch 3/50, Loss: 1.2338701571737016\n",
      "Epoch 4/50, Loss: 1.1634507179260254\n",
      "Epoch 5/50, Loss: 1.075463252408164\n",
      "Epoch 6/50, Loss: 1.037421464920044\n",
      "Epoch 7/50, Loss: 1.1077836411339896\n",
      "Epoch 8/50, Loss: 1.1249003665787833\n",
      "Epoch 9/50, Loss: 1.0436700327055795\n",
      "Epoch 10/50, Loss: 1.1454479098320007\n",
      "Epoch 11/50, Loss: 0.9406829561505999\n",
      "Epoch 12/50, Loss: 0.9013710618019104\n",
      "Epoch 13/50, Loss: 0.9251632222107479\n",
      "Epoch 14/50, Loss: 1.0173813700675964\n",
      "Epoch 15/50, Loss: 0.9571801679474967\n",
      "Epoch 16/50, Loss: 1.053467801639012\n",
      "Early stopping at epoch 17/50, best loss: 0.9013710618019104\n",
      "Epoch 1/50, Loss: 1.362183826310294\n",
      "Epoch 2/50, Loss: 1.3018725258963448\n",
      "Epoch 3/50, Loss: 1.2535743032182967\n",
      "Epoch 4/50, Loss: 1.1953482287270683\n",
      "Epoch 5/50, Loss: 1.1423212460109167\n",
      "Epoch 6/50, Loss: 1.0979820149285453\n",
      "Epoch 7/50, Loss: 1.0356128896985735\n",
      "Epoch 8/50, Loss: 1.0068189757210868\n",
      "Epoch 9/50, Loss: 0.9512690390859332\n",
      "Epoch 10/50, Loss: 0.9602878178868975\n",
      "Epoch 11/50, Loss: 0.8967953154018947\n",
      "Epoch 12/50, Loss: 0.877629007611956\n",
      "Epoch 13/50, Loss: 0.8308529938970294\n",
      "Epoch 14/50, Loss: 0.8533743619918823\n",
      "Epoch 15/50, Loss: 0.8110738311495099\n",
      "Epoch 16/50, Loss: 0.7538496255874634\n",
      "Epoch 17/50, Loss: 0.7267887166568211\n",
      "Epoch 18/50, Loss: 0.6929831760270255\n",
      "Epoch 19/50, Loss: 0.7007338915552411\n",
      "Epoch 20/50, Loss: 0.6136981504304069\n",
      "Epoch 21/50, Loss: 0.6137293449469975\n",
      "Epoch 22/50, Loss: 0.5990351438522339\n",
      "Epoch 23/50, Loss: 0.5549729551587786\n",
      "Epoch 24/50, Loss: 0.5092613569327763\n",
      "Epoch 25/50, Loss: 0.5034432496343341\n",
      "Epoch 26/50, Loss: 0.4983813890389034\n",
      "Epoch 27/50, Loss: 0.437409907579422\n",
      "Epoch 28/50, Loss: 0.4360321845327105\n",
      "Epoch 29/50, Loss: 0.4916466176509857\n",
      "Epoch 30/50, Loss: 0.40256684592791964\n",
      "Epoch 31/50, Loss: 0.3757001459598541\n",
      "Epoch 32/50, Loss: 0.3106701501778194\n",
      "Epoch 33/50, Loss: 0.32966580774102894\n",
      "Epoch 34/50, Loss: 0.28887770431382315\n",
      "Epoch 35/50, Loss: 0.24901841474430902\n",
      "Epoch 36/50, Loss: 0.22070919935192382\n",
      "Epoch 37/50, Loss: 0.20965177885123662\n",
      "Epoch 38/50, Loss: 0.2110404861824853\n",
      "Epoch 39/50, Loss: 0.1947950225855623\n",
      "Epoch 40/50, Loss: 0.2144115354333605\n",
      "Epoch 41/50, Loss: 0.19075723098857061\n",
      "Epoch 42/50, Loss: 0.16087915003299713\n",
      "Epoch 43/50, Loss: 0.15311851991074427\n",
      "Epoch 44/50, Loss: 0.1051859472479139\n",
      "Epoch 45/50, Loss: 0.12436213450772422\n",
      "Epoch 46/50, Loss: 0.1318039894104004\n",
      "Epoch 47/50, Loss: 0.0946909159954105\n",
      "Epoch 48/50, Loss: 0.07880069621439491\n",
      "Epoch 49/50, Loss: 0.09134825691580772\n",
      "Epoch 50/50, Loss: 0.08552289195358753\n",
      "Epoch 1/50, Loss: 1.354039294379098\n",
      "Epoch 2/50, Loss: 1.3062643664223808\n",
      "Epoch 3/50, Loss: 1.2375328881399972\n",
      "Epoch 4/50, Loss: 1.1866217000143868\n",
      "Epoch 5/50, Loss: 1.1385510308401925\n",
      "Epoch 6/50, Loss: 1.1075375761304582\n",
      "Epoch 7/50, Loss: 1.0539723805018835\n",
      "Epoch 8/50, Loss: 1.0261326091630119\n",
      "Epoch 9/50, Loss: 0.9781527859824044\n",
      "Epoch 10/50, Loss: 0.9416725550379071\n",
      "Epoch 11/50, Loss: 0.8883512275559562\n",
      "Epoch 12/50, Loss: 0.9045844503811428\n",
      "Epoch 13/50, Loss: 0.806318862097604\n",
      "Epoch 14/50, Loss: 0.8421862891742161\n",
      "Epoch 15/50, Loss: 0.7911268898418972\n",
      "Epoch 16/50, Loss: 0.7362274953297206\n",
      "Epoch 17/50, Loss: 0.7711714931896755\n",
      "Epoch 18/50, Loss: 0.7007595470973423\n",
      "Epoch 19/50, Loss: 0.6856752038002014\n",
      "Epoch 20/50, Loss: 0.6437530432428632\n",
      "Epoch 21/50, Loss: 0.6273696252277919\n",
      "Epoch 22/50, Loss: 0.6398222276142665\n",
      "Epoch 23/50, Loss: 0.5328826095376696\n",
      "Epoch 24/50, Loss: 0.5263895690441132\n",
      "Epoch 25/50, Loss: 0.48952905195099966\n",
      "Epoch 26/50, Loss: 0.4875348082610539\n",
      "Epoch 27/50, Loss: 0.4124190296445574\n",
      "Epoch 28/50, Loss: 0.4023675194808415\n",
      "Epoch 29/50, Loss: 0.3658919078963144\n",
      "Epoch 30/50, Loss: 0.3598678026880537\n",
      "Epoch 31/50, Loss: 0.326001521732126\n",
      "Epoch 32/50, Loss: 0.3352804716144289\n",
      "Epoch 33/50, Loss: 0.27369807021958487\n",
      "Epoch 34/50, Loss: 0.26797246507235933\n",
      "Epoch 35/50, Loss: 0.2688786456627505\n",
      "Epoch 36/50, Loss: 0.2909842623131616\n",
      "Epoch 37/50, Loss: 0.2489614337682724\n",
      "Epoch 38/50, Loss: 0.20937209044184005\n",
      "Epoch 39/50, Loss: 0.19185893663338252\n",
      "Epoch 40/50, Loss: 0.22088561952114105\n",
      "Epoch 41/50, Loss: 0.16239728778600693\n",
      "Epoch 42/50, Loss: 0.15496053440230234\n",
      "Epoch 43/50, Loss: 0.13196864298411778\n",
      "Epoch 44/50, Loss: 0.11492239258119039\n",
      "Epoch 45/50, Loss: 0.13085707809243882\n",
      "Epoch 46/50, Loss: 0.10502249321767262\n",
      "Epoch 47/50, Loss: 0.08430542477539607\n",
      "Epoch 48/50, Loss: 0.11251606260027204\n",
      "Epoch 49/50, Loss: 0.1179896385541984\n",
      "Epoch 50/50, Loss: 0.17059091638241494\n",
      "Epoch 1/50, Loss: 1.3497601747512817\n",
      "Epoch 2/50, Loss: 1.2934434754507882\n",
      "Epoch 3/50, Loss: 1.238734245300293\n",
      "Epoch 4/50, Loss: 1.1747636113848006\n",
      "Epoch 5/50, Loss: 1.1175894056047713\n",
      "Epoch 6/50, Loss: 1.0723988158362252\n",
      "Epoch 7/50, Loss: 1.044423256601606\n",
      "Epoch 8/50, Loss: 1.020515331200191\n",
      "Epoch 9/50, Loss: 1.0181677511760168\n",
      "Epoch 10/50, Loss: 0.9244719317981175\n",
      "Epoch 11/50, Loss: 0.9049656902040754\n",
      "Epoch 12/50, Loss: 0.8499205963952201\n",
      "Epoch 13/50, Loss: 0.8392416068485805\n",
      "Epoch 14/50, Loss: 0.8265084624290466\n",
      "Epoch 15/50, Loss: 0.8135980112212045\n",
      "Epoch 16/50, Loss: 0.8191587924957275\n",
      "Epoch 17/50, Loss: 0.7640777145113263\n",
      "Epoch 18/50, Loss: 0.7485553707395282\n",
      "Epoch 19/50, Loss: 0.7925161378724235\n",
      "Epoch 20/50, Loss: 0.6333828568458557\n",
      "Epoch 21/50, Loss: 0.6274402226720538\n",
      "Epoch 22/50, Loss: 0.6516070408480508\n",
      "Epoch 23/50, Loss: 0.5885999798774719\n",
      "Epoch 24/50, Loss: 0.5587316921779087\n",
      "Epoch 25/50, Loss: 0.5272951722145081\n",
      "Epoch 26/50, Loss: 0.4727149861199515\n",
      "Epoch 27/50, Loss: 0.5310454496315548\n",
      "Epoch 28/50, Loss: 0.4099576771259308\n",
      "Epoch 29/50, Loss: 0.4379342922142574\n",
      "Epoch 30/50, Loss: 0.4560478755405971\n",
      "Epoch 31/50, Loss: 0.35290345762457165\n",
      "Epoch 32/50, Loss: 0.3996870815753937\n",
      "Epoch 33/50, Loss: 0.3136261190686907\n",
      "Epoch 34/50, Loss: 0.3108492131744112\n",
      "Epoch 35/50, Loss: 0.2755309385912759\n",
      "Epoch 36/50, Loss: 0.2076762882726533\n",
      "Epoch 37/50, Loss: 0.2282847570521491\n",
      "Epoch 38/50, Loss: 0.21310000334467208\n",
      "Epoch 39/50, Loss: 0.1858614661863872\n",
      "Epoch 40/50, Loss: 0.17013105856520788\n",
      "Epoch 41/50, Loss: 0.16602616331407002\n",
      "Epoch 42/50, Loss: 0.15365383561168397\n",
      "Epoch 43/50, Loss: 0.1383540513260024\n",
      "Epoch 44/50, Loss: 0.11487386269228798\n",
      "Epoch 45/50, Loss: 0.0962214996772153\n",
      "Epoch 46/50, Loss: 0.11657989983047758\n",
      "Epoch 47/50, Loss: 0.10529981340680804\n",
      "Epoch 48/50, Loss: 0.08652853433574949\n",
      "Epoch 49/50, Loss: 0.11856171754854065\n",
      "Epoch 50/50, Loss: 0.0994809807411262\n",
      "Epoch 1/50, Loss: 1.1938916104180473\n",
      "Epoch 2/50, Loss: 1.1199762650898524\n",
      "Epoch 3/50, Loss: 0.9665462630135673\n",
      "Epoch 4/50, Loss: 0.7515616927828107\n",
      "Epoch 5/50, Loss: 0.7467966675758362\n",
      "Epoch 6/50, Loss: 0.5687367532934461\n",
      "Epoch 7/50, Loss: 0.45640742778778076\n",
      "Epoch 8/50, Loss: 0.33388619657073704\n",
      "Epoch 9/50, Loss: 0.2817824259400368\n",
      "Epoch 10/50, Loss: 0.3033164782183511\n",
      "Epoch 11/50, Loss: 0.1701607427426747\n",
      "Epoch 12/50, Loss: 0.14603208377957344\n",
      "Epoch 13/50, Loss: 0.29293217084237505\n",
      "Epoch 14/50, Loss: 0.2671992587191718\n",
      "Epoch 15/50, Loss: 0.18743977642485074\n",
      "Epoch 16/50, Loss: 0.19176511892250606\n",
      "Epoch 17/50, Loss: 0.11630290746688843\n",
      "Epoch 18/50, Loss: 0.12723491686795438\n",
      "Epoch 19/50, Loss: 0.04762457444199494\n",
      "Epoch 20/50, Loss: 0.09170900584597673\n",
      "Epoch 21/50, Loss: 0.15717923012562096\n",
      "Epoch 22/50, Loss: 0.08562860617946301\n",
      "Epoch 23/50, Loss: 0.05865866018991385\n",
      "Epoch 24/50, Loss: 0.037386243364640644\n",
      "Epoch 25/50, Loss: 0.03526202296572072\n",
      "Epoch 26/50, Loss: 0.05995530987690602\n",
      "Epoch 27/50, Loss: 0.11446066659742168\n",
      "Epoch 28/50, Loss: 0.1480041016267413\n",
      "Epoch 29/50, Loss: 0.028019779257842208\n",
      "Epoch 30/50, Loss: 0.04847843183337578\n",
      "Epoch 31/50, Loss: 0.010045752261898347\n",
      "Epoch 32/50, Loss: 0.02349698630340364\n",
      "Epoch 33/50, Loss: 0.01848333079500922\n",
      "Epoch 34/50, Loss: 0.0105953244326104\n",
      "Epoch 35/50, Loss: 0.013174771821858096\n",
      "Epoch 36/50, Loss: 0.008058945883281663\n",
      "Epoch 37/50, Loss: 0.005890001932389818\n",
      "Epoch 38/50, Loss: 0.00577849118521304\n",
      "Epoch 39/50, Loss: 0.018510860803092197\n",
      "Epoch 40/50, Loss: 0.016460314925227846\n",
      "Epoch 41/50, Loss: 0.09868492928217165\n",
      "Epoch 42/50, Loss: 0.0027095339693395154\n",
      "Epoch 43/50, Loss: 0.03499897352802301\n",
      "Epoch 44/50, Loss: 0.13120859248946154\n",
      "Epoch 45/50, Loss: 0.028656290607094497\n",
      "Epoch 46/50, Loss: 0.060423865249114375\n",
      "Early stopping at epoch 47/50, best loss: 0.0027095339693395154\n",
      "Epoch 1/50, Loss: 1.2159326928002494\n",
      "Epoch 2/50, Loss: 0.9506766540663583\n",
      "Epoch 3/50, Loss: 1.013198937688555\n",
      "Epoch 4/50, Loss: 0.8443679256098611\n",
      "Epoch 5/50, Loss: 0.8046332001686096\n",
      "Epoch 6/50, Loss: 0.6227684872491019\n",
      "Epoch 7/50, Loss: 0.46561761839049204\n",
      "Epoch 8/50, Loss: 0.3897512895720346\n",
      "Epoch 9/50, Loss: 0.31496285860027584\n",
      "Epoch 10/50, Loss: 0.29302388429641724\n",
      "Epoch 11/50, Loss: 0.3137320157672678\n",
      "Epoch 12/50, Loss: 0.28818980178662706\n",
      "Epoch 13/50, Loss: 0.1945541724562645\n",
      "Epoch 14/50, Loss: 0.22732590351785933\n",
      "Epoch 15/50, Loss: 0.14112232572266034\n",
      "Epoch 16/50, Loss: 0.17666458870683396\n",
      "Epoch 17/50, Loss: 0.10677647377763476\n",
      "Epoch 18/50, Loss: 0.1014048701950482\n",
      "Epoch 19/50, Loss: 0.05610769335180521\n",
      "Epoch 20/50, Loss: 0.05668363197037252\n",
      "Epoch 21/50, Loss: 0.10414661852908987\n",
      "Epoch 22/50, Loss: 0.1015344602721078\n",
      "Epoch 23/50, Loss: 0.060966288803943565\n",
      "Epoch 24/50, Loss: 0.030757553143692867\n",
      "Epoch 25/50, Loss: 0.023412873648047543\n",
      "Epoch 26/50, Loss: 0.03833237109107098\n",
      "Epoch 27/50, Loss: 0.062361004296690226\n",
      "Epoch 28/50, Loss: 0.09601739527923721\n",
      "Epoch 29/50, Loss: 0.03042802997931306\n",
      "Epoch 30/50, Loss: 0.015097760412442898\n",
      "Epoch 31/50, Loss: 0.020300242043699006\n",
      "Epoch 32/50, Loss: 0.015936040452548435\n",
      "Epoch 33/50, Loss: 0.017678364196659198\n",
      "Epoch 34/50, Loss: 0.02688915327390922\n",
      "Early stopping at epoch 35/50, best loss: 0.015097760412442898\n",
      "Epoch 1/50, Loss: 1.186810621193477\n",
      "Epoch 2/50, Loss: 1.0083110502788\n",
      "Epoch 3/50, Loss: 0.8659370967320034\n",
      "Epoch 4/50, Loss: 0.9101517796516418\n",
      "Epoch 5/50, Loss: 0.6712402318205152\n",
      "Epoch 6/50, Loss: 0.5895718634128571\n",
      "Epoch 7/50, Loss: 0.4312805874007089\n",
      "Epoch 8/50, Loss: 0.27986336765544756\n",
      "Epoch 9/50, Loss: 0.3178296557494572\n",
      "Epoch 10/50, Loss: 0.2126292598965977\n",
      "Epoch 11/50, Loss: 0.16086141977991378\n",
      "Epoch 12/50, Loss: 0.1756687999836036\n",
      "Epoch 13/50, Loss: 0.15808147990277835\n",
      "Epoch 14/50, Loss: 0.1571989812489067\n",
      "Epoch 15/50, Loss: 0.12530965750712703\n",
      "Epoch 16/50, Loss: 0.22001335237707412\n",
      "Epoch 17/50, Loss: 0.20956939658416168\n",
      "Epoch 18/50, Loss: 0.0721614028194121\n",
      "Epoch 19/50, Loss: 0.9590714033693075\n",
      "Epoch 20/50, Loss: 0.19283776997222699\n",
      "Epoch 21/50, Loss: 0.1835333172764097\n",
      "Epoch 22/50, Loss: 0.08915588685444423\n",
      "Epoch 23/50, Loss: 0.04841658818934645\n",
      "Epoch 24/50, Loss: 0.08775886138235885\n",
      "Epoch 25/50, Loss: 0.041654468048363924\n",
      "Epoch 26/50, Loss: 0.057402317046320865\n",
      "Epoch 27/50, Loss: 0.034099055254565816\n",
      "Epoch 28/50, Loss: 0.022004787668785348\n",
      "Epoch 29/50, Loss: 0.011466544071351694\n",
      "Epoch 30/50, Loss: 0.0515776218380779\n",
      "Epoch 31/50, Loss: 0.016509412638177828\n",
      "Epoch 32/50, Loss: 0.005599236685481758\n",
      "Epoch 33/50, Loss: 0.009267412841186993\n",
      "Epoch 34/50, Loss: 0.013578447180667095\n",
      "Epoch 35/50, Loss: 0.0048634889202990705\n",
      "Epoch 36/50, Loss: 0.04749746341050403\n",
      "Epoch 37/50, Loss: 0.25672612532175015\n",
      "Epoch 38/50, Loss: 0.16249010499034608\n",
      "Epoch 39/50, Loss: 0.1501243935033147\n",
      "Early stopping at epoch 40/50, best loss: 0.0048634889202990705\n",
      "Epoch 1/50, Loss: 4.922277774129595\n",
      "Epoch 2/50, Loss: 1.4672583852495467\n",
      "Epoch 3/50, Loss: 1.269680917263031\n",
      "Epoch 4/50, Loss: 1.1707797135625566\n",
      "Epoch 5/50, Loss: 1.5316174711499895\n",
      "Epoch 6/50, Loss: 1.0927385772977556\n",
      "Epoch 7/50, Loss: 1.0730523041316442\n",
      "Epoch 8/50, Loss: 1.0952171087265015\n",
      "Epoch 9/50, Loss: 1.0154506819588798\n",
      "Epoch 10/50, Loss: 1.06061794928142\n",
      "Epoch 11/50, Loss: 1.0688098924500602\n",
      "Epoch 12/50, Loss: 1.04549617426736\n",
      "Epoch 13/50, Loss: 1.0465627227510725\n",
      "Early stopping at epoch 14/50, best loss: 1.0154506819588798\n",
      "Epoch 1/50, Loss: 2.6936937740870883\n",
      "Epoch 2/50, Loss: 1.358720796448844\n",
      "Epoch 3/50, Loss: 1.1839933906282698\n",
      "Epoch 4/50, Loss: 1.7052394236837114\n",
      "Epoch 5/50, Loss: 1.3857760429382324\n",
      "Epoch 6/50, Loss: 1.2636820929391044\n",
      "Epoch 7/50, Loss: 1.0356617740222387\n",
      "Epoch 8/50, Loss: 0.983744238104139\n",
      "Epoch 9/50, Loss: 1.1714777094977242\n",
      "Epoch 10/50, Loss: 0.9823723861149379\n",
      "Epoch 11/50, Loss: 1.3243549466133118\n",
      "Epoch 12/50, Loss: 1.094829295362745\n",
      "Epoch 13/50, Loss: 0.9926651205335345\n",
      "Epoch 14/50, Loss: 1.1144269279071264\n",
      "Early stopping at epoch 15/50, best loss: 0.9823723861149379\n",
      "Epoch 1/50, Loss: 4.207723293985639\n",
      "Epoch 2/50, Loss: 1.4170047725949968\n",
      "Epoch 3/50, Loss: 1.5140125751495361\n",
      "Epoch 4/50, Loss: 1.5371377979006087\n",
      "Epoch 5/50, Loss: 1.230967674936567\n",
      "Epoch 6/50, Loss: 1.2644309571811132\n",
      "Epoch 7/50, Loss: 1.204206713608333\n",
      "Epoch 8/50, Loss: 1.1001815966197424\n",
      "Epoch 9/50, Loss: 1.4559349247387476\n",
      "Epoch 10/50, Loss: 0.9806985769953046\n",
      "Epoch 11/50, Loss: 1.2851629938398088\n",
      "Epoch 12/50, Loss: 0.9871890715190342\n",
      "Epoch 13/50, Loss: 1.054939602102552\n",
      "Epoch 14/50, Loss: 0.8905873213495527\n",
      "Epoch 15/50, Loss: 0.9665048973900932\n",
      "Epoch 16/50, Loss: 1.054111293384007\n",
      "Epoch 17/50, Loss: 1.0782225728034973\n",
      "Epoch 18/50, Loss: 1.1486111879348755\n",
      "Early stopping at epoch 19/50, best loss: 0.8905873213495527\n",
      "  epoch  epoch_loss  best_loss hidden_size  learning_rate weight_decay  \\\n",
      "0    49    0.225273   0.209766         460         0.0001            0   \n",
      "0    49    0.239266   0.239266         460         0.0001      0.00001   \n",
      "0    49    0.294779   0.240885         460         0.0001       0.0001   \n",
      "0    35    0.067327   0.012194         460         0.0010            0   \n",
      "0    29    0.137157   0.037796         460         0.0010      0.00001   \n",
      "0    29    0.073449   0.017896         460         0.0010       0.0001   \n",
      "0    17    1.110631   0.808146         460         0.0100            0   \n",
      "0    15    0.976041   0.902526         460         0.0100      0.00001   \n",
      "0    15    1.165698   0.889146         460         0.0100       0.0001   \n",
      "0    49    0.115403   0.107142         575         0.0001            0   \n",
      "0    49    0.118085   0.114446         575         0.0001      0.00001   \n",
      "0    49    0.138859   0.138859         575         0.0001       0.0001   \n",
      "0    27    0.087011   0.039852         575         0.0010            0   \n",
      "0    28    0.145323   0.027893         575         0.0010      0.00001   \n",
      "0    19    0.183415   0.097794         575         0.0010       0.0001   \n",
      "0    10    1.045783   0.951232         575         0.0100            0   \n",
      "0    17    1.033562   0.969611         575         0.0100      0.00001   \n",
      "0    16    0.990624   0.901371         575         0.0100       0.0001   \n",
      "0    49    0.085523   0.078801         690         0.0001            0   \n",
      "0    49    0.170591   0.084305         690         0.0001      0.00001   \n",
      "0    49    0.099481   0.086529         690         0.0001       0.0001   \n",
      "0    46    0.042288   0.002710         690         0.0010            0   \n",
      "0    34    0.024954   0.015098         690         0.0010      0.00001   \n",
      "0    39    0.028338   0.004863         690         0.0010       0.0001   \n",
      "0    13    1.088713   1.015451         690         0.0100            0   \n",
      "0    14    1.319186   0.982372         690         0.0100      0.00001   \n",
      "0    18    1.146538   0.890587         690         0.0100       0.0001   \n",
      "\n",
      "   accuracy                         sensitivity  \\\n",
      "0  0.758065   [0.9, 0.8125, 0.6153846153846154]   \n",
      "0  0.725806   [0.9, 0.8125, 0.5384615384615384]   \n",
      "0  0.790323  [0.95, 0.8125, 0.6538461538461539]   \n",
      "0  0.854839  [0.95, 0.8125, 0.8076923076923077]   \n",
      "0  0.838710  [0.85, 0.8125, 0.8461538461538461]   \n",
      "0  0.854839  [0.85, 0.8125, 0.8846153846153846]   \n",
      "0  0.483871  [0.55, 0.625, 0.34615384615384615]   \n",
      "0  0.629032                   [0.8, 0.625, 0.5]   \n",
      "0  0.580645  [0.85, 0.625, 0.34615384615384615]   \n",
      "0  0.790323   [0.9, 0.8125, 0.6923076923076923]   \n",
      "0  0.806452  [0.95, 0.8125, 0.6923076923076923]   \n",
      "0  0.806452  [0.85, 0.8125, 0.7692307692307693]   \n",
      "0  0.774194     [0.7, 0.75, 0.8461538461538461]   \n",
      "0  0.822581  [0.75, 0.8125, 0.8846153846153846]   \n",
      "0  0.774194   [0.9, 0.8125, 0.6538461538461539]   \n",
      "0  0.467742  [0.15, 0.1875, 0.8846153846153846]   \n",
      "0  0.451613   [0.0, 0.1875, 0.9615384615384616]   \n",
      "0  0.612903    [0.45, 0.75, 0.6538461538461539]   \n",
      "0  0.790323   [0.9, 0.8125, 0.6923076923076923]   \n",
      "0  0.822581   [0.9, 0.8125, 0.7692307692307693]   \n",
      "0  0.822581  [0.95, 0.8125, 0.7307692307692307]   \n",
      "0  0.838710   [0.8, 0.8125, 0.8846153846153846]   \n",
      "0  0.822581  [0.95, 0.8125, 0.7307692307692307]   \n",
      "0  0.870968  [0.95, 0.8125, 0.8461538461538461]   \n",
      "0  0.451613   [0.0, 0.1875, 0.9615384615384616]   \n",
      "0  0.483871  [0.9, 0.1875, 0.34615384615384615]   \n",
      "0  0.645161    [0.45, 0.75, 0.7307692307692307]   \n",
      "\n",
      "                                         specificity  \n",
      "0   [0.9411764705882353, 0.9375, 0.7619047619047619]  \n",
      "0  [0.9428571428571428, 0.9333333333333333, 0.727...  \n",
      "0  [0.9705882352941176, 0.9387755102040817, 0.780...  \n",
      "0  [0.9743589743589743, 0.9361702127659575, 0.868...  \n",
      "0  [0.926829268292683, 0.9333333333333333, 0.8947...  \n",
      "0  [0.9285714285714286, 0.9347826086956522, 0.916...  \n",
      "0  [0.7567567567567568, 0.8775510204081632, 0.552...  \n",
      "0  [0.8666666666666667, 0.8775510204081632, 0.711...  \n",
      "0  [0.8928571428571429, 0.8775510204081632, 0.638...  \n",
      "0      [0.9459459459459459, 0.9361702127659575, 0.8]  \n",
      "0  [0.9722222222222222, 0.9361702127659575, 0.804...  \n",
      "0    [0.925, 0.9361702127659575, 0.8378378378378378]  \n",
      "0    [0.8666666666666667, 0.9148936170212766, 0.875]  \n",
      "0  [0.8888888888888888, 0.9361702127659575, 0.90625]  \n",
      "0  [0.9444444444444444, 0.9361702127659575, 0.780...  \n",
      "0     [0.7068965517241379, 0.7592592592592593, 0.75]  \n",
      "0     [0.6774193548387096, 0.7758620689655172, 0.75]  \n",
      "0     [0.78, 0.8974358974358975, 0.7428571428571429]  \n",
      "0      [0.9459459459459459, 0.9361702127659575, 0.8]  \n",
      "0   [0.9473684210526315, 0.9375, 0.8421052631578947]  \n",
      "0                [0.9722222222222222, 0.9375, 0.825]  \n",
      "0  [0.9090909090909091, 0.9333333333333333, 0.914...  \n",
      "0     [0.972972972972973, 0.9361702127659575, 0.825]  \n",
      "0    [0.975, 0.9361702127659575, 0.8918918918918919]  \n",
      "0     [0.6774193548387096, 0.7758620689655172, 0.75]  \n",
      "0  [0.8888888888888888, 0.7758620689655172, 0.645...  \n",
      "0     [0.78, 0.9090909090909091, 0.7666666666666667]  \n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = train_dataset.tensors[0].shape[1]  # Get the number of features from your dataset\n",
    "output_size = 4   # 3 labels \n",
    "batch_size = 32\n",
    "epochs = 50  # Adjust based on your runtime requirement\n",
    "early_stopping_factor = 10\n",
    "clip_value = 1  # for gradient clipping\n",
    "\n",
    "# Hyperparameters to tune\n",
    "hidden_sizes = [input_size*4, input_size*5, input_size*6]\n",
    "learning_rates = [0.0001, 0.001, 0.01]\n",
    "weight_decays = [0, 1e-5, 1e-4]  # L2 regularization\n",
    "\n",
    "# Load validation data\n",
    "validation_data = pd.read_csv('DF_Radiomics_noduls_with_diagnose_test_data_scaled.csv')\n",
    "\n",
    "# Create the tensor dataset\n",
    "X_test = validation_data.drop(['Patient', 'Node', 'Labels'], axis=1).values\n",
    "y_test = validation_data['Labels'].values\n",
    "validation_dataset = TensorDataset(torch.tensor(X_test).float(), torch.tensor(y_test).float())\n",
    "\n",
    "# Use the function\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize DataFrame to store results\n",
    "results = pd.DataFrame(columns=[\"epoch\", \"epoch_loss\", \"best_loss\", \"hidden_size\", \"learning_rate\", \"weight_decay\", \"accuracy\", \"sensitivity\", \"specificity\"])\n",
    "\n",
    "# Grid search\n",
    "for hidden_size in hidden_sizes:\n",
    "    for learning_rate in learning_rates:\n",
    "        for weight_decay in weight_decays:\n",
    "            # Initialize model, loss function, and optimizer\n",
    "            model = FCNN(input_size, hidden_size, output_size).cuda()\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "            # DataLoader\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "                        # Initialize best loss to infinity for comparison in the first epoch\n",
    "            best_loss = float('inf')\n",
    "\n",
    "            # Patience counter\n",
    "            patience_counter = 0\n",
    "\n",
    "            # Patience limit\n",
    "            patience_limit = 5\n",
    "            \n",
    "            # Training loop (as before)...\n",
    "            model.train()\n",
    "            for epoch in range(epochs):\n",
    "                epoch_loss = 0\n",
    "                for inputs, targets in train_loader:\n",
    "                \n",
    "                    # Move inputs and targets to the device\n",
    "                    inputs = inputs.to(device)\n",
    "                    targets = targets.to(device)\n",
    "                    \n",
    "                    targets = targets.long()\n",
    "\n",
    "                    # Zero the gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Forward pass\n",
    "                    outputs = model(inputs)\n",
    "\n",
    "                    # Compute loss\n",
    "                    loss = criterion(outputs, targets)\n",
    "\n",
    "                    # Backward pass and optimize\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    epoch_loss += loss.item()\n",
    "\n",
    "                # Average epoch loss\n",
    "                epoch_loss = epoch_loss / len(train_loader)\n",
    "\n",
    "                # If the training loss has improved, save the model and reset the patience counter\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    patience_counter = 0\n",
    "                    #torch.save(model.state_dict(), 'best_model.pth')\n",
    "                    #change to realtive path according to the hidden size, learning rate and weight decay\n",
    "                    torch.save(model.state_dict(), f'../models/best_model_{hidden_size}_{str(learning_rate).replace(\".\", \"_\")}_{weight_decay}.pth')\n",
    "\n",
    "                    \n",
    "                else:\n",
    "                    # If the training loss has not improved, increment the patience counter\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= patience_limit:\n",
    "                        print(f\"Early stopping at epoch {epoch+1}/{epochs}, best loss: {best_loss}\")\n",
    "                        break\n",
    "\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss}\")\n",
    "\n",
    "            # Load the best model\n",
    "            model.load_state_dict(torch.load(f'../models/best_model_{hidden_size}_{str(learning_rate).replace(\".\", \"_\")}_{weight_decay}.pth'))\n",
    "\n",
    "            # Evaluate the model\n",
    "            accuracy, sensitivity, specificity = evaluate(model, validation_loader, device)\n",
    "\n",
    "            # Write results to DataFrame\n",
    "            # Check if results is a DataFrame with concat\n",
    "            results = pd.concat([results, pd.DataFrame([[epoch, epoch_loss, best_loss, hidden_size, learning_rate, weight_decay, accuracy, sensitivity, specificity]], columns=results.columns)])\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>epoch_loss</th>\n",
       "      <th>best_loss</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.028338</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>690</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>[0.95, 0.8125, 0.8461538461538461]</td>\n",
       "      <td>[0.975, 0.9361702127659575, 0.8918918918918919]</td>\n",
       "      <td>6.282684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>0.067327</td>\n",
       "      <td>0.012194</td>\n",
       "      <td>460</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>[0.95, 0.8125, 0.8076923076923077]</td>\n",
       "      <td>[0.9743589743589743, 0.9361702127659575, 0.868...</td>\n",
       "      <td>6.203981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>0.073449</td>\n",
       "      <td>0.017896</td>\n",
       "      <td>460</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>[0.85, 0.8125, 0.8846153846153846]</td>\n",
       "      <td>[0.9285714285714286, 0.9347826086956522, 0.916...</td>\n",
       "      <td>6.181975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>0.137157</td>\n",
       "      <td>0.037796</td>\n",
       "      <td>460</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>[0.85, 0.8125, 0.8461538461538461]</td>\n",
       "      <td>[0.926829268292683, 0.9333333333333333, 0.8947...</td>\n",
       "      <td>6.102263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>0.042288</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>690</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>[0.8, 0.8125, 0.8846153846153846]</td>\n",
       "      <td>[0.9090909090909091, 0.9333333333333333, 0.914...</td>\n",
       "      <td>6.092535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>0.099481</td>\n",
       "      <td>0.086529</td>\n",
       "      <td>690</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>[0.95, 0.8125, 0.7307692307692307]</td>\n",
       "      <td>[0.9722222222222222, 0.9375, 0.825]</td>\n",
       "      <td>6.050572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>0.024954</td>\n",
       "      <td>0.015098</td>\n",
       "      <td>690</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>[0.95, 0.8125, 0.7307692307692307]</td>\n",
       "      <td>[0.972972972972973, 0.9361702127659575, 0.825]</td>\n",
       "      <td>6.049993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>0.170591</td>\n",
       "      <td>0.084305</td>\n",
       "      <td>690</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>[0.9, 0.8125, 0.7692307692307693]</td>\n",
       "      <td>[0.9473684210526315, 0.9375, 0.8421052631578947]</td>\n",
       "      <td>6.031285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>0.145323</td>\n",
       "      <td>0.027893</td>\n",
       "      <td>575</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>[0.75, 0.8125, 0.8846153846153846]</td>\n",
       "      <td>[0.8888888888888888, 0.9361702127659575, 0.90625]</td>\n",
       "      <td>6.001005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>0.118085</td>\n",
       "      <td>0.114446</td>\n",
       "      <td>575</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>[0.95, 0.8125, 0.6923076923076923]</td>\n",
       "      <td>[0.9722222222222222, 0.9361702127659575, 0.804...</td>\n",
       "      <td>5.974530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>0.138859</td>\n",
       "      <td>0.138859</td>\n",
       "      <td>575</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>[0.85, 0.8125, 0.7692307692307693]</td>\n",
       "      <td>[0.925, 0.9361702127659575, 0.8378378378378378]</td>\n",
       "      <td>5.937190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>0.294779</td>\n",
       "      <td>0.240885</td>\n",
       "      <td>460</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>[0.95, 0.8125, 0.6538461538461539]</td>\n",
       "      <td>[0.9705882352941176, 0.9387755102040817, 0.780...</td>\n",
       "      <td>5.896520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>0.085523</td>\n",
       "      <td>0.078801</td>\n",
       "      <td>690</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>[0.9, 0.8125, 0.6923076923076923]</td>\n",
       "      <td>[0.9459459459459459, 0.9361702127659575, 0.8]</td>\n",
       "      <td>5.877246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>0.115403</td>\n",
       "      <td>0.107142</td>\n",
       "      <td>575</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>[0.9, 0.8125, 0.6923076923076923]</td>\n",
       "      <td>[0.9459459459459459, 0.9361702127659575, 0.8]</td>\n",
       "      <td>5.877246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>0.183415</td>\n",
       "      <td>0.097794</td>\n",
       "      <td>575</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>[0.9, 0.8125, 0.6538461538461539]</td>\n",
       "      <td>[0.9444444444444444, 0.9361702127659575, 0.780...</td>\n",
       "      <td>5.801642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>0.087011</td>\n",
       "      <td>0.039852</td>\n",
       "      <td>575</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>[0.7, 0.75, 0.8461538461538461]</td>\n",
       "      <td>[0.8666666666666667, 0.9148936170212766, 0.875]</td>\n",
       "      <td>5.726908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>0.225273</td>\n",
       "      <td>0.209766</td>\n",
       "      <td>460</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>[0.9, 0.8125, 0.6153846153846154]</td>\n",
       "      <td>[0.9411764705882353, 0.9375, 0.7619047619047619]</td>\n",
       "      <td>5.726530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>0.239266</td>\n",
       "      <td>0.239266</td>\n",
       "      <td>460</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>[0.9, 0.8125, 0.5384615384615384]</td>\n",
       "      <td>[0.9428571428571428, 0.9333333333333333, 0.727...</td>\n",
       "      <td>5.580231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>1.146538</td>\n",
       "      <td>0.890587</td>\n",
       "      <td>690</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>[0.45, 0.75, 0.7307692307692307]</td>\n",
       "      <td>[0.78, 0.9090909090909091, 0.7666666666666667]</td>\n",
       "      <td>5.031688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0.976041</td>\n",
       "      <td>0.902526</td>\n",
       "      <td>460</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>[0.8, 0.625, 0.5]</td>\n",
       "      <td>[0.8666666666666667, 0.8775510204081632, 0.711...</td>\n",
       "      <td>5.009361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0.990624</td>\n",
       "      <td>0.901371</td>\n",
       "      <td>575</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>[0.45, 0.75, 0.6538461538461539]</td>\n",
       "      <td>[0.78, 0.8974358974358975, 0.7428571428571429]</td>\n",
       "      <td>4.887042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1.165698</td>\n",
       "      <td>0.889146</td>\n",
       "      <td>460</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>[0.85, 0.625, 0.34615384615384615]</td>\n",
       "      <td>[0.8928571428571429, 0.8775510204081632, 0.638...</td>\n",
       "      <td>4.810505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>1.319186</td>\n",
       "      <td>0.982372</td>\n",
       "      <td>690</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>[0.9, 0.1875, 0.34615384615384615]</td>\n",
       "      <td>[0.8888888888888888, 0.7758620689655172, 0.645...</td>\n",
       "      <td>4.228109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>1.110631</td>\n",
       "      <td>0.808146</td>\n",
       "      <td>460</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>[0.55, 0.625, 0.34615384615384615]</td>\n",
       "      <td>[0.7567567567567568, 0.8775510204081632, 0.552...</td>\n",
       "      <td>4.191964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1.045783</td>\n",
       "      <td>0.951232</td>\n",
       "      <td>575</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.467742</td>\n",
       "      <td>[0.15, 0.1875, 0.8846153846153846]</td>\n",
       "      <td>[0.7068965517241379, 0.7592592592592593, 0.75]</td>\n",
       "      <td>3.906013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>1.033562</td>\n",
       "      <td>0.969611</td>\n",
       "      <td>575</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>[0.0, 0.1875, 0.9615384615384616]</td>\n",
       "      <td>[0.6774193548387096, 0.7758620689655172, 0.75]</td>\n",
       "      <td>3.803933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>1.088713</td>\n",
       "      <td>1.015451</td>\n",
       "      <td>690</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>[0.0, 0.1875, 0.9615384615384616]</td>\n",
       "      <td>[0.6774193548387096, 0.7758620689655172, 0.75]</td>\n",
       "      <td>3.803933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch  epoch_loss  best_loss hidden_size  learning_rate weight_decay  \\\n",
       "0    39    0.028338   0.004863         690         0.0010       0.0001   \n",
       "0    35    0.067327   0.012194         460         0.0010            0   \n",
       "0    29    0.073449   0.017896         460         0.0010       0.0001   \n",
       "0    29    0.137157   0.037796         460         0.0010      0.00001   \n",
       "0    46    0.042288   0.002710         690         0.0010            0   \n",
       "0    49    0.099481   0.086529         690         0.0001       0.0001   \n",
       "0    34    0.024954   0.015098         690         0.0010      0.00001   \n",
       "0    49    0.170591   0.084305         690         0.0001      0.00001   \n",
       "0    28    0.145323   0.027893         575         0.0010      0.00001   \n",
       "0    49    0.118085   0.114446         575         0.0001      0.00001   \n",
       "0    49    0.138859   0.138859         575         0.0001       0.0001   \n",
       "0    49    0.294779   0.240885         460         0.0001       0.0001   \n",
       "0    49    0.085523   0.078801         690         0.0001            0   \n",
       "0    49    0.115403   0.107142         575         0.0001            0   \n",
       "0    19    0.183415   0.097794         575         0.0010       0.0001   \n",
       "0    27    0.087011   0.039852         575         0.0010            0   \n",
       "0    49    0.225273   0.209766         460         0.0001            0   \n",
       "0    49    0.239266   0.239266         460         0.0001      0.00001   \n",
       "0    18    1.146538   0.890587         690         0.0100       0.0001   \n",
       "0    15    0.976041   0.902526         460         0.0100      0.00001   \n",
       "0    16    0.990624   0.901371         575         0.0100       0.0001   \n",
       "0    15    1.165698   0.889146         460         0.0100       0.0001   \n",
       "0    14    1.319186   0.982372         690         0.0100      0.00001   \n",
       "0    17    1.110631   0.808146         460         0.0100            0   \n",
       "0    10    1.045783   0.951232         575         0.0100            0   \n",
       "0    17    1.033562   0.969611         575         0.0100      0.00001   \n",
       "0    13    1.088713   1.015451         690         0.0100            0   \n",
       "\n",
       "   accuracy                         sensitivity  \\\n",
       "0  0.870968  [0.95, 0.8125, 0.8461538461538461]   \n",
       "0  0.854839  [0.95, 0.8125, 0.8076923076923077]   \n",
       "0  0.854839  [0.85, 0.8125, 0.8846153846153846]   \n",
       "0  0.838710  [0.85, 0.8125, 0.8461538461538461]   \n",
       "0  0.838710   [0.8, 0.8125, 0.8846153846153846]   \n",
       "0  0.822581  [0.95, 0.8125, 0.7307692307692307]   \n",
       "0  0.822581  [0.95, 0.8125, 0.7307692307692307]   \n",
       "0  0.822581   [0.9, 0.8125, 0.7692307692307693]   \n",
       "0  0.822581  [0.75, 0.8125, 0.8846153846153846]   \n",
       "0  0.806452  [0.95, 0.8125, 0.6923076923076923]   \n",
       "0  0.806452  [0.85, 0.8125, 0.7692307692307693]   \n",
       "0  0.790323  [0.95, 0.8125, 0.6538461538461539]   \n",
       "0  0.790323   [0.9, 0.8125, 0.6923076923076923]   \n",
       "0  0.790323   [0.9, 0.8125, 0.6923076923076923]   \n",
       "0  0.774194   [0.9, 0.8125, 0.6538461538461539]   \n",
       "0  0.774194     [0.7, 0.75, 0.8461538461538461]   \n",
       "0  0.758065   [0.9, 0.8125, 0.6153846153846154]   \n",
       "0  0.725806   [0.9, 0.8125, 0.5384615384615384]   \n",
       "0  0.645161    [0.45, 0.75, 0.7307692307692307]   \n",
       "0  0.629032                   [0.8, 0.625, 0.5]   \n",
       "0  0.612903    [0.45, 0.75, 0.6538461538461539]   \n",
       "0  0.580645  [0.85, 0.625, 0.34615384615384615]   \n",
       "0  0.483871  [0.9, 0.1875, 0.34615384615384615]   \n",
       "0  0.483871  [0.55, 0.625, 0.34615384615384615]   \n",
       "0  0.467742  [0.15, 0.1875, 0.8846153846153846]   \n",
       "0  0.451613   [0.0, 0.1875, 0.9615384615384616]   \n",
       "0  0.451613   [0.0, 0.1875, 0.9615384615384616]   \n",
       "\n",
       "                                         specificity     score  \n",
       "0    [0.975, 0.9361702127659575, 0.8918918918918919]  6.282684  \n",
       "0  [0.9743589743589743, 0.9361702127659575, 0.868...  6.203981  \n",
       "0  [0.9285714285714286, 0.9347826086956522, 0.916...  6.181975  \n",
       "0  [0.926829268292683, 0.9333333333333333, 0.8947...  6.102263  \n",
       "0  [0.9090909090909091, 0.9333333333333333, 0.914...  6.092535  \n",
       "0                [0.9722222222222222, 0.9375, 0.825]  6.050572  \n",
       "0     [0.972972972972973, 0.9361702127659575, 0.825]  6.049993  \n",
       "0   [0.9473684210526315, 0.9375, 0.8421052631578947]  6.031285  \n",
       "0  [0.8888888888888888, 0.9361702127659575, 0.90625]  6.001005  \n",
       "0  [0.9722222222222222, 0.9361702127659575, 0.804...  5.974530  \n",
       "0    [0.925, 0.9361702127659575, 0.8378378378378378]  5.937190  \n",
       "0  [0.9705882352941176, 0.9387755102040817, 0.780...  5.896520  \n",
       "0      [0.9459459459459459, 0.9361702127659575, 0.8]  5.877246  \n",
       "0      [0.9459459459459459, 0.9361702127659575, 0.8]  5.877246  \n",
       "0  [0.9444444444444444, 0.9361702127659575, 0.780...  5.801642  \n",
       "0    [0.8666666666666667, 0.9148936170212766, 0.875]  5.726908  \n",
       "0   [0.9411764705882353, 0.9375, 0.7619047619047619]  5.726530  \n",
       "0  [0.9428571428571428, 0.9333333333333333, 0.727...  5.580231  \n",
       "0     [0.78, 0.9090909090909091, 0.7666666666666667]  5.031688  \n",
       "0  [0.8666666666666667, 0.8775510204081632, 0.711...  5.009361  \n",
       "0     [0.78, 0.8974358974358975, 0.7428571428571429]  4.887042  \n",
       "0  [0.8928571428571429, 0.8775510204081632, 0.638...  4.810505  \n",
       "0  [0.8888888888888888, 0.7758620689655172, 0.645...  4.228109  \n",
       "0  [0.7567567567567568, 0.8775510204081632, 0.552...  4.191964  \n",
       "0     [0.7068965517241379, 0.7592592592592593, 0.75]  3.906013  \n",
       "0     [0.6774193548387096, 0.7758620689655172, 0.75]  3.803933  \n",
       "0     [0.6774193548387096, 0.7758620689655172, 0.75]  3.803933  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate a score from accuracy, sensitivity and specificity wher sensitivity and specificity are a list of 3 values\n",
    "results['score'] = results['accuracy'] + results['sensitivity'].apply(lambda x: sum(x)) + results['specificity'].apply(lambda x: sum(x))\n",
    "#sort by score\n",
    "results = results.sort_values(by=['score'], ascending=False)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
