{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the CSV file into a DataFrame.\n",
    "2. Parse the \"Radiomics\" column, as it contains JSON data.\n",
    "3. Remove columns with the same values across all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(405, 4)\n",
      "(309, 3)\n",
      "(309, 123)\n",
      "(309, 126)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create random seed for reproducibility\n",
    "random_state = 42\n",
    "\n",
    "# Load the data from DF_Radiomics_noduls_with_diagnose.csv\n",
    "file_path = \"DF_Radiomics_noduls_with_diagnose.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "# Convert the 'Labels' column to an integer\n",
    "data['Labels'] = data['Labels'].astype(int)\n",
    "\n",
    "# drop all rows where the label == 0\n",
    "data = data[data.Labels != 0]\n",
    "\n",
    "# Parse the JSON in the 'Radiomics' column\n",
    "data['Radiomics'] = data['Radiomics'].apply(json.loads)\n",
    "\n",
    "# Convert the 'Radiomics' column into separate columns\n",
    "radiomics_data = pd.json_normalize(data['Radiomics'])\n",
    "\n",
    "\n",
    "# Drop the original 'Radiomics' column\n",
    "data = data.drop('Radiomics', axis=1)\n",
    "print(data.shape)\n",
    "\n",
    "print(radiomics_data.shape)\n",
    "\n",
    "# Reset the indices of both DataFrames\n",
    "data = data.reset_index(drop=True)\n",
    "radiomics_data = radiomics_data.reset_index(drop=True)\n",
    "\n",
    "# Combine the data with the new radiomics columns\n",
    "data = pd.concat([data, radiomics_data], axis=1)\n",
    "\n",
    "print(data.shape)\n",
    "# Remove columns with the same value across all rows\n",
    "data = data.loc[:, (data != data.iloc[0]).any()]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient                                                       0\n",
      "Node                                                          0\n",
      "Labels                                                        0\n",
      "diagnostics_Image-original_Hash                               0\n",
      "diagnostics_Image-original_Spacing                            0\n",
      "                                                           ... \n",
      "diagnostics_Configuration_Settings.minimumROISize           309\n",
      "diagnostics_Configuration_Settings.removeOutliers           309\n",
      "diagnostics_Configuration_Settings.resampledPixelSpacing    309\n",
      "diagnostics_Configuration_Settings.resegmentRange           309\n",
      "diagnostics_Configuration_Settings.weightingNorm            309\n",
      "Length: 108, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#show  rows with NaN values\n",
    "data[data.isna().any(axis=1)].head()\n",
    "#count NaN values per column\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient                                                       0\n",
      "Node                                                          0\n",
      "Labels                                                        0\n",
      "diagnostics_Image-original_Hash                               0\n",
      "diagnostics_Image-original_Spacing                            0\n",
      "                                                           ... \n",
      "diagnostics_Configuration_Settings.minimumROISize           309\n",
      "diagnostics_Configuration_Settings.removeOutliers           309\n",
      "diagnostics_Configuration_Settings.resampledPixelSpacing    309\n",
      "diagnostics_Configuration_Settings.resegmentRange           309\n",
      "diagnostics_Configuration_Settings.weightingNorm            309\n",
      "Length: 108, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient\n",
      "Node\n",
      "diagnostics_Image-original_Hash\n",
      "diagnostics_Image-original_Spacing\n",
      "diagnostics_Image-original_Size\n",
      "diagnostics_Mask-original_Hash\n",
      "diagnostics_Mask-original_Spacing\n",
      "diagnostics_Mask-original_Size\n",
      "diagnostics_Mask-original_BoundingBox\n",
      "diagnostics_Mask-original_CenterOfMassIndex\n",
      "diagnostics_Mask-original_CenterOfMass\n",
      "diagnostics_Configuration_Settings.minimumROISize\n",
      "diagnostics_Configuration_Settings.removeOutliers\n",
      "diagnostics_Configuration_Settings.resampledPixelSpacing\n",
      "diagnostics_Configuration_Settings.resegmentRange\n",
      "diagnostics_Configuration_Settings.weightingNorm\n",
      "object\n",
      "(309, 92)\n",
      "(309, 92)\n"
     ]
    }
   ],
   "source": [
    "# if a column is type string, show it\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':\n",
    "        print(col)\n",
    "\n",
    "# type of column diagnostics_Image-original_Spacing\n",
    "print(data['diagnostics_Image-original_Spacing'].dtype)\n",
    "\n",
    "#remove all columns with type string\n",
    "data = data.select_dtypes(exclude=['object'])\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "#explode all columns with type object\n",
    "data = data.apply(pd.Series.explode).reset_index(drop=True)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 121)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all rows with NaN values\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234, 121)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a stratified split\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_data, test_data \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Save the data to CSV files\u001b[39;00m\n\u001b[1;32m      5\u001b[0m train_data\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDF_Radiomics_noduls_with_diagnose_train_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Medical_image/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/Medical_image/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2670\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2666\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[1;32m   2668\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m-> 2670\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2672\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2673\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m   2674\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m   2675\u001b[0m     )\n\u001b[1;32m   2676\u001b[0m )\n",
      "File \u001b[0;32m~/Medical_image/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2229\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2196\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m   2197\u001b[0m \n\u001b[1;32m   2198\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2227\u001b[0m \u001b[38;5;124;03m    to an integer.\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2229\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n",
      "File \u001b[0;32m~/Medical_image/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    952\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    954\u001b[0m         )\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 957\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/Medical_image/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Medical_image/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "# Create a stratified split\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['Labels'])\n",
    "\n",
    "# Save the data to CSV files\n",
    "train_data.to_csv('DF_Radiomics_noduls_with_diagnose_train_data.csv', index=False)\n",
    "test_data.to_csv('DF_Radiomics_noduls_with_diagnose_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Node</th>\n",
       "      <th>Labels</th>\n",
       "      <th>diagnostics_Image-original_Hash</th>\n",
       "      <th>diagnostics_Image-original_Spacing</th>\n",
       "      <th>diagnostics_Image-original_Size</th>\n",
       "      <th>diagnostics_Image-original_Mean</th>\n",
       "      <th>diagnostics_Image-original_Minimum</th>\n",
       "      <th>diagnostics_Image-original_Maximum</th>\n",
       "      <th>diagnostics_Mask-original_Hash</th>\n",
       "      <th>...</th>\n",
       "      <th>original_gldm_LargeDependenceLowGrayLevelEmphasis</th>\n",
       "      <th>original_gldm_LowGrayLevelEmphasis</th>\n",
       "      <th>original_gldm_SmallDependenceEmphasis</th>\n",
       "      <th>original_gldm_SmallDependenceHighGrayLevelEmphasis</th>\n",
       "      <th>original_gldm_SmallDependenceLowGrayLevelEmphasis</th>\n",
       "      <th>diagnostics_Configuration_Settings.minimumROISize</th>\n",
       "      <th>diagnostics_Configuration_Settings.removeOutliers</th>\n",
       "      <th>diagnostics_Configuration_Settings.resampledPixelSpacing</th>\n",
       "      <th>diagnostics_Configuration_Settings.resegmentRange</th>\n",
       "      <th>diagnostics_Configuration_Settings.weightingNorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIDC-IDRI-0068</td>\n",
       "      <td>Node_N1</td>\n",
       "      <td>3</td>\n",
       "      <td>bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28</td>\n",
       "      <td>[0.683594, 0.683594, 1.25]</td>\n",
       "      <td>[512, 512, 261]</td>\n",
       "      <td>-1026.065264</td>\n",
       "      <td>-3024.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>0506d1d0d6522eddd1640c8ea75c2fc5a9266270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053875</td>\n",
       "      <td>0.021012</td>\n",
       "      <td>0.488461</td>\n",
       "      <td>152.929922</td>\n",
       "      <td>0.019809</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIDC-IDRI-0068</td>\n",
       "      <td>Node_N1</td>\n",
       "      <td>3</td>\n",
       "      <td>bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28</td>\n",
       "      <td>[0.683594, 0.683594, 1.25]</td>\n",
       "      <td>[512, 512, 261]</td>\n",
       "      <td>-1026.065264</td>\n",
       "      <td>-3024.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>9d7da356d43e2f7ad7f374f6c193e97f6088d7c7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110650</td>\n",
       "      <td>0.024328</td>\n",
       "      <td>0.494688</td>\n",
       "      <td>165.356306</td>\n",
       "      <td>0.010062</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Patient     Node  Labels           diagnostics_Image-original_Hash  \\\n",
       "0  LIDC-IDRI-0068  Node_N1       3  bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28   \n",
       "1  LIDC-IDRI-0068  Node_N1       3  bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28   \n",
       "\n",
       "  diagnostics_Image-original_Spacing diagnostics_Image-original_Size  \\\n",
       "0         [0.683594, 0.683594, 1.25]                 [512, 512, 261]   \n",
       "1         [0.683594, 0.683594, 1.25]                 [512, 512, 261]   \n",
       "\n",
       "   diagnostics_Image-original_Mean  diagnostics_Image-original_Minimum  \\\n",
       "0                     -1026.065264                             -3024.0   \n",
       "1                     -1026.065264                             -3024.0   \n",
       "\n",
       "   diagnostics_Image-original_Maximum  \\\n",
       "0                              3071.0   \n",
       "1                              3071.0   \n",
       "\n",
       "             diagnostics_Mask-original_Hash  ...  \\\n",
       "0  0506d1d0d6522eddd1640c8ea75c2fc5a9266270  ...   \n",
       "1  9d7da356d43e2f7ad7f374f6c193e97f6088d7c7  ...   \n",
       "\n",
       "  original_gldm_LargeDependenceLowGrayLevelEmphasis  \\\n",
       "0                                          0.053875   \n",
       "1                                          0.110650   \n",
       "\n",
       "  original_gldm_LowGrayLevelEmphasis original_gldm_SmallDependenceEmphasis  \\\n",
       "0                           0.021012                              0.488461   \n",
       "1                           0.024328                              0.494688   \n",
       "\n",
       "   original_gldm_SmallDependenceHighGrayLevelEmphasis  \\\n",
       "0                                         152.929922    \n",
       "1                                         165.356306    \n",
       "\n",
       "   original_gldm_SmallDependenceLowGrayLevelEmphasis  \\\n",
       "0                                           0.019809   \n",
       "1                                           0.010062   \n",
       "\n",
       "  diagnostics_Configuration_Settings.minimumROISize  \\\n",
       "0                                              None   \n",
       "1                                              None   \n",
       "\n",
       "  diagnostics_Configuration_Settings.removeOutliers  \\\n",
       "0                                              None   \n",
       "1                                              None   \n",
       "\n",
       "   diagnostics_Configuration_Settings.resampledPixelSpacing  \\\n",
       "0                                               None          \n",
       "1                                               None          \n",
       "\n",
       "   diagnostics_Configuration_Settings.resegmentRange  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "\n",
       "   diagnostics_Configuration_Settings.weightingNorm  \n",
       "0                                              None  \n",
       "1                                              None  \n",
       "\n",
       "[2 rows x 108 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (324, 108)\n",
      "Test data: (81, 108)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data:\", train_data.shape)\n",
    "print(\"Test data:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'data' is your pandas DataFrame\n",
    "# Ensure the DataFrame only contains numeric values\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Split data into features and labels\n",
    "X = data.drop('Labels', axis=1).values\n",
    "y = data['Labels'].values\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X).float()\n",
    "y_tensor = torch.tensor(y).float()\n",
    "\n",
    "# Stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, stratify=y_tensor)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: torch.Size([324, 107])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data:\", train_dataset.tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class FCNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FCNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),  # Dropout for regularization\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = train_dataset.tensors[0].shape[1]  # Get the number of features from your dataset\n",
    "hidden_size = 64  # You can tune this\n",
    "output_size = 4   # 4 labels according to the dataset description\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 50  # Adjust based on your runtime requirement\n",
    "clip_value = 1  # for gradient clipping\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = FCNN(input_size, hidden_size, output_size).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)  # L2 regularization\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "#check if cuda is available, print the gpu model name\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cuda\":\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    # Move model to the device\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: nan\n",
      "Epoch 2/50, Loss: nan\n",
      "Epoch 3/50, Loss: nan\n",
      "Epoch 4/50, Loss: nan\n",
      "Epoch 5/50, Loss: nan\n",
      "Epoch 6/50, Loss: nan\n",
      "Epoch 7/50, Loss: nan\n",
      "Epoch 8/50, Loss: nan\n",
      "Epoch 9/50, Loss: nan\n",
      "Epoch 10/50, Loss: nan\n",
      "Epoch 11/50, Loss: nan\n",
      "Epoch 12/50, Loss: nan\n",
      "Epoch 13/50, Loss: nan\n",
      "Epoch 14/50, Loss: nan\n",
      "Epoch 15/50, Loss: nan\n",
      "Epoch 16/50, Loss: nan\n",
      "Epoch 17/50, Loss: nan\n",
      "Epoch 18/50, Loss: nan\n",
      "Epoch 19/50, Loss: nan\n",
      "Epoch 20/50, Loss: nan\n",
      "Epoch 21/50, Loss: nan\n",
      "Epoch 22/50, Loss: nan\n",
      "Epoch 23/50, Loss: nan\n",
      "Epoch 24/50, Loss: nan\n",
      "Epoch 25/50, Loss: nan\n",
      "Epoch 26/50, Loss: nan\n",
      "Epoch 27/50, Loss: nan\n",
      "Epoch 28/50, Loss: nan\n",
      "Epoch 29/50, Loss: nan\n",
      "Epoch 30/50, Loss: nan\n",
      "Epoch 31/50, Loss: nan\n",
      "Epoch 32/50, Loss: nan\n",
      "Epoch 33/50, Loss: nan\n",
      "Epoch 34/50, Loss: nan\n",
      "Epoch 35/50, Loss: nan\n",
      "Epoch 36/50, Loss: nan\n",
      "Epoch 37/50, Loss: nan\n",
      "Epoch 38/50, Loss: nan\n",
      "Epoch 39/50, Loss: nan\n",
      "Epoch 40/50, Loss: nan\n",
      "Epoch 41/50, Loss: nan\n",
      "Epoch 42/50, Loss: nan\n",
      "Epoch 43/50, Loss: nan\n",
      "Epoch 44/50, Loss: nan\n",
      "Epoch 45/50, Loss: nan\n",
      "Epoch 46/50, Loss: nan\n",
      "Epoch 47/50, Loss: nan\n",
      "Epoch 48/50, Loss: nan\n",
      "Epoch 49/50, Loss: nan\n",
      "Epoch 50/50, Loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.fc = nn.Linear(num_features, output_size)  # 'num_output_neurons' is the number of output neurons in your linear layer\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for inputs, targets in train_loader:\n",
    "        # Move inputs and targets to the device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Convert targets to LongTensor\n",
    "        targets = targets.long()\n",
    "\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 23.456790123456788%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# Evaluation function\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Get the index of the max log-probability\n",
    "\n",
    "            total_predictions += targets.size(0)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy\n",
    "\n",
    "# Use the function\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "accuracy = evaluate(model, test_loader, device)\n",
    "print(f'Accuracy: {accuracy * 100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
