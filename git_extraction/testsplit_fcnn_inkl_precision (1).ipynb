{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cntWduXx2FEY"
      },
      "source": [
        "1. Load the CSV file into a DataFrame.\n",
        "2. Parse the \"Radiomics\" column, as it contains JSON data.\n",
        "3. Remove columns with the same values across all rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL48RTMU2FEc",
        "outputId": "9857ce13-0b5c-4872-d4c4-ba51d9126f3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(309, 103)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# create random seed for reproducibility\n",
        "ran_seed = 42\n",
        "\n",
        "# Load the data from DF_Radiomics_noduls_with_diagnose.csv\n",
        "file_path = \"DF_Radiomics_noduls_with_diagnose.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "# Convert the 'Labels' column to an integer\n",
        "data['Labels'] = data['Labels'].astype(int)\n",
        "\n",
        "# drop all rows where the label == 0\n",
        "data = data[data.Labels != 0]\n",
        "\n",
        "# Parse the JSON in the 'Radiomics' column\n",
        "data['Radiomics'] = data['Radiomics'].apply(json.loads)\n",
        "\n",
        "# Convert the 'Radiomics' column into separate columns\n",
        "radiomics_data = pd.json_normalize(data['Radiomics'])\n",
        "\n",
        "\n",
        "# Drop the original 'Radiomics' column\n",
        "data = data.drop('Radiomics', axis=1)\n",
        "\n",
        "\n",
        "# Reset the indices of both DataFrames\n",
        "data = data.reset_index(drop=True)\n",
        "radiomics_data = radiomics_data.reset_index(drop=True)\n",
        "\n",
        "# Combine the data with the new radiomics columns\n",
        "data = pd.concat([data, radiomics_data], axis=1)\n",
        "\n",
        "# Remove columns with the same value across all rows\n",
        "data = data.loc[:, (data != data.iloc[0]).any()]\n",
        "\n",
        "#remove columns with all NaN values\n",
        "data = data.dropna(axis=1, how='all')\n",
        "\n",
        "print(data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "UAVHEmXw2FEh",
        "outputId": "216f0e40-a311-42af-df14-a827900f12fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Patient     Node  Labels           diagnostics_Image-original_Hash  \\\n",
              "0  LIDC-IDRI-0068  Node_N1       3  bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28   \n",
              "1  LIDC-IDRI-0068  Node_N1       3  bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28   \n",
              "2  LIDC-IDRI-0068  Node_N1       3  bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28   \n",
              "3  LIDC-IDRI-0068  Node_N1       3  bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28   \n",
              "4  LIDC-IDRI-0072  Node_N1       1  54705f26f9320581c90452445aa820fe9630d5e9   \n",
              "\n",
              "  diagnostics_Image-original_Spacing diagnostics_Image-original_Size  \\\n",
              "0         [0.683594, 0.683594, 1.25]                 [512, 512, 261]   \n",
              "1         [0.683594, 0.683594, 1.25]                 [512, 512, 261]   \n",
              "2         [0.683594, 0.683594, 1.25]                 [512, 512, 261]   \n",
              "3         [0.683594, 0.683594, 1.25]                 [512, 512, 261]   \n",
              "4         [0.732422, 0.732422, 1.25]                 [512, 512, 305]   \n",
              "\n",
              "   diagnostics_Image-original_Mean  diagnostics_Image-original_Minimum  \\\n",
              "0                     -1026.065264                             -3024.0   \n",
              "1                     -1026.065264                             -3024.0   \n",
              "2                     -1026.065264                             -3024.0   \n",
              "3                     -1026.065264                             -3024.0   \n",
              "4                      -871.936330                             -3024.0   \n",
              "\n",
              "   diagnostics_Image-original_Maximum  \\\n",
              "0                              3071.0   \n",
              "1                              3071.0   \n",
              "2                              3071.0   \n",
              "3                              3071.0   \n",
              "4                              3071.0   \n",
              "\n",
              "             diagnostics_Mask-original_Hash  ...  \\\n",
              "0  0506d1d0d6522eddd1640c8ea75c2fc5a9266270  ...   \n",
              "1  9d7da356d43e2f7ad7f374f6c193e97f6088d7c7  ...   \n",
              "2  c0a43747a23d26b107e21614525f2fd8870ffefc  ...   \n",
              "3  72a09dc3f5d5d146b13402b8ef109422cc3f38a5  ...   \n",
              "4  05efcefff38c73903c3d7839bb987a49176f6068  ...   \n",
              "\n",
              "  original_gldm_GrayLevelNonUniformity original_gldm_GrayLevelVariance  \\\n",
              "0                             7.355556                       60.706173   \n",
              "1                             7.467153                       72.801002   \n",
              "2                             7.685185                       43.527006   \n",
              "3                             6.780220                       35.367709   \n",
              "4                           629.334146                       45.147393   \n",
              "\n",
              "  original_gldm_HighGrayLevelEmphasis  original_gldm_LargeDependenceEmphasis  \\\n",
              "0                          469.644444                              23.444444   \n",
              "1                          471.051095                              17.496350   \n",
              "2                          277.787037                              20.370370   \n",
              "3                          229.219780                              18.780220   \n",
              "4                         1253.131545                              28.918031   \n",
              "\n",
              "   original_gldm_LargeDependenceHighGrayLevelEmphasis  \\\n",
              "0                                       16578.377778    \n",
              "1                                       13573.328467    \n",
              "2                                        9310.490741    \n",
              "3                                        7065.923077    \n",
              "4                                       43475.541623    \n",
              "\n",
              "  original_gldm_LargeDependenceLowGrayLevelEmphasis  \\\n",
              "0                                          0.053875   \n",
              "1                                          0.110650   \n",
              "2                                          0.084481   \n",
              "3                                          0.084783   \n",
              "4                                          0.020967   \n",
              "\n",
              "  original_gldm_LowGrayLevelEmphasis  original_gldm_SmallDependenceEmphasis  \\\n",
              "0                           0.021012                               0.488461   \n",
              "1                           0.024328                               0.494688   \n",
              "2                           0.031811                               0.463956   \n",
              "3                           0.026368                               0.465301   \n",
              "4                           0.001319                               0.262518   \n",
              "\n",
              "   original_gldm_SmallDependenceHighGrayLevelEmphasis  \\\n",
              "0                                         152.929922    \n",
              "1                                         165.356306    \n",
              "2                                          84.174037    \n",
              "3                                          67.725183    \n",
              "4                                         254.476429    \n",
              "\n",
              "   original_gldm_SmallDependenceLowGrayLevelEmphasis  \n",
              "0                                           0.019809  \n",
              "1                                           0.010062  \n",
              "2                                           0.027819  \n",
              "3                                           0.021973  \n",
              "4                                           0.000632  \n",
              "\n",
              "[5 rows x 103 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a52303b6-cc74-4ebc-8a72-ce96aafa6bcd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Patient</th>\n",
              "      <th>Node</th>\n",
              "      <th>Labels</th>\n",
              "      <th>diagnostics_Image-original_Hash</th>\n",
              "      <th>diagnostics_Image-original_Spacing</th>\n",
              "      <th>diagnostics_Image-original_Size</th>\n",
              "      <th>diagnostics_Image-original_Mean</th>\n",
              "      <th>diagnostics_Image-original_Minimum</th>\n",
              "      <th>diagnostics_Image-original_Maximum</th>\n",
              "      <th>diagnostics_Mask-original_Hash</th>\n",
              "      <th>...</th>\n",
              "      <th>original_gldm_GrayLevelNonUniformity</th>\n",
              "      <th>original_gldm_GrayLevelVariance</th>\n",
              "      <th>original_gldm_HighGrayLevelEmphasis</th>\n",
              "      <th>original_gldm_LargeDependenceEmphasis</th>\n",
              "      <th>original_gldm_LargeDependenceHighGrayLevelEmphasis</th>\n",
              "      <th>original_gldm_LargeDependenceLowGrayLevelEmphasis</th>\n",
              "      <th>original_gldm_LowGrayLevelEmphasis</th>\n",
              "      <th>original_gldm_SmallDependenceEmphasis</th>\n",
              "      <th>original_gldm_SmallDependenceHighGrayLevelEmphasis</th>\n",
              "      <th>original_gldm_SmallDependenceLowGrayLevelEmphasis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LIDC-IDRI-0068</td>\n",
              "      <td>Node_N1</td>\n",
              "      <td>3</td>\n",
              "      <td>bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28</td>\n",
              "      <td>[0.683594, 0.683594, 1.25]</td>\n",
              "      <td>[512, 512, 261]</td>\n",
              "      <td>-1026.065264</td>\n",
              "      <td>-3024.0</td>\n",
              "      <td>3071.0</td>\n",
              "      <td>0506d1d0d6522eddd1640c8ea75c2fc5a9266270</td>\n",
              "      <td>...</td>\n",
              "      <td>7.355556</td>\n",
              "      <td>60.706173</td>\n",
              "      <td>469.644444</td>\n",
              "      <td>23.444444</td>\n",
              "      <td>16578.377778</td>\n",
              "      <td>0.053875</td>\n",
              "      <td>0.021012</td>\n",
              "      <td>0.488461</td>\n",
              "      <td>152.929922</td>\n",
              "      <td>0.019809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LIDC-IDRI-0068</td>\n",
              "      <td>Node_N1</td>\n",
              "      <td>3</td>\n",
              "      <td>bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28</td>\n",
              "      <td>[0.683594, 0.683594, 1.25]</td>\n",
              "      <td>[512, 512, 261]</td>\n",
              "      <td>-1026.065264</td>\n",
              "      <td>-3024.0</td>\n",
              "      <td>3071.0</td>\n",
              "      <td>9d7da356d43e2f7ad7f374f6c193e97f6088d7c7</td>\n",
              "      <td>...</td>\n",
              "      <td>7.467153</td>\n",
              "      <td>72.801002</td>\n",
              "      <td>471.051095</td>\n",
              "      <td>17.496350</td>\n",
              "      <td>13573.328467</td>\n",
              "      <td>0.110650</td>\n",
              "      <td>0.024328</td>\n",
              "      <td>0.494688</td>\n",
              "      <td>165.356306</td>\n",
              "      <td>0.010062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LIDC-IDRI-0068</td>\n",
              "      <td>Node_N1</td>\n",
              "      <td>3</td>\n",
              "      <td>bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28</td>\n",
              "      <td>[0.683594, 0.683594, 1.25]</td>\n",
              "      <td>[512, 512, 261]</td>\n",
              "      <td>-1026.065264</td>\n",
              "      <td>-3024.0</td>\n",
              "      <td>3071.0</td>\n",
              "      <td>c0a43747a23d26b107e21614525f2fd8870ffefc</td>\n",
              "      <td>...</td>\n",
              "      <td>7.685185</td>\n",
              "      <td>43.527006</td>\n",
              "      <td>277.787037</td>\n",
              "      <td>20.370370</td>\n",
              "      <td>9310.490741</td>\n",
              "      <td>0.084481</td>\n",
              "      <td>0.031811</td>\n",
              "      <td>0.463956</td>\n",
              "      <td>84.174037</td>\n",
              "      <td>0.027819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LIDC-IDRI-0068</td>\n",
              "      <td>Node_N1</td>\n",
              "      <td>3</td>\n",
              "      <td>bea2c9750ea59a0bebb6d3bd63ffacc40fcf6a28</td>\n",
              "      <td>[0.683594, 0.683594, 1.25]</td>\n",
              "      <td>[512, 512, 261]</td>\n",
              "      <td>-1026.065264</td>\n",
              "      <td>-3024.0</td>\n",
              "      <td>3071.0</td>\n",
              "      <td>72a09dc3f5d5d146b13402b8ef109422cc3f38a5</td>\n",
              "      <td>...</td>\n",
              "      <td>6.780220</td>\n",
              "      <td>35.367709</td>\n",
              "      <td>229.219780</td>\n",
              "      <td>18.780220</td>\n",
              "      <td>7065.923077</td>\n",
              "      <td>0.084783</td>\n",
              "      <td>0.026368</td>\n",
              "      <td>0.465301</td>\n",
              "      <td>67.725183</td>\n",
              "      <td>0.021973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LIDC-IDRI-0072</td>\n",
              "      <td>Node_N1</td>\n",
              "      <td>1</td>\n",
              "      <td>54705f26f9320581c90452445aa820fe9630d5e9</td>\n",
              "      <td>[0.732422, 0.732422, 1.25]</td>\n",
              "      <td>[512, 512, 305]</td>\n",
              "      <td>-871.936330</td>\n",
              "      <td>-3024.0</td>\n",
              "      <td>3071.0</td>\n",
              "      <td>05efcefff38c73903c3d7839bb987a49176f6068</td>\n",
              "      <td>...</td>\n",
              "      <td>629.334146</td>\n",
              "      <td>45.147393</td>\n",
              "      <td>1253.131545</td>\n",
              "      <td>28.918031</td>\n",
              "      <td>43475.541623</td>\n",
              "      <td>0.020967</td>\n",
              "      <td>0.001319</td>\n",
              "      <td>0.262518</td>\n",
              "      <td>254.476429</td>\n",
              "      <td>0.000632</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 103 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a52303b6-cc74-4ebc-8a72-ce96aafa6bcd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a52303b6-cc74-4ebc-8a72-ce96aafa6bcd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a52303b6-cc74-4ebc-8a72-ce96aafa6bcd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-76b4af6f-ab8f-4f47-9d02-a25afa68bc57\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76b4af6f-ab8f-4f47-9d02-a25afa68bc57')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-76b4af6f-ab8f-4f47-9d02-a25afa68bc57 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uZS49RDZ2FEi"
      },
      "outputs": [],
      "source": [
        "#remove hash columns\n",
        "data = data.drop(['diagnostics_Image-original_Hash', 'diagnostics_Mask-original_Hash'], axis=1)\n",
        "\n",
        "# ok looks like all the objeckt columns except of \"Patient\" & \"Node\" are in this form [0.683594, 0.683594, 1.25] which is a list of multiple floats\n",
        "# exploade them into multiple columns\n",
        "\n",
        "object_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Remove 'Patient' and 'Node' from the list\n",
        "object_columns.remove('Patient')\n",
        "object_columns.remove('Node')\n",
        "\n",
        "# Explode the lists in each object column into multiple columns\n",
        "for column in object_columns:\n",
        "    # Convert each list to a Series and expand it into multiple columns\n",
        "    expanded_columns = data[column].apply(pd.Series)\n",
        "\n",
        "    # Rename the expanded columns to have the original column name as a prefix\n",
        "    expanded_columns = expanded_columns.rename(columns=lambda x: f\"{column}_{x}\")\n",
        "\n",
        "    # Drop the original column from the DataFrame\n",
        "    data = data.drop(column, axis=1)\n",
        "\n",
        "    # Concatenate the expanded columns to the DataFrame\n",
        "    data = pd.concat([data, expanded_columns], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CiQxD8jA2FEi"
      },
      "outputs": [],
      "source": [
        "# Create a stratified split\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['Labels'], random_state=ran_seed)\n",
        "\n",
        "# if the files already exist, skip this step\n",
        "if os.path.isfile('DF_Radiomics_noduls_with_diagnose_train_data.csv') and os.path.isfile('DF_Radiomics_noduls_with_diagnose_test_data.csv'):\n",
        "    print(\"Files already exist, skipping this step\")\n",
        "else:\n",
        "    # Save the data to CSV files\n",
        "    train_data.to_csv('DF_Radiomics_noduls_with_diagnose_train_data.csv', index=False)\n",
        "    test_data.to_csv('DF_Radiomics_noduls_with_diagnose_test_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am061hHL2FEj",
        "outputId": "cb75f4eb-daac-40ff-ecab-3d4910da397c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: (247, 118)\n",
            "Test data: (62, 118)\n"
          ]
        }
      ],
      "source": [
        "print(\"Train data:\", train_data.shape)\n",
        "print(\"Test data:\", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "QARkvo4B2FEk",
        "outputId": "88929001-dc06-4575-ff5b-46fa99b03594"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Patient     Node  Labels  diagnostics_Image-original_Mean  \\\n",
              "23   LIDC-IDRI-0137  Node_N1       3                      -671.885608   \n",
              "263  LIDC-IDRI-0377  Node_N1       2                      -882.321409   \n",
              "44   LIDC-IDRI-0167  Node_N1       1                      -664.766231   \n",
              "219  LIDC-IDRI-0272  Node_N1       3                      -824.358062   \n",
              "143  LIDC-IDRI-0234  Node_N1       1                      -708.012378   \n",
              "\n",
              "     diagnostics_Image-original_Minimum  diagnostics_Image-original_Maximum  \\\n",
              "23                              -2048.0                              3071.0   \n",
              "263                             -3024.0                              3071.0   \n",
              "44                              -2048.0                              3071.0   \n",
              "219                             -2048.0                              3071.0   \n",
              "143                             -2048.0                              3029.0   \n",
              "\n",
              "     diagnostics_Mask-original_VoxelNum  diagnostics_Mask-original_VolumeNum  \\\n",
              "23                                   26                                    1   \n",
              "263                                2402                                    1   \n",
              "44                                   56                                    1   \n",
              "219                                  51                                    1   \n",
              "143                                 251                                    1   \n",
              "\n",
              "     original_firstorder_10Percentile  original_firstorder_90Percentile  ...  \\\n",
              "23                              175.5                             850.5  ...   \n",
              "263                            -307.0                              61.0  ...   \n",
              "44                             -444.5                             -66.5  ...   \n",
              "219                            -447.0                             102.0  ...   \n",
              "143                            -569.0                              82.0  ...   \n",
              "\n",
              "     diagnostics_Mask-original_BoundingBox_2  \\\n",
              "23                                        30   \n",
              "263                                      169   \n",
              "44                                        50   \n",
              "219                                       81   \n",
              "143                                       41   \n",
              "\n",
              "     diagnostics_Mask-original_BoundingBox_3  \\\n",
              "23                                         4   \n",
              "263                                       29   \n",
              "44                                         6   \n",
              "219                                        6   \n",
              "143                                       11   \n",
              "\n",
              "     diagnostics_Mask-original_BoundingBox_4  \\\n",
              "23                                         6   \n",
              "263                                       24   \n",
              "44                                         9   \n",
              "219                                        7   \n",
              "143                                       14   \n",
              "\n",
              "     diagnostics_Mask-original_BoundingBox_5  \\\n",
              "23                                         2   \n",
              "263                                        9   \n",
              "44                                         2   \n",
              "219                                        2   \n",
              "143                                        3   \n",
              "\n",
              "     diagnostics_Mask-original_CenterOfMassIndex_0  \\\n",
              "23                                      332.692308   \n",
              "263                                     382.402998   \n",
              "44                                       70.267857   \n",
              "219                                     209.313725   \n",
              "143                                     367.756972   \n",
              "\n",
              "     diagnostics_Mask-original_CenterOfMassIndex_1  \\\n",
              "23                                      389.538462   \n",
              "263                                     308.854288   \n",
              "44                                      174.964286   \n",
              "219                                     390.941176   \n",
              "143                                     310.848606   \n",
              "\n",
              "     diagnostics_Mask-original_CenterOfMassIndex_2  \\\n",
              "23                                       30.307692   \n",
              "263                                     173.039550   \n",
              "44                                       50.321429   \n",
              "219                                      81.568627   \n",
              "143                                      41.689243   \n",
              "\n",
              "     diagnostics_Mask-original_CenterOfMass_0  \\\n",
              "23                                  53.215868   \n",
              "263                                 92.739302   \n",
              "44                                -136.237780   \n",
              "219                                -47.673652   \n",
              "143                                 65.179121   \n",
              "\n",
              "     diagnostics_Mask-original_CenterOfMass_1  \\\n",
              "23                                  83.626926   \n",
              "263                                 28.898399   \n",
              "44                                 -53.812866   \n",
              "219                                 80.722794   \n",
              "143                                 43.765426   \n",
              "\n",
              "     diagnostics_Mask-original_CenterOfMass_2  \n",
              "23                                -321.730769  \n",
              "263                                -68.460564  \n",
              "44                                -234.696429  \n",
              "219                               -109.078431  \n",
              "143                               -236.276892  \n",
              "\n",
              "[5 rows x 118 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7e8a048-24dc-43d8-9cf0-0d214687203e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Patient</th>\n",
              "      <th>Node</th>\n",
              "      <th>Labels</th>\n",
              "      <th>diagnostics_Image-original_Mean</th>\n",
              "      <th>diagnostics_Image-original_Minimum</th>\n",
              "      <th>diagnostics_Image-original_Maximum</th>\n",
              "      <th>diagnostics_Mask-original_VoxelNum</th>\n",
              "      <th>diagnostics_Mask-original_VolumeNum</th>\n",
              "      <th>original_firstorder_10Percentile</th>\n",
              "      <th>original_firstorder_90Percentile</th>\n",
              "      <th>...</th>\n",
              "      <th>diagnostics_Mask-original_BoundingBox_2</th>\n",
              "      <th>diagnostics_Mask-original_BoundingBox_3</th>\n",
              "      <th>diagnostics_Mask-original_BoundingBox_4</th>\n",
              "      <th>diagnostics_Mask-original_BoundingBox_5</th>\n",
              "      <th>diagnostics_Mask-original_CenterOfMassIndex_0</th>\n",
              "      <th>diagnostics_Mask-original_CenterOfMassIndex_1</th>\n",
              "      <th>diagnostics_Mask-original_CenterOfMassIndex_2</th>\n",
              "      <th>diagnostics_Mask-original_CenterOfMass_0</th>\n",
              "      <th>diagnostics_Mask-original_CenterOfMass_1</th>\n",
              "      <th>diagnostics_Mask-original_CenterOfMass_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>LIDC-IDRI-0137</td>\n",
              "      <td>Node_N1</td>\n",
              "      <td>3</td>\n",
              "      <td>-671.885608</td>\n",
              "      <td>-2048.0</td>\n",
              "      <td>3071.0</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>175.5</td>\n",
              "      <td>850.5</td>\n",
              "      <td>...</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>332.692308</td>\n",
              "      <td>389.538462</td>\n",
              "      <td>30.307692</td>\n",
              "      <td>53.215868</td>\n",
              "      <td>83.626926</td>\n",
              "      <td>-321.730769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>LIDC-IDRI-0377</td>\n",
              "      <td>Node_N1</td>\n",
              "      <td>2</td>\n",
              "      <td>-882.321409</td>\n",
              "      <td>-3024.0</td>\n",
              "      <td>3071.0</td>\n",
              "      <td>2402</td>\n",
              "      <td>1</td>\n",
              "      <td>-307.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>...</td>\n",
              "      <td>169</td>\n",
              "      <td>29</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>382.402998</td>\n",
              "      <td>308.854288</td>\n",
              "      <td>173.039550</td>\n",
              "      <td>92.739302</td>\n",
              "      <td>28.898399</td>\n",
              "      <td>-68.460564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>LIDC-IDRI-0167</td>\n",
              "      <td>Node_N1</td>\n",
              "      <td>1</td>\n",
              "      <td>-664.766231</td>\n",
              "      <td>-2048.0</td>\n",
              "      <td>3071.0</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>-444.5</td>\n",
              "      <td>-66.5</td>\n",
              "      <td>...</td>\n",
              "      <td>50</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>70.267857</td>\n",
              "      <td>174.964286</td>\n",
              "      <td>50.321429</td>\n",
              "      <td>-136.237780</td>\n",
              "      <td>-53.812866</td>\n",
              "      <td>-234.696429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>LIDC-IDRI-0272</td>\n",
              "      <td>Node_N1</td>\n",
              "      <td>3</td>\n",
              "      <td>-824.358062</td>\n",
              "      <td>-2048.0</td>\n",
              "      <td>3071.0</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>-447.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>...</td>\n",
              "      <td>81</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>209.313725</td>\n",
              "      <td>390.941176</td>\n",
              "      <td>81.568627</td>\n",
              "      <td>-47.673652</td>\n",
              "      <td>80.722794</td>\n",
              "      <td>-109.078431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>LIDC-IDRI-0234</td>\n",
              "      <td>Node_N1</td>\n",
              "      <td>1</td>\n",
              "      <td>-708.012378</td>\n",
              "      <td>-2048.0</td>\n",
              "      <td>3029.0</td>\n",
              "      <td>251</td>\n",
              "      <td>1</td>\n",
              "      <td>-569.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>...</td>\n",
              "      <td>41</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>367.756972</td>\n",
              "      <td>310.848606</td>\n",
              "      <td>41.689243</td>\n",
              "      <td>65.179121</td>\n",
              "      <td>43.765426</td>\n",
              "      <td>-236.276892</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 118 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7e8a048-24dc-43d8-9cf0-0d214687203e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7e8a048-24dc-43d8-9cf0-0d214687203e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7e8a048-24dc-43d8-9cf0-0d214687203e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f88f17a6-bc4e-473c-825f-e8a5ef81230f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f88f17a6-bc4e-473c-825f-e8a5ef81230f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f88f17a6-bc4e-473c-825f-e8a5ef81230f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_Fz_OIN2FEk"
      },
      "source": [
        "Scaling the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RcLS7ByB2FEl"
      },
      "outputs": [],
      "source": [
        "# if DF_Radiomics_noduls_with_diagnose_train_data_scaled.csv and DF_Radiomics_noduls_with_diagnose_test_data_scaled.csv already exist, skip this step\n",
        "# otherwise scale the data and save it to CSV files\n",
        "if os.path.isfile('DF_Radiomics_noduls_with_diagnose_train_data_scaled.csv') and os.path.isfile('DF_Radiomics_noduls_with_diagnose_test_data_scaled.csv'):\n",
        "    print(\"Scaled data already exists\")\n",
        "else:\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    # Get all column names\n",
        "    all_columns = train_data.columns.tolist()\n",
        "\n",
        "    # Exclude the first three columns\n",
        "    features = all_columns[3:]\n",
        "\n",
        "    # Create a stratified split\n",
        "    train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['Labels'])\n",
        "\n",
        "    # Create a scaler\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Fit the scaler on the training data and transform both training and test data\n",
        "    train_data[features] = scaler.fit_transform(train_data[features])\n",
        "    test_data[features] = scaler.transform(test_data[features])\n",
        "\n",
        "    # Save the data to CSV files\n",
        "    train_data.to_csv('DF_Radiomics_noduls_with_diagnose_train_data_scaled.csv', index=False)\n",
        "    test_data.to_csv('DF_Radiomics_noduls_with_diagnose_test_data_scaled.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N81JoEut2FEm"
      },
      "source": [
        "# Fully Connected Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "LD3uokiE2FEm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Assuming 'data' is your pandas DataFrame\n",
        "# Ensure the DataFrame only contains numeric values\n",
        "data = pd.read_csv('DF_Radiomics_noduls_with_diagnose_train_data_scaled.csv')\n",
        "#drop patient and node columns\n",
        "data = data.drop(['Patient', 'Node'], axis=1)\n",
        "# TODO maybe add the columns later to see if it helps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js8quVEN2FEn"
      },
      "source": [
        "Trainset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "5SI4GMcr2FEn"
      },
      "outputs": [],
      "source": [
        "# Split data into features and labels\n",
        "X = data.drop('Labels', axis=1).values\n",
        "y = data['Labels'].values\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_tensor = torch.tensor(X).float()\n",
        "y_tensor = torch.tensor(y).float()\n",
        "\n",
        "# Stratified split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, stratify=y_tensor, random_state=ran_seed)\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03uXcMix2FEo",
        "outputId": "4f243cac-e9ea-4469-df50-c4b7bde2c323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: torch.Size([197, 115])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train data:\", train_dataset.tensors[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "iPHt3soL2FEp"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "class FCNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(FCNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),  # Dropout for regularization\n",
        "            nn.Linear(hidden_size, hidden_size*3),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),  # Dropout for regularization\n",
        "            nn.Linear(hidden_size*3, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(hidden_size, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = train_dataset.tensors[0].shape[1]  # Get the number of features from your dataset\n",
        "hidden_size = input_size*2  # You can tune this\n",
        "output_size = 4   # 3 labels\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "epochs = 50  # Adjust based on your runtime requirement\n",
        "early_stopping_factor = 10\n",
        "clip_value = 1  # for gradient clipping\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = FCNN(input_size, hidden_size, output_size).cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)  # L2 regularization\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6VljB5-2FEp",
        "outputId": "f865e0eb-1b16-43d9-ae2d-f826b6a17dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "#check if cuda is available, print the gpu model name\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device.type == \"cuda\":\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    # Move model to the device\n",
        "    model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU335I2g2FEq",
        "outputId": "3579ad61-714e-4a66-9259-73f286142727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 1.2764712061200822\n",
            "Epoch 2/50, Loss: 1.1164940084729875\n",
            "Epoch 3/50, Loss: 1.069572286946433\n",
            "Epoch 4/50, Loss: 1.0010316371917725\n",
            "Epoch 5/50, Loss: 0.8850643294198173\n",
            "Epoch 6/50, Loss: 0.8508239643914359\n",
            "Epoch 7/50, Loss: 0.7754661100251334\n",
            "Epoch 8/50, Loss: 0.7781052333968026\n",
            "Epoch 9/50, Loss: 0.6625750064849854\n",
            "Epoch 10/50, Loss: 0.6034435076372964\n",
            "Epoch 11/50, Loss: 0.5899662588323865\n",
            "Epoch 12/50, Loss: 0.583292692899704\n",
            "Epoch 13/50, Loss: 0.35725148235048565\n",
            "Epoch 14/50, Loss: 0.5620798213141305\n",
            "Epoch 15/50, Loss: 0.35166414082050323\n",
            "Epoch 16/50, Loss: 0.3195797460419791\n",
            "Epoch 17/50, Loss: 0.2029707602092198\n",
            "Epoch 18/50, Loss: 0.2601077790771212\n",
            "Epoch 19/50, Loss: 0.2092943862080574\n",
            "Epoch 20/50, Loss: 0.15212084196640976\n",
            "Epoch 21/50, Loss: 0.13738406715648516\n",
            "Epoch 22/50, Loss: 0.09999799808221203\n",
            "Epoch 23/50, Loss: 0.08991094412548202\n",
            "Epoch 24/50, Loss: 0.05423117269362722\n",
            "Epoch 25/50, Loss: 0.03400894463993609\n",
            "Epoch 26/50, Loss: 0.08408010079126273\n",
            "Epoch 27/50, Loss: 0.09458090494652945\n",
            "Epoch 28/50, Loss: 0.11196854650708181\n",
            "Epoch 29/50, Loss: 0.2181779340441738\n",
            "Early stopping at epoch 30/50, best loss: 0.03400894463993609\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Initialize best loss to infinity for comparison in the first epoch\n",
        "best_loss = float('inf')\n",
        "\n",
        "# Patience counter\n",
        "patience_counter = 0\n",
        "\n",
        "# Patience limit\n",
        "patience_limit = 5\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss = 0\n",
        "    for inputs, targets in train_loader:\n",
        "\n",
        "        # Move inputs and targets to the device\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        targets = targets.long()\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # Average epoch loss\n",
        "    epoch_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "    # If the training loss has improved, save the model and reset the patience counter\n",
        "    if epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        # If the training loss has not improved, increment the patience counter\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience_limit:\n",
        "            print(f\"Early stopping at epoch {epoch+1}/{epochs}, best loss: {best_loss}\")\n",
        "            break\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss}\")\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load('best_model.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKQkb-862FEr"
      },
      "source": [
        "# Evaluate\n",
        "\n",
        "Since Confusion Matrix is 3x3 calculate Sensitivity & Specificity for each class by considering that class as the positive class and the other two as the negative class.\n",
        "\n",
        "Sensitivity, also known as the true positive rate (TPR), measures the proportion of actual positives that are correctly identified as such. In other words, it measures the ability of the model to correctly identify positive instances.\n",
        "\n",
        "Specificity, on the other hand, measures the proportion of actual negatives that are correctly identified as such. It measures the ability of the model to correctly identify negative instances.\n",
        "\n",
        "The false positive rate (FPR) is the complement of specificity. It measures the proportion of actual negatives that are incorrectly identified as positives. In other words, it measures the rate at which the model makes false alarms.\n",
        "\n",
        "Here's how they relate:\n",
        "\n",
        "- TPR = Sensitivity = TP / (TP + FN)\n",
        "- FPR = 1 - Specificity = FP / (FP + TN)\n",
        "- Specificity = TN / (TN + FP)\n",
        "\n",
        "Where:\n",
        "- TP = True Positives\n",
        "- FN = False Negatives\n",
        "- FP = False Positives\n",
        "- TN = True Negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RbYM-akY2FEr"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    all_targets = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculations\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)  # Get the index of the max log-probability\n",
        "\n",
        "            total_predictions += targets.size(0)\n",
        "            correct_predictions += (predicted == targets).sum().item()\n",
        "\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(all_targets, all_predictions)\n",
        "\n",
        "    # Calculate sensitivity and specificity for each class\n",
        "    sensitivity = np.diag(cm) / np.sum(cm, axis = 1)\n",
        "    specificity = (np.sum(cm) - np.sum(cm, axis = 0) - np.sum(cm, axis = 1) + np.diag(cm)) / (np.sum(cm) - np.sum(cm, axis = 0))\n",
        "    precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
        "\n",
        "\n",
        "    return accuracy, sensitivity, specificity, precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdaU5Oez2FEs"
      },
      "source": [
        "## Testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CAYj7Ro2FEt",
        "outputId": "d0f08d1c-ca3d-4bd9-afe8-c05878f8120e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 84.0%\n",
            "Class 0: Sensitivity: 93.75%, Specificity: 96.7741935483871%, Precision: 78.94736842105263%\n",
            "Class 1: Sensitivity: 76.92307692307693%, Specificity: 92.10526315789474%, Precision: 83.33333333333334%\n",
            "Class 2: Sensitivity: 80.95238095238095%, Specificity: 87.09677419354838%, Precision: 89.47368421052632%\n"
          ]
        }
      ],
      "source": [
        "# Use the function\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "accuracy, sensitivity, specificity, precision = evaluate(model, test_loader, device)\n",
        "print(f'Accuracy: {accuracy * 100}%')\n",
        "for i, (sens, spec, prec) in enumerate(zip(sensitivity, specificity, precision)):\n",
        "    print(f'Class {i}: Sensitivity: {sens * 100}%, Specificity: {spec * 100}%, Precision: {prec * 100}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hpL07rV2FEu"
      },
      "source": [
        "## Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKvMpM6I2FEu",
        "outputId": "316a22c9-9240-4b52-d68d-72d349ce3760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 93.54838709677419%\n",
            "Class 0: Sensitivity: 95.0%, Specificity: 97.5609756097561%, Precision: 90.47619047619048%\n",
            "Class 1: Sensitivity: 93.75%, Specificity: 97.87234042553192%, Precision: 100.0%\n",
            "Class 2: Sensitivity: 92.3076923076923%, Specificity: 94.44444444444444%, Precision: 92.3076923076923%\n"
          ]
        }
      ],
      "source": [
        "validation_data = pd.read_csv('DF_Radiomics_noduls_with_diagnose_test_data_scaled.csv')\n",
        "\n",
        "#create the tensor dataset\n",
        "X_test = validation_data.drop(['Patient', 'Node', 'Labels'], axis=1).values\n",
        "y_test = validation_data['Labels'].values\n",
        "validation_dataset = TensorDataset(torch.tensor(X_test).float(), torch.tensor(y_test).float())\n",
        "\n",
        "# Use the function\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
        "accuracy, sensitivity, specificity, precision = evaluate(model, validation_loader, device)\n",
        "print(f'Accuracy: {accuracy * 100}%')\n",
        "for i, (sens, spec, prec) in enumerate(zip(sensitivity, specificity, precision)):\n",
        "    print(f'Class {i}: Sensitivity: {sens * 100}%, Specificity: {spec * 100}%, Precision: {prec * 100}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN8vOF8e2FEv"
      },
      "source": [
        "# Gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWdeWJZt2FEv",
        "outputId": "31598b3b-178b-4729-be4e-9a9964cbbaf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 1.3554297174726213\n",
            "Epoch 2/50, Loss: 1.3358621086393083\n",
            "Epoch 3/50, Loss: 1.2907871689115251\n",
            "Epoch 4/50, Loss: 1.2733120066779\n",
            "Epoch 5/50, Loss: 1.2393259831837244\n",
            "Epoch 6/50, Loss: 1.2022192478179932\n",
            "Epoch 7/50, Loss: 1.1608630418777466\n",
            "Epoch 8/50, Loss: 1.1353511299405779\n",
            "Epoch 9/50, Loss: 1.1137003558022636\n",
            "Epoch 10/50, Loss: 1.0705109579222543\n",
            "Epoch 11/50, Loss: 1.0544582775660925\n",
            "Epoch 12/50, Loss: 1.0286338499614172\n",
            "Epoch 13/50, Loss: 0.9850686107363019\n",
            "Epoch 14/50, Loss: 1.0041164244924272\n",
            "Epoch 15/50, Loss: 0.99050201688494\n",
            "Epoch 16/50, Loss: 0.9508578607014248\n",
            "Epoch 17/50, Loss: 0.9512286867414202\n",
            "Epoch 18/50, Loss: 0.8784484948430743\n",
            "Epoch 19/50, Loss: 0.8971239668982369\n",
            "Epoch 20/50, Loss: 0.879322520324162\n",
            "Epoch 21/50, Loss: 0.9245747327804565\n",
            "Epoch 22/50, Loss: 0.9025287543024335\n",
            "Epoch 23/50, Loss: 0.8493801781109401\n",
            "Epoch 24/50, Loss: 0.8518879243305751\n",
            "Epoch 25/50, Loss: 0.7785953623907906\n",
            "Epoch 26/50, Loss: 0.751436880656651\n",
            "Epoch 27/50, Loss: 0.8032194035393851\n",
            "Epoch 28/50, Loss: 0.7489205173083714\n",
            "Epoch 29/50, Loss: 0.7789715528488159\n",
            "Epoch 30/50, Loss: 0.7725169232913426\n",
            "Epoch 31/50, Loss: 0.8177980610302517\n",
            "Epoch 32/50, Loss: 0.7001365082604545\n",
            "Epoch 33/50, Loss: 0.7083242961338588\n",
            "Epoch 34/50, Loss: 0.7544069545609611\n",
            "Epoch 35/50, Loss: 0.6373202715601239\n",
            "Epoch 36/50, Loss: 0.6101021596363613\n",
            "Epoch 37/50, Loss: 0.6073887944221497\n",
            "Epoch 38/50, Loss: 0.5790689970765796\n",
            "Epoch 39/50, Loss: 0.5865348279476166\n",
            "Epoch 40/50, Loss: 0.5479228837149483\n",
            "Epoch 41/50, Loss: 0.5053301240716662\n",
            "Epoch 42/50, Loss: 0.5407924481800624\n",
            "Epoch 43/50, Loss: 0.5170990143503461\n",
            "Epoch 44/50, Loss: 0.5118776091507503\n",
            "Epoch 45/50, Loss: 0.49149114319256376\n",
            "Epoch 46/50, Loss: 0.4202639992747988\n",
            "Epoch 47/50, Loss: 0.46033954194613863\n",
            "Epoch 48/50, Loss: 0.413744466645377\n",
            "Epoch 49/50, Loss: 0.3618650904723576\n",
            "Epoch 50/50, Loss: 0.40979459030287607\n",
            "Epoch 1/50, Loss: 1.3795577117374964\n",
            "Epoch 2/50, Loss: 1.3474518741880144\n",
            "Epoch 3/50, Loss: 1.3158409084592546\n",
            "Epoch 4/50, Loss: 1.2920250381742204\n",
            "Epoch 5/50, Loss: 1.254696590559823\n",
            "Epoch 6/50, Loss: 1.220935344696045\n",
            "Epoch 7/50, Loss: 1.156131454876491\n",
            "Epoch 8/50, Loss: 1.1381984097617013\n",
            "Epoch 9/50, Loss: 1.1162679025105067\n",
            "Epoch 10/50, Loss: 1.0607995646340507\n",
            "Epoch 11/50, Loss: 1.0459871632712228\n",
            "Epoch 12/50, Loss: 1.0111704894474574\n",
            "Epoch 13/50, Loss: 1.0116115042141505\n",
            "Epoch 14/50, Loss: 0.9844116994312831\n",
            "Epoch 15/50, Loss: 0.9865538563047137\n",
            "Epoch 16/50, Loss: 0.9779193997383118\n",
            "Epoch 17/50, Loss: 0.8687660694122314\n",
            "Epoch 18/50, Loss: 0.8993043558938163\n",
            "Epoch 19/50, Loss: 0.9045323048319135\n",
            "Epoch 20/50, Loss: 0.8488801377160209\n",
            "Epoch 21/50, Loss: 0.8635069217000689\n",
            "Epoch 22/50, Loss: 0.8611442106110709\n",
            "Epoch 23/50, Loss: 0.8516933832849775\n",
            "Epoch 24/50, Loss: 0.7790692448616028\n",
            "Epoch 25/50, Loss: 0.7742873430252075\n",
            "Epoch 26/50, Loss: 0.8477839231491089\n",
            "Epoch 27/50, Loss: 0.788256015096392\n",
            "Epoch 28/50, Loss: 0.7558282273156303\n",
            "Epoch 29/50, Loss: 0.7754185625485012\n",
            "Epoch 30/50, Loss: 0.725418107850211\n",
            "Epoch 31/50, Loss: 0.7267259955406189\n",
            "Epoch 32/50, Loss: 0.6816811220986503\n",
            "Epoch 33/50, Loss: 0.7066260916846139\n",
            "Epoch 34/50, Loss: 0.6848433017730713\n",
            "Epoch 35/50, Loss: 0.6773959015096936\n",
            "Epoch 36/50, Loss: 0.6206400905336652\n",
            "Epoch 37/50, Loss: 0.618421230997358\n",
            "Epoch 38/50, Loss: 0.6063795174871173\n",
            "Epoch 39/50, Loss: 0.6000663893563407\n",
            "Epoch 40/50, Loss: 0.5635137132235936\n",
            "Epoch 41/50, Loss: 0.5361245657716479\n",
            "Epoch 42/50, Loss: 0.5426752482141767\n",
            "Epoch 43/50, Loss: 0.5129792647702354\n",
            "Epoch 44/50, Loss: 0.5033036129815238\n",
            "Epoch 45/50, Loss: 0.4893170211996351\n",
            "Epoch 46/50, Loss: 0.43574486460004536\n",
            "Epoch 47/50, Loss: 0.4808392482144492\n",
            "Epoch 48/50, Loss: 0.4497844619410379\n",
            "Epoch 49/50, Loss: 0.3979973665305546\n",
            "Epoch 50/50, Loss: 0.4248101796422686\n",
            "Epoch 1/50, Loss: 1.3763750110353743\n",
            "Epoch 2/50, Loss: 1.363505823271615\n",
            "Epoch 3/50, Loss: 1.3308158772332328\n",
            "Epoch 4/50, Loss: 1.29822838306427\n",
            "Epoch 5/50, Loss: 1.2676003660474504\n",
            "Epoch 6/50, Loss: 1.2274486677987235\n",
            "Epoch 7/50, Loss: 1.1911577667508806\n",
            "Epoch 8/50, Loss: 1.187246322631836\n",
            "Epoch 9/50, Loss: 1.1397009917667933\n",
            "Epoch 10/50, Loss: 1.0859778778893607\n",
            "Epoch 11/50, Loss: 1.0661725657326835\n",
            "Epoch 12/50, Loss: 1.062082154410226\n",
            "Epoch 13/50, Loss: 1.0811635426112585\n",
            "Epoch 14/50, Loss: 0.9967931509017944\n",
            "Epoch 15/50, Loss: 0.9646621091025216\n",
            "Epoch 16/50, Loss: 0.9776928169386727\n",
            "Epoch 17/50, Loss: 0.9542492628097534\n",
            "Epoch 18/50, Loss: 0.918430004801069\n",
            "Epoch 19/50, Loss: 0.883529816355024\n",
            "Epoch 20/50, Loss: 0.8419589911188398\n",
            "Epoch 21/50, Loss: 0.850783748286111\n",
            "Epoch 22/50, Loss: 0.8844957096236092\n",
            "Epoch 23/50, Loss: 0.8279300161770412\n",
            "Epoch 24/50, Loss: 0.7826820101056781\n",
            "Epoch 25/50, Loss: 0.819769697529929\n",
            "Epoch 26/50, Loss: 0.8381430166108268\n",
            "Epoch 27/50, Loss: 0.7943214007786342\n",
            "Epoch 28/50, Loss: 0.7201012713568551\n",
            "Epoch 29/50, Loss: 0.6921587884426117\n",
            "Epoch 30/50, Loss: 0.7866768922124591\n",
            "Epoch 31/50, Loss: 0.7199581520898002\n",
            "Epoch 32/50, Loss: 0.6756371004240853\n",
            "Epoch 33/50, Loss: 0.7071804574557713\n",
            "Epoch 34/50, Loss: 0.6093380962099347\n",
            "Epoch 35/50, Loss: 0.6727635179247174\n",
            "Epoch 36/50, Loss: 0.6341827511787415\n",
            "Epoch 37/50, Loss: 0.6113770348685128\n",
            "Epoch 38/50, Loss: 0.5958220107214791\n",
            "Epoch 39/50, Loss: 0.6662144448075976\n",
            "Epoch 40/50, Loss: 0.5873512710843768\n",
            "Epoch 41/50, Loss: 0.5287917128631047\n",
            "Epoch 42/50, Loss: 0.577621511050633\n",
            "Epoch 43/50, Loss: 0.5216059599603925\n",
            "Epoch 44/50, Loss: 0.4660368391445705\n",
            "Epoch 45/50, Loss: 0.5081840838704791\n",
            "Epoch 46/50, Loss: 0.4982443239007677\n",
            "Epoch 47/50, Loss: 0.4841785899230412\n",
            "Epoch 48/50, Loss: 0.44381299189158846\n",
            "Epoch 49/50, Loss: 0.4137670653206961\n",
            "Epoch 50/50, Loss: 0.4006270170211792\n",
            "Epoch 1/50, Loss: 1.2618354388645716\n",
            "Epoch 2/50, Loss: 1.0376167808260237\n",
            "Epoch 3/50, Loss: 1.0031313725880213\n",
            "Epoch 4/50, Loss: 0.8720294748033796\n",
            "Epoch 5/50, Loss: 0.7989846595696041\n",
            "Epoch 6/50, Loss: 0.8229816811425346\n",
            "Epoch 7/50, Loss: 0.7200517995016915\n",
            "Epoch 8/50, Loss: 0.6811774628502982\n",
            "Epoch 9/50, Loss: 0.5092839747667313\n",
            "Epoch 10/50, Loss: 0.5474791271345956\n",
            "Epoch 11/50, Loss: 0.5067866316863469\n",
            "Epoch 12/50, Loss: 0.41024793471608845\n",
            "Epoch 13/50, Loss: 0.2934797299759729\n",
            "Epoch 14/50, Loss: 0.3265263651098524\n",
            "Epoch 15/50, Loss: 0.2478566531624113\n",
            "Epoch 16/50, Loss: 0.15988514412726676\n",
            "Epoch 17/50, Loss: 0.1368765128510339\n",
            "Epoch 18/50, Loss: 0.10870492378515857\n",
            "Epoch 19/50, Loss: 0.11448393921766963\n",
            "Epoch 20/50, Loss: 0.0620812749756234\n",
            "Epoch 21/50, Loss: 0.118908602112372\n",
            "Epoch 22/50, Loss: 0.04860680177807808\n",
            "Epoch 23/50, Loss: 0.06242065344538007\n",
            "Epoch 24/50, Loss: 0.055593141221574376\n",
            "Epoch 25/50, Loss: 0.05473094520026019\n",
            "Epoch 26/50, Loss: 0.026354256684758832\n",
            "Epoch 27/50, Loss: 0.02838686792113419\n",
            "Epoch 28/50, Loss: 0.02231229598900037\n",
            "Epoch 29/50, Loss: 0.07992477914584535\n",
            "Epoch 30/50, Loss: 0.03593040783224361\n",
            "Epoch 31/50, Loss: 0.014964264152305467\n",
            "Epoch 32/50, Loss: 0.01864025996266199\n",
            "Epoch 33/50, Loss: 0.013946717222487288\n",
            "Epoch 34/50, Loss: 0.022296055468489482\n",
            "Epoch 35/50, Loss: 0.023011512671863393\n",
            "Epoch 36/50, Loss: 0.030631461679669365\n",
            "Epoch 37/50, Loss: 0.019000830317963846\n",
            "Early stopping at epoch 38/50, best loss: 0.013946717222487288\n",
            "Epoch 1/50, Loss: 1.290713174002511\n",
            "Epoch 2/50, Loss: 1.0920390486717224\n",
            "Epoch 3/50, Loss: 0.9652530040059771\n",
            "Epoch 4/50, Loss: 0.8877693244389125\n",
            "Epoch 5/50, Loss: 0.8394419550895691\n",
            "Epoch 6/50, Loss: 0.8501476560320173\n",
            "Epoch 7/50, Loss: 0.691932567528316\n",
            "Epoch 8/50, Loss: 0.6041817154203143\n",
            "Epoch 9/50, Loss: 0.5752569309302739\n",
            "Epoch 10/50, Loss: 0.4712573971067156\n",
            "Epoch 11/50, Loss: 0.41071174825940815\n",
            "Epoch 12/50, Loss: 0.36464842728206087\n",
            "Epoch 13/50, Loss: 0.2693628211106573\n",
            "Epoch 14/50, Loss: 0.24998972032751357\n",
            "Epoch 15/50, Loss: 0.21666644726480758\n",
            "Epoch 16/50, Loss: 0.16787278013569967\n",
            "Epoch 17/50, Loss: 0.12098099983164243\n",
            "Epoch 18/50, Loss: 0.08270561907972608\n",
            "Epoch 19/50, Loss: 0.07978529858935092\n",
            "Epoch 20/50, Loss: 0.05642991193703243\n",
            "Epoch 21/50, Loss: 0.08575825499636787\n",
            "Epoch 22/50, Loss: 0.07910320901178888\n",
            "Epoch 23/50, Loss: 0.0944662517202752\n",
            "Epoch 24/50, Loss: 0.0689935621672443\n",
            "Early stopping at epoch 25/50, best loss: 0.05642991193703243\n",
            "Epoch 1/50, Loss: 1.2542012078421456\n",
            "Epoch 2/50, Loss: 1.061320926461901\n",
            "Epoch 3/50, Loss: 0.9917804683957782\n",
            "Epoch 4/50, Loss: 0.9493119674069541\n",
            "Epoch 5/50, Loss: 0.8840819852692741\n",
            "Epoch 6/50, Loss: 0.8111974682126727\n",
            "Epoch 7/50, Loss: 0.6652847571032388\n",
            "Epoch 8/50, Loss: 0.6024128411497388\n",
            "Epoch 9/50, Loss: 0.4987384336335318\n",
            "Epoch 10/50, Loss: 0.4774167239665985\n",
            "Epoch 11/50, Loss: 0.3830049229519708\n",
            "Epoch 12/50, Loss: 0.28793410105364664\n",
            "Epoch 13/50, Loss: 0.260143837758473\n",
            "Epoch 14/50, Loss: 0.24471475609711238\n",
            "Epoch 15/50, Loss: 0.2003534510731697\n",
            "Epoch 16/50, Loss: 0.16004553916198866\n",
            "Epoch 17/50, Loss: 0.14458377127136504\n",
            "Epoch 18/50, Loss: 0.07772319494480533\n",
            "Epoch 19/50, Loss: 0.0650921305641532\n",
            "Epoch 20/50, Loss: 0.06522722735202738\n",
            "Epoch 21/50, Loss: 0.049468696982200654\n",
            "Epoch 22/50, Loss: 0.052300792187452316\n",
            "Epoch 23/50, Loss: 0.04334388008075101\n",
            "Epoch 24/50, Loss: 0.028255430848470757\n",
            "Epoch 25/50, Loss: 0.04071715259591916\n",
            "Epoch 26/50, Loss: 0.09608414562951241\n",
            "Epoch 27/50, Loss: 0.07067423397009927\n",
            "Epoch 28/50, Loss: 0.11989854475749391\n",
            "Early stopping at epoch 29/50, best loss: 0.028255430848470757\n",
            "Epoch 1/50, Loss: 1.5618051545960563\n",
            "Epoch 2/50, Loss: 1.1854579448699951\n",
            "Epoch 3/50, Loss: 1.20229549067361\n",
            "Epoch 4/50, Loss: 1.0899735944611686\n",
            "Epoch 5/50, Loss: 1.1954971211297172\n",
            "Epoch 6/50, Loss: 1.0007986000605993\n",
            "Epoch 7/50, Loss: 1.1346669367381506\n",
            "Epoch 8/50, Loss: 1.1222263148852758\n",
            "Epoch 9/50, Loss: 0.9877813969339643\n",
            "Epoch 10/50, Loss: 1.10650691815785\n",
            "Epoch 11/50, Loss: 0.9884582417351859\n",
            "Epoch 12/50, Loss: 0.9617968457085746\n",
            "Epoch 13/50, Loss: 1.0527016009603227\n",
            "Epoch 14/50, Loss: 0.9704997454370771\n",
            "Epoch 15/50, Loss: 0.9554196085248675\n",
            "Epoch 16/50, Loss: 0.9654438325337001\n",
            "Epoch 17/50, Loss: 0.9592394999095372\n",
            "Epoch 18/50, Loss: 0.8971079417637416\n",
            "Epoch 19/50, Loss: 0.8840415222304208\n",
            "Epoch 20/50, Loss: 0.9506648693765912\n",
            "Epoch 21/50, Loss: 0.9009527564048767\n",
            "Epoch 22/50, Loss: 1.0389724629265922\n",
            "Epoch 23/50, Loss: 0.8719256264822823\n",
            "Epoch 24/50, Loss: 0.9393519248281207\n",
            "Epoch 25/50, Loss: 0.9367477893829346\n",
            "Epoch 26/50, Loss: 1.0866668650082179\n",
            "Epoch 27/50, Loss: 0.9511434350694928\n",
            "Early stopping at epoch 28/50, best loss: 0.8719256264822823\n",
            "Epoch 1/50, Loss: 1.5165116957255773\n",
            "Epoch 2/50, Loss: 1.227805427142552\n",
            "Epoch 3/50, Loss: 1.2260842493602209\n",
            "Epoch 4/50, Loss: 1.1082919239997864\n",
            "Epoch 5/50, Loss: 1.0373438681874956\n",
            "Epoch 6/50, Loss: 0.9843518563679287\n",
            "Epoch 7/50, Loss: 1.2146742854799544\n",
            "Epoch 8/50, Loss: 0.9438414829117912\n",
            "Epoch 9/50, Loss: 0.9469474298613412\n",
            "Epoch 10/50, Loss: 0.9009568350655692\n",
            "Epoch 11/50, Loss: 1.00259667634964\n",
            "Epoch 12/50, Loss: 0.9118615048272269\n",
            "Epoch 13/50, Loss: 0.9510367938450405\n",
            "Epoch 14/50, Loss: 0.905859649181366\n",
            "Early stopping at epoch 15/50, best loss: 0.9009568350655692\n",
            "Epoch 1/50, Loss: 1.543766702924456\n",
            "Epoch 2/50, Loss: 1.1414179035595484\n",
            "Epoch 3/50, Loss: 1.1179310934884208\n",
            "Epoch 4/50, Loss: 1.0252246856689453\n",
            "Epoch 5/50, Loss: 1.049531808921269\n",
            "Epoch 6/50, Loss: 1.1415379217692785\n",
            "Epoch 7/50, Loss: 0.9775892155511039\n",
            "Epoch 8/50, Loss: 1.0665027073451452\n",
            "Epoch 9/50, Loss: 1.0343258891786848\n",
            "Epoch 10/50, Loss: 1.0376510109220232\n",
            "Epoch 11/50, Loss: 1.0215825268200465\n",
            "Early stopping at epoch 12/50, best loss: 0.9775892155511039\n",
            "Epoch 1/50, Loss: 1.38003294808524\n",
            "Epoch 2/50, Loss: 1.3370205163955688\n",
            "Epoch 3/50, Loss: 1.2974939857210432\n",
            "Epoch 4/50, Loss: 1.2416349308831351\n",
            "Epoch 5/50, Loss: 1.2055620465959822\n",
            "Epoch 6/50, Loss: 1.1735588141850062\n",
            "Epoch 7/50, Loss: 1.1243851355143957\n",
            "Epoch 8/50, Loss: 1.0782567262649536\n",
            "Epoch 9/50, Loss: 1.0590712172644479\n",
            "Epoch 10/50, Loss: 1.0126708490507943\n",
            "Epoch 11/50, Loss: 1.0008575320243835\n",
            "Epoch 12/50, Loss: 1.0095769677843367\n",
            "Epoch 13/50, Loss: 0.9874148624283927\n",
            "Epoch 14/50, Loss: 0.8904742853982108\n",
            "Epoch 15/50, Loss: 0.956103937966483\n",
            "Epoch 16/50, Loss: 0.8564967257635934\n",
            "Epoch 17/50, Loss: 0.9010883314268929\n",
            "Epoch 18/50, Loss: 0.83519332749503\n",
            "Epoch 19/50, Loss: 0.7920120358467102\n",
            "Epoch 20/50, Loss: 0.8333943997110639\n",
            "Epoch 21/50, Loss: 0.7548721092087882\n",
            "Epoch 22/50, Loss: 0.7713755709784371\n",
            "Epoch 23/50, Loss: 0.732904953616006\n",
            "Epoch 24/50, Loss: 0.7338456341198513\n",
            "Epoch 25/50, Loss: 0.706264785357884\n",
            "Epoch 26/50, Loss: 0.6548638428960528\n",
            "Epoch 27/50, Loss: 0.5751461940152305\n",
            "Epoch 28/50, Loss: 0.6321974524429866\n",
            "Epoch 29/50, Loss: 0.561573543718883\n",
            "Epoch 30/50, Loss: 0.5651531091758183\n",
            "Epoch 31/50, Loss: 0.6326330006122589\n",
            "Epoch 32/50, Loss: 0.5240436622074672\n",
            "Epoch 33/50, Loss: 0.46440415510109495\n",
            "Epoch 34/50, Loss: 0.4743973101888384\n",
            "Epoch 35/50, Loss: 0.4811582437583378\n",
            "Epoch 36/50, Loss: 0.4169003324849265\n",
            "Epoch 37/50, Loss: 0.42765580330576214\n",
            "Epoch 38/50, Loss: 0.40242051652499605\n",
            "Epoch 39/50, Loss: 0.4047679305076599\n",
            "Epoch 40/50, Loss: 0.4503868520259857\n",
            "Epoch 41/50, Loss: 0.3482268920966557\n",
            "Epoch 42/50, Loss: 0.4025793692895344\n",
            "Epoch 43/50, Loss: 0.27912629182849613\n",
            "Epoch 44/50, Loss: 0.32547883902277264\n",
            "Epoch 45/50, Loss: 0.3046437842505319\n",
            "Epoch 46/50, Loss: 0.2557504613484655\n",
            "Epoch 47/50, Loss: 0.22948131497417176\n",
            "Epoch 48/50, Loss: 0.22919649630784988\n",
            "Epoch 49/50, Loss: 0.21478974180562155\n",
            "Epoch 50/50, Loss: 0.1751535353916032\n",
            "Epoch 1/50, Loss: 1.3591935975211007\n",
            "Epoch 2/50, Loss: 1.310116938182286\n",
            "Epoch 3/50, Loss: 1.2745137214660645\n",
            "Epoch 4/50, Loss: 1.2140299081802368\n",
            "Epoch 5/50, Loss: 1.1590405872889928\n",
            "Epoch 6/50, Loss: 1.1359425783157349\n",
            "Epoch 7/50, Loss: 1.104704533304487\n",
            "Epoch 8/50, Loss: 1.084181274686541\n",
            "Epoch 9/50, Loss: 1.0439670426504952\n",
            "Epoch 10/50, Loss: 1.028209958757673\n",
            "Epoch 11/50, Loss: 1.0233213305473328\n",
            "Epoch 12/50, Loss: 0.9391876714570182\n",
            "Epoch 13/50, Loss: 0.9260436381612506\n",
            "Epoch 14/50, Loss: 0.9154087390218463\n",
            "Epoch 15/50, Loss: 0.8800559980528695\n",
            "Epoch 16/50, Loss: 0.8543475525719779\n",
            "Epoch 17/50, Loss: 0.8234846081052508\n",
            "Epoch 18/50, Loss: 0.8472959654671806\n",
            "Epoch 19/50, Loss: 0.8297729407038007\n",
            "Epoch 20/50, Loss: 0.7841479778289795\n",
            "Epoch 21/50, Loss: 0.8060812183788845\n",
            "Epoch 22/50, Loss: 0.8391953110694885\n",
            "Epoch 23/50, Loss: 0.7854716607502529\n",
            "Epoch 24/50, Loss: 0.7671434112957546\n",
            "Epoch 25/50, Loss: 0.7056362799235752\n",
            "Epoch 26/50, Loss: 0.7226956742150443\n",
            "Epoch 27/50, Loss: 0.765211454459599\n",
            "Epoch 28/50, Loss: 0.7768058606556484\n",
            "Epoch 29/50, Loss: 0.6305741156850543\n",
            "Epoch 30/50, Loss: 0.5867534918444497\n",
            "Epoch 31/50, Loss: 0.5558441025870187\n",
            "Epoch 32/50, Loss: 0.6018799458231244\n",
            "Epoch 33/50, Loss: 0.5495085333074842\n",
            "Epoch 34/50, Loss: 0.5692671494824546\n",
            "Epoch 35/50, Loss: 0.5761634537151882\n",
            "Epoch 36/50, Loss: 0.48168832063674927\n",
            "Epoch 37/50, Loss: 0.4649015750203814\n",
            "Epoch 38/50, Loss: 0.4439695307186672\n",
            "Epoch 39/50, Loss: 0.4697029505457197\n",
            "Epoch 40/50, Loss: 0.37582406188760487\n",
            "Epoch 41/50, Loss: 0.4343747411455427\n",
            "Epoch 42/50, Loss: 0.3359527162143162\n",
            "Epoch 43/50, Loss: 0.32888335841042654\n",
            "Epoch 44/50, Loss: 0.3104975180966513\n",
            "Epoch 45/50, Loss: 0.29637389736516134\n",
            "Epoch 46/50, Loss: 0.2767131392444883\n",
            "Epoch 47/50, Loss: 0.27637065947055817\n",
            "Epoch 48/50, Loss: 0.23940902309758322\n",
            "Epoch 49/50, Loss: 0.22914890306336538\n",
            "Epoch 50/50, Loss: 0.28801250032016207\n",
            "Epoch 1/50, Loss: 1.3808408635003226\n",
            "Epoch 2/50, Loss: 1.3221989018576485\n",
            "Epoch 3/50, Loss: 1.2865945441382272\n",
            "Epoch 4/50, Loss: 1.230458208492824\n",
            "Epoch 5/50, Loss: 1.1799778597695487\n",
            "Epoch 6/50, Loss: 1.1255075590951102\n",
            "Epoch 7/50, Loss: 1.102466983454568\n",
            "Epoch 8/50, Loss: 1.0468815224511283\n",
            "Epoch 9/50, Loss: 1.027599913733346\n",
            "Epoch 10/50, Loss: 0.9883483222552708\n",
            "Epoch 11/50, Loss: 0.945176933492933\n",
            "Epoch 12/50, Loss: 0.9389784506389073\n",
            "Epoch 13/50, Loss: 0.9542162077767509\n",
            "Epoch 14/50, Loss: 0.895846562726157\n",
            "Epoch 15/50, Loss: 0.9133898871285575\n",
            "Epoch 16/50, Loss: 0.8370027627263751\n",
            "Epoch 17/50, Loss: 0.8028795037950788\n",
            "Epoch 18/50, Loss: 0.8007003920418876\n",
            "Epoch 19/50, Loss: 0.7956286839076451\n",
            "Epoch 20/50, Loss: 0.7750017472675869\n",
            "Epoch 21/50, Loss: 0.7975310938698905\n",
            "Epoch 22/50, Loss: 0.7616220712661743\n",
            "Epoch 23/50, Loss: 0.6734121441841125\n",
            "Epoch 24/50, Loss: 0.7347667387553624\n",
            "Epoch 25/50, Loss: 0.7036107097353254\n",
            "Epoch 26/50, Loss: 0.7004429612840924\n",
            "Epoch 27/50, Loss: 0.6596646904945374\n",
            "Epoch 28/50, Loss: 0.6104549808161599\n",
            "Epoch 29/50, Loss: 0.6483082728726524\n",
            "Epoch 30/50, Loss: 0.6023203773157937\n",
            "Epoch 31/50, Loss: 0.5756948973451342\n",
            "Epoch 32/50, Loss: 0.5486939804894584\n",
            "Epoch 33/50, Loss: 0.5173268658774239\n",
            "Epoch 34/50, Loss: 0.524766491992133\n",
            "Epoch 35/50, Loss: 0.4681467499051775\n",
            "Epoch 36/50, Loss: 0.48143099461283\n",
            "Epoch 37/50, Loss: 0.44376384786197115\n",
            "Epoch 38/50, Loss: 0.45875512276376995\n",
            "Epoch 39/50, Loss: 0.3604823372193745\n",
            "Epoch 40/50, Loss: 0.40171330315726145\n",
            "Epoch 41/50, Loss: 0.40128583141735624\n",
            "Epoch 42/50, Loss: 0.3876331512417112\n",
            "Epoch 43/50, Loss: 0.3391421969447817\n",
            "Epoch 44/50, Loss: 0.28420652023383547\n",
            "Epoch 45/50, Loss: 0.28068637209279196\n",
            "Epoch 46/50, Loss: 0.2821529677936009\n",
            "Epoch 47/50, Loss: 0.25501951575279236\n",
            "Epoch 48/50, Loss: 0.2885215325014932\n",
            "Epoch 49/50, Loss: 0.22753677942923137\n",
            "Epoch 50/50, Loss: 0.19730206898280553\n",
            "Epoch 1/50, Loss: 1.2032643386295863\n",
            "Epoch 2/50, Loss: 0.9968005248478481\n",
            "Epoch 3/50, Loss: 0.8995545506477356\n",
            "Epoch 4/50, Loss: 0.8638551831245422\n",
            "Epoch 5/50, Loss: 0.8254415222576686\n",
            "Epoch 6/50, Loss: 0.6919603177479335\n",
            "Epoch 7/50, Loss: 0.651942504303796\n",
            "Epoch 8/50, Loss: 0.6342572910445077\n",
            "Epoch 9/50, Loss: 0.5772328291620527\n",
            "Epoch 10/50, Loss: 0.36394493920462473\n",
            "Epoch 11/50, Loss: 0.21837330822433745\n",
            "Epoch 12/50, Loss: 0.29265302206788746\n",
            "Epoch 13/50, Loss: 0.26140766457787584\n",
            "Epoch 14/50, Loss: 0.17903374401586397\n",
            "Epoch 15/50, Loss: 0.19099079072475433\n",
            "Epoch 16/50, Loss: 0.08490597988877978\n",
            "Epoch 17/50, Loss: 0.07283096185087093\n",
            "Epoch 18/50, Loss: 0.07293247458125864\n",
            "Epoch 19/50, Loss: 0.06378591273512159\n",
            "Epoch 20/50, Loss: 0.026947460270353725\n",
            "Epoch 21/50, Loss: 0.07344109591628824\n",
            "Epoch 22/50, Loss: 0.04531288905335324\n",
            "Epoch 23/50, Loss: 0.04296245339459607\n",
            "Epoch 24/50, Loss: 0.18726706172206573\n",
            "Early stopping at epoch 25/50, best loss: 0.026947460270353725\n",
            "Epoch 1/50, Loss: 1.210372771535601\n",
            "Epoch 2/50, Loss: 1.0736469796725683\n",
            "Epoch 3/50, Loss: 0.9210373844419207\n",
            "Epoch 4/50, Loss: 0.8883283564022609\n",
            "Epoch 5/50, Loss: 0.742497844355447\n",
            "Epoch 6/50, Loss: 0.628798885004861\n",
            "Epoch 7/50, Loss: 0.5986100775854928\n",
            "Epoch 8/50, Loss: 0.44104754499026705\n",
            "Epoch 9/50, Loss: 0.4205865263938904\n",
            "Epoch 10/50, Loss: 0.23869425803422928\n",
            "Epoch 11/50, Loss: 0.28354651800223757\n",
            "Epoch 12/50, Loss: 0.24780120381287166\n",
            "Epoch 13/50, Loss: 0.28135558537074495\n",
            "Epoch 14/50, Loss: 0.19047349531735694\n",
            "Epoch 15/50, Loss: 0.5047985496265548\n",
            "Epoch 16/50, Loss: 0.19819245593888418\n",
            "Epoch 17/50, Loss: 0.1736807425373367\n",
            "Epoch 18/50, Loss: 0.32287984767130445\n",
            "Epoch 19/50, Loss: 0.23223087271409376\n",
            "Epoch 20/50, Loss: 0.1781898494809866\n",
            "Epoch 21/50, Loss: 0.09702967393345066\n",
            "Epoch 22/50, Loss: 0.09408734066944037\n",
            "Epoch 23/50, Loss: 0.05694038341087954\n",
            "Epoch 24/50, Loss: 0.024567664484493434\n",
            "Epoch 25/50, Loss: 0.04766749457589218\n",
            "Epoch 26/50, Loss: 0.17833434298102344\n",
            "Epoch 27/50, Loss: 0.0916986840644053\n",
            "Epoch 28/50, Loss: 0.04727433954498598\n",
            "Early stopping at epoch 29/50, best loss: 0.024567664484493434\n",
            "Epoch 1/50, Loss: 1.2387666872569494\n",
            "Epoch 2/50, Loss: 1.0409581746373857\n",
            "Epoch 3/50, Loss: 1.0081045031547546\n",
            "Epoch 4/50, Loss: 0.9284114497048515\n",
            "Epoch 5/50, Loss: 0.7984274285180228\n",
            "Epoch 6/50, Loss: 0.6729870779173714\n",
            "Epoch 7/50, Loss: 0.613813545022692\n",
            "Epoch 8/50, Loss: 0.5417940957205636\n",
            "Epoch 9/50, Loss: 0.47696588720594135\n",
            "Epoch 10/50, Loss: 0.3560149648359844\n",
            "Epoch 11/50, Loss: 0.34104582028729574\n",
            "Epoch 12/50, Loss: 0.21570239535399846\n",
            "Epoch 13/50, Loss: 0.19469772239348718\n",
            "Epoch 14/50, Loss: 0.2328134828380176\n",
            "Epoch 15/50, Loss: 0.14070698565670423\n",
            "Epoch 16/50, Loss: 0.16383262883339608\n",
            "Epoch 17/50, Loss: 0.07176018186977931\n",
            "Epoch 18/50, Loss: 0.10657947829791478\n",
            "Epoch 19/50, Loss: 0.35172735686813084\n",
            "Epoch 20/50, Loss: 0.21862187342984335\n",
            "Epoch 21/50, Loss: 0.14797088157917773\n",
            "Early stopping at epoch 22/50, best loss: 0.07176018186977931\n",
            "Epoch 1/50, Loss: 1.8839770725795202\n",
            "Epoch 2/50, Loss: 1.3243555511747087\n",
            "Epoch 3/50, Loss: 1.1778664078031267\n",
            "Epoch 4/50, Loss: 1.0938432557242257\n",
            "Epoch 5/50, Loss: 1.191433140209743\n",
            "Epoch 6/50, Loss: 1.033938365323203\n",
            "Epoch 7/50, Loss: 1.1309867927006312\n",
            "Epoch 8/50, Loss: 1.0262603078569685\n",
            "Epoch 9/50, Loss: 1.0793228234563554\n",
            "Epoch 10/50, Loss: 0.9813339199338641\n",
            "Epoch 11/50, Loss: 0.9794505153383527\n",
            "Epoch 12/50, Loss: 0.9863765665463039\n",
            "Epoch 13/50, Loss: 1.0079145686967033\n",
            "Epoch 14/50, Loss: 1.1156518799918038\n",
            "Epoch 15/50, Loss: 1.07216511453901\n",
            "Early stopping at epoch 16/50, best loss: 0.9794505153383527\n",
            "Epoch 1/50, Loss: 2.172803214618138\n",
            "Epoch 2/50, Loss: 1.2217695202146257\n",
            "Epoch 3/50, Loss: 1.1157647626740592\n",
            "Epoch 4/50, Loss: 1.196118882724217\n",
            "Epoch 5/50, Loss: 1.2217535291399275\n",
            "Epoch 6/50, Loss: 1.025895552975791\n",
            "Epoch 7/50, Loss: 1.0098657863480704\n",
            "Epoch 8/50, Loss: 1.0607368860925948\n",
            "Epoch 9/50, Loss: 1.0387985025133406\n",
            "Epoch 10/50, Loss: 1.078936619418008\n",
            "Epoch 11/50, Loss: 1.127752159323011\n",
            "Early stopping at epoch 12/50, best loss: 1.0098657863480704\n",
            "Epoch 1/50, Loss: 3.0255695240838185\n",
            "Epoch 2/50, Loss: 1.214068855558123\n",
            "Epoch 3/50, Loss: 1.3959409168788366\n",
            "Epoch 4/50, Loss: 1.1838036264692033\n",
            "Epoch 5/50, Loss: 1.0674357839993067\n",
            "Epoch 6/50, Loss: 0.9487343515668597\n",
            "Epoch 7/50, Loss: 1.0181051322392054\n",
            "Epoch 8/50, Loss: 1.0366142647606986\n",
            "Epoch 9/50, Loss: 1.1098934837750025\n",
            "Epoch 10/50, Loss: 1.0487101333481925\n",
            "Epoch 11/50, Loss: 0.9139912639345441\n",
            "Epoch 12/50, Loss: 1.0156500424657549\n",
            "Epoch 13/50, Loss: 0.9761918953486851\n",
            "Epoch 14/50, Loss: 0.9919247627258301\n",
            "Epoch 15/50, Loss: 0.9765199082238334\n",
            "Early stopping at epoch 16/50, best loss: 0.9139912639345441\n",
            "Epoch 1/50, Loss: 1.361374991280692\n",
            "Epoch 2/50, Loss: 1.2963498319898332\n",
            "Epoch 3/50, Loss: 1.2328682456697737\n",
            "Epoch 4/50, Loss: 1.1962751831327165\n",
            "Epoch 5/50, Loss: 1.144433549472264\n",
            "Epoch 6/50, Loss: 1.0971331255776542\n",
            "Epoch 7/50, Loss: 1.0643718242645264\n",
            "Epoch 8/50, Loss: 1.0506840433393205\n",
            "Epoch 9/50, Loss: 0.9860942959785461\n",
            "Epoch 10/50, Loss: 0.9653572525296893\n",
            "Epoch 11/50, Loss: 0.9434140580041068\n",
            "Epoch 12/50, Loss: 0.8964067101478577\n",
            "Epoch 13/50, Loss: 0.9299053805215018\n",
            "Epoch 14/50, Loss: 0.8446310332843235\n",
            "Epoch 15/50, Loss: 0.8155531883239746\n",
            "Epoch 16/50, Loss: 0.8350177577563694\n",
            "Epoch 17/50, Loss: 0.7468130843979972\n",
            "Epoch 18/50, Loss: 0.7510673403739929\n",
            "Epoch 19/50, Loss: 0.7521095361028399\n",
            "Epoch 20/50, Loss: 0.7231278249195644\n",
            "Epoch 21/50, Loss: 0.6661311686038971\n",
            "Epoch 22/50, Loss: 0.6316989191940853\n",
            "Epoch 23/50, Loss: 0.6177471833569663\n",
            "Epoch 24/50, Loss: 0.614686804158347\n",
            "Epoch 25/50, Loss: 0.576411349432809\n",
            "Epoch 26/50, Loss: 0.5973721785204751\n",
            "Epoch 27/50, Loss: 0.5247782937117985\n",
            "Epoch 28/50, Loss: 0.5412762122494834\n",
            "Epoch 29/50, Loss: 0.45329213993889944\n",
            "Epoch 30/50, Loss: 0.41384006823812214\n",
            "Epoch 31/50, Loss: 0.4528293396745409\n",
            "Epoch 32/50, Loss: 0.41354142342294964\n",
            "Epoch 33/50, Loss: 0.4681499983583178\n",
            "Epoch 34/50, Loss: 0.36225516881261555\n",
            "Epoch 35/50, Loss: 0.365311792918614\n",
            "Epoch 36/50, Loss: 0.2749971864478929\n",
            "Epoch 37/50, Loss: 0.33384932364736286\n",
            "Epoch 38/50, Loss: 0.29216992429324556\n",
            "Epoch 39/50, Loss: 0.21448818487780436\n",
            "Epoch 40/50, Loss: 0.26059468516281675\n",
            "Epoch 41/50, Loss: 0.22564515471458435\n",
            "Epoch 42/50, Loss: 0.21328712148325785\n",
            "Epoch 43/50, Loss: 0.17553327126162394\n",
            "Epoch 44/50, Loss: 0.14253009855747223\n",
            "Epoch 45/50, Loss: 0.16081501969269343\n",
            "Epoch 46/50, Loss: 0.13657633321625845\n",
            "Epoch 47/50, Loss: 0.13904338223593576\n",
            "Epoch 48/50, Loss: 0.13020033655422075\n",
            "Epoch 49/50, Loss: 0.11748674405472619\n",
            "Epoch 50/50, Loss: 0.09846148872748017\n",
            "Epoch 1/50, Loss: 1.3729500600269862\n",
            "Epoch 2/50, Loss: 1.3002911635807581\n",
            "Epoch 3/50, Loss: 1.237043329647609\n",
            "Epoch 4/50, Loss: 1.2028065579278129\n",
            "Epoch 5/50, Loss: 1.1356990507670812\n",
            "Epoch 6/50, Loss: 1.0994010482515608\n",
            "Epoch 7/50, Loss: 1.0446540117263794\n",
            "Epoch 8/50, Loss: 0.9934382438659668\n",
            "Epoch 9/50, Loss: 1.006828444344657\n",
            "Epoch 10/50, Loss: 0.9701278209686279\n",
            "Epoch 11/50, Loss: 0.9726249660764422\n",
            "Epoch 12/50, Loss: 0.9198055352483477\n",
            "Epoch 13/50, Loss: 0.9069777301379612\n",
            "Epoch 14/50, Loss: 0.8627059885433742\n",
            "Epoch 15/50, Loss: 0.8417465857097081\n",
            "Epoch 16/50, Loss: 0.793258684022086\n",
            "Epoch 17/50, Loss: 0.8181086012295314\n",
            "Epoch 18/50, Loss: 0.7482295334339142\n",
            "Epoch 19/50, Loss: 0.7542782511029925\n",
            "Epoch 20/50, Loss: 0.7360439215387616\n",
            "Epoch 21/50, Loss: 0.6869664064475468\n",
            "Epoch 22/50, Loss: 0.6616520668779101\n",
            "Epoch 23/50, Loss: 0.6724444457462856\n",
            "Epoch 24/50, Loss: 0.6299622144017901\n",
            "Epoch 25/50, Loss: 0.6539981705801827\n",
            "Epoch 26/50, Loss: 0.5845217534473964\n",
            "Epoch 27/50, Loss: 0.5879106223583221\n",
            "Epoch 28/50, Loss: 0.5640164911746979\n",
            "Epoch 29/50, Loss: 0.5188747218676976\n",
            "Epoch 30/50, Loss: 0.4839221622262682\n",
            "Epoch 31/50, Loss: 0.3752147597926004\n",
            "Epoch 32/50, Loss: 0.44660334076200214\n",
            "Epoch 33/50, Loss: 0.4414089960711343\n",
            "Epoch 34/50, Loss: 0.3607285235609327\n",
            "Epoch 35/50, Loss: 0.32747706345149447\n",
            "Epoch 36/50, Loss: 0.3296172320842743\n",
            "Epoch 37/50, Loss: 0.2880167599235262\n",
            "Epoch 38/50, Loss: 0.29554103314876556\n",
            "Epoch 39/50, Loss: 0.23205311383519853\n",
            "Epoch 40/50, Loss: 0.2413302276815687\n",
            "Epoch 41/50, Loss: 0.22864967158862523\n",
            "Epoch 42/50, Loss: 0.1972127045903887\n",
            "Epoch 43/50, Loss: 0.18550116888114385\n",
            "Epoch 44/50, Loss: 0.1611320333821433\n",
            "Epoch 45/50, Loss: 0.16324064029114588\n",
            "Epoch 46/50, Loss: 0.14088817898716247\n",
            "Epoch 47/50, Loss: 0.1490823674414839\n",
            "Epoch 48/50, Loss: 0.14206072900976455\n",
            "Epoch 49/50, Loss: 0.11114844440349511\n",
            "Epoch 50/50, Loss: 0.15460921664323127\n",
            "Epoch 1/50, Loss: 1.3597727843693324\n",
            "Epoch 2/50, Loss: 1.3065741573061262\n",
            "Epoch 3/50, Loss: 1.2485284634998866\n",
            "Epoch 4/50, Loss: 1.1940701689038957\n",
            "Epoch 5/50, Loss: 1.1285699265343803\n",
            "Epoch 6/50, Loss: 1.1105728319713049\n",
            "Epoch 7/50, Loss: 1.07734249319349\n",
            "Epoch 8/50, Loss: 1.0241334182875497\n",
            "Epoch 9/50, Loss: 0.9955527016094753\n",
            "Epoch 10/50, Loss: 0.9452546834945679\n",
            "Epoch 11/50, Loss: 0.9580092174666268\n",
            "Epoch 12/50, Loss: 0.9173530851091657\n",
            "Epoch 13/50, Loss: 0.922248831817082\n",
            "Epoch 14/50, Loss: 0.8476812839508057\n",
            "Epoch 15/50, Loss: 0.8470511862209865\n",
            "Epoch 16/50, Loss: 0.8146908027785165\n",
            "Epoch 17/50, Loss: 0.8269164477075849\n",
            "Epoch 18/50, Loss: 0.7857644047055926\n",
            "Epoch 19/50, Loss: 0.717881155865533\n",
            "Epoch 20/50, Loss: 0.7478406599589756\n",
            "Epoch 21/50, Loss: 0.7173689944403512\n",
            "Epoch 22/50, Loss: 0.6886467593056815\n",
            "Epoch 23/50, Loss: 0.6426679577146258\n",
            "Epoch 24/50, Loss: 0.6313389241695404\n",
            "Epoch 25/50, Loss: 0.5552257831607547\n",
            "Epoch 26/50, Loss: 0.5771504896027702\n",
            "Epoch 27/50, Loss: 0.49766855580466135\n",
            "Epoch 28/50, Loss: 0.5557208742414202\n",
            "Epoch 29/50, Loss: 0.4483575097152165\n",
            "Epoch 30/50, Loss: 0.5247281917503902\n",
            "Epoch 31/50, Loss: 0.4542677530220577\n",
            "Epoch 32/50, Loss: 0.42623286162103924\n",
            "Epoch 33/50, Loss: 0.3514767108219011\n",
            "Epoch 34/50, Loss: 0.37293756008148193\n",
            "Epoch 35/50, Loss: 0.41459702593939646\n",
            "Epoch 36/50, Loss: 0.37686681960310253\n",
            "Epoch 37/50, Loss: 0.33348946486200604\n",
            "Epoch 38/50, Loss: 0.2612410879560879\n",
            "Epoch 39/50, Loss: 0.26114348641463686\n",
            "Epoch 40/50, Loss: 0.2563520733799253\n",
            "Epoch 41/50, Loss: 0.22639920668942587\n",
            "Epoch 42/50, Loss: 0.21077857272965567\n",
            "Epoch 43/50, Loss: 0.20117411868912832\n",
            "Epoch 44/50, Loss: 0.25099187876497\n",
            "Epoch 45/50, Loss: 0.17059985335384095\n",
            "Epoch 46/50, Loss: 0.1659099417073386\n",
            "Epoch 47/50, Loss: 0.15473049453326634\n",
            "Epoch 48/50, Loss: 0.12155137157865933\n",
            "Epoch 49/50, Loss: 0.11978306514876229\n",
            "Epoch 50/50, Loss: 0.11422458078180041\n",
            "Epoch 1/50, Loss: 1.196143320628575\n",
            "Epoch 2/50, Loss: 1.1344992348126002\n",
            "Epoch 3/50, Loss: 0.8528148191315787\n",
            "Epoch 4/50, Loss: 0.8777330432619367\n",
            "Epoch 5/50, Loss: 0.8235459327697754\n",
            "Epoch 6/50, Loss: 0.6923240678650993\n",
            "Epoch 7/50, Loss: 0.5885559448174068\n",
            "Epoch 8/50, Loss: 0.5124430315835136\n",
            "Epoch 9/50, Loss: 0.48517307213374544\n",
            "Epoch 10/50, Loss: 0.36012702541691916\n",
            "Epoch 11/50, Loss: 0.2961407782776015\n",
            "Epoch 12/50, Loss: 0.2356755935720035\n",
            "Epoch 13/50, Loss: 0.1965809783765248\n",
            "Epoch 14/50, Loss: 0.12809755972453526\n",
            "Epoch 15/50, Loss: 0.10865902416740678\n",
            "Epoch 16/50, Loss: 0.059612718277743885\n",
            "Epoch 17/50, Loss: 0.028799655215282525\n",
            "Epoch 18/50, Loss: 0.049498194096876044\n",
            "Epoch 19/50, Loss: 0.07372326151068721\n",
            "Epoch 20/50, Loss: 0.08395835308225028\n",
            "Epoch 21/50, Loss: 0.020743141383198754\n",
            "Epoch 22/50, Loss: 0.01715085979334877\n",
            "Epoch 23/50, Loss: 0.033023023046553135\n",
            "Epoch 24/50, Loss: 0.05651432674910341\n",
            "Epoch 25/50, Loss: 0.16293289877441047\n",
            "Epoch 26/50, Loss: 0.12723259057383984\n",
            "Early stopping at epoch 27/50, best loss: 0.01715085979334877\n",
            "Epoch 1/50, Loss: 1.2574622971670968\n",
            "Epoch 2/50, Loss: 0.9808556182043893\n",
            "Epoch 3/50, Loss: 0.897770379270826\n",
            "Epoch 4/50, Loss: 0.9241968052727836\n",
            "Epoch 5/50, Loss: 0.6940286500113351\n",
            "Epoch 6/50, Loss: 0.643940269947052\n",
            "Epoch 7/50, Loss: 0.8096160675798144\n",
            "Epoch 8/50, Loss: 0.48103330390793936\n",
            "Epoch 9/50, Loss: 0.34219710741724285\n",
            "Epoch 10/50, Loss: 0.3244538392339434\n",
            "Epoch 11/50, Loss: 0.21227677166461945\n",
            "Epoch 12/50, Loss: 0.1719934679567814\n",
            "Epoch 13/50, Loss: 0.1488336899450847\n",
            "Epoch 14/50, Loss: 0.19085908042533056\n",
            "Epoch 15/50, Loss: 0.22047395897763117\n",
            "Epoch 16/50, Loss: 0.23919464647769928\n",
            "Epoch 17/50, Loss: 0.12389461376837321\n",
            "Epoch 18/50, Loss: 0.21876258722373418\n",
            "Epoch 19/50, Loss: 0.14351446979812213\n",
            "Epoch 20/50, Loss: 0.1253006782914911\n",
            "Epoch 21/50, Loss: 0.05791478969955018\n",
            "Epoch 22/50, Loss: 0.06587752985901066\n",
            "Epoch 23/50, Loss: 0.060178804876548905\n",
            "Epoch 24/50, Loss: 0.035503596566351395\n",
            "Epoch 25/50, Loss: 0.0407569837822978\n",
            "Epoch 26/50, Loss: 0.04775022134916591\n",
            "Epoch 27/50, Loss: 0.029264558904937336\n",
            "Epoch 28/50, Loss: 0.0971839370898806\n",
            "Epoch 29/50, Loss: 0.10488503479531833\n",
            "Epoch 30/50, Loss: 0.0928351553156972\n",
            "Epoch 31/50, Loss: 0.05471024532536311\n",
            "Early stopping at epoch 32/50, best loss: 0.029264558904937336\n",
            "Epoch 1/50, Loss: 1.2022007874080114\n",
            "Epoch 2/50, Loss: 1.0340820040021623\n",
            "Epoch 3/50, Loss: 0.9401959180831909\n",
            "Epoch 4/50, Loss: 0.7879804117338998\n",
            "Epoch 5/50, Loss: 0.7477941257613046\n",
            "Epoch 6/50, Loss: 0.6198726126125881\n",
            "Epoch 7/50, Loss: 0.5094250653471265\n",
            "Epoch 8/50, Loss: 0.3958806949002402\n",
            "Epoch 9/50, Loss: 0.4384158934865679\n",
            "Epoch 10/50, Loss: 0.2676088511943817\n",
            "Epoch 11/50, Loss: 0.24477217665740422\n",
            "Epoch 12/50, Loss: 0.1927690309073244\n",
            "Epoch 13/50, Loss: 0.20256139444453375\n",
            "Epoch 14/50, Loss: 0.13434751531375305\n",
            "Epoch 15/50, Loss: 0.07647596831832613\n",
            "Epoch 16/50, Loss: 0.09044433072475451\n",
            "Epoch 17/50, Loss: 0.07040610909461975\n",
            "Epoch 18/50, Loss: 0.057499533253056664\n",
            "Epoch 19/50, Loss: 0.04068957069622619\n",
            "Epoch 20/50, Loss: 0.055294217209198644\n",
            "Epoch 21/50, Loss: 0.0502455980250878\n",
            "Epoch 22/50, Loss: 0.07936021352985076\n",
            "Epoch 23/50, Loss: 0.10835790527718407\n",
            "Early stopping at epoch 24/50, best loss: 0.04068957069622619\n",
            "Epoch 1/50, Loss: 3.1082430396761214\n",
            "Epoch 2/50, Loss: 1.5451883929116386\n",
            "Epoch 3/50, Loss: 1.5709906475884574\n",
            "Epoch 4/50, Loss: 1.240216314792633\n",
            "Epoch 5/50, Loss: 1.3931834612573897\n",
            "Epoch 6/50, Loss: 1.0753897854260035\n",
            "Epoch 7/50, Loss: 1.2721680913652693\n",
            "Epoch 8/50, Loss: 1.071932579789843\n",
            "Epoch 9/50, Loss: 1.099072711808341\n",
            "Epoch 10/50, Loss: 1.0678207533700126\n",
            "Epoch 11/50, Loss: 1.1151556287493025\n",
            "Epoch 12/50, Loss: 1.0722404888698034\n",
            "Epoch 13/50, Loss: 1.035658095564161\n",
            "Epoch 14/50, Loss: 1.048427368913378\n",
            "Epoch 15/50, Loss: 1.065542800085885\n",
            "Epoch 16/50, Loss: 1.0394416962351118\n",
            "Epoch 17/50, Loss: 1.0493476390838623\n",
            "Early stopping at epoch 18/50, best loss: 1.035658095564161\n",
            "Epoch 1/50, Loss: 3.0527752467564175\n",
            "Epoch 2/50, Loss: 1.669650844165257\n",
            "Epoch 3/50, Loss: 1.5636638402938843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-22903269d615>:34: RuntimeWarning: invalid value encountered in divide\n",
            "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/50, Loss: 1.2307863065174647\n",
            "Epoch 5/50, Loss: 1.2478564126150948\n",
            "Epoch 6/50, Loss: 1.1621578931808472\n",
            "Epoch 7/50, Loss: 1.1099132980619157\n",
            "Epoch 8/50, Loss: 1.1274420363562447\n",
            "Epoch 9/50, Loss: 1.0910966055733817\n",
            "Epoch 10/50, Loss: 1.0698596239089966\n",
            "Epoch 11/50, Loss: 1.080525585583278\n",
            "Epoch 12/50, Loss: 1.076450867312295\n",
            "Epoch 13/50, Loss: 1.0652915835380554\n",
            "Epoch 14/50, Loss: 1.0953669377735682\n",
            "Epoch 15/50, Loss: 1.0674548574856348\n",
            "Epoch 16/50, Loss: 1.0511126347950526\n",
            "Epoch 17/50, Loss: 1.1036701372691564\n",
            "Epoch 18/50, Loss: 1.0239627361297607\n",
            "Epoch 19/50, Loss: 1.0573028240885054\n",
            "Epoch 20/50, Loss: 1.0776689989226205\n",
            "Epoch 21/50, Loss: 1.070700900895255\n",
            "Epoch 22/50, Loss: 1.044233500957489\n",
            "Early stopping at epoch 23/50, best loss: 1.0239627361297607\n",
            "Epoch 1/50, Loss: 4.19248058114733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-22903269d615>:34: RuntimeWarning: invalid value encountered in divide\n",
            "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50, Loss: 1.2642748866762434\n",
            "Epoch 3/50, Loss: 1.1894644498825073\n",
            "Epoch 4/50, Loss: 1.2097436359950475\n",
            "Epoch 5/50, Loss: 1.0772592255047388\n",
            "Epoch 6/50, Loss: 1.2343097073691232\n",
            "Epoch 7/50, Loss: 1.4132442133767265\n",
            "Epoch 8/50, Loss: 1.248852014541626\n",
            "Epoch 9/50, Loss: 1.0471209372792925\n",
            "Epoch 10/50, Loss: 1.1028304951531547\n",
            "Epoch 11/50, Loss: 1.076323390007019\n",
            "Epoch 12/50, Loss: 1.359334077153887\n",
            "Epoch 13/50, Loss: 1.1198822089603968\n",
            "Early stopping at epoch 14/50, best loss: 1.0471209372792925\n",
            "  epoch  epoch_loss  best_loss hidden_size  learning_rate weight_decay  \\\n",
            "0    49    0.409795   0.361865         345         0.0001            0   \n",
            "0    49    0.424810   0.397997         345         0.0001      0.00001   \n",
            "0    49    0.400627   0.400627         345         0.0001       0.0001   \n",
            "0    37    0.030471   0.013947         345         0.0010            0   \n",
            "0    24    0.107460   0.056430         345         0.0010      0.00001   \n",
            "0    28    0.137882   0.028255         345         0.0010       0.0001   \n",
            "0    27    0.978319   0.871926         345         0.0100            0   \n",
            "0    14    0.950245   0.900957         345         0.0100      0.00001   \n",
            "0    11    0.977758   0.977589         345         0.0100       0.0001   \n",
            "0    49    0.175154   0.175154         460         0.0001            0   \n",
            "0    49    0.288013   0.229149         460         0.0001      0.00001   \n",
            "0    49    0.197302   0.197302         460         0.0001       0.0001   \n",
            "0    24    0.172472   0.026947         460         0.0010            0   \n",
            "0    28    0.106571   0.024568         460         0.0010      0.00001   \n",
            "0    21    0.125465   0.071760         460         0.0010       0.0001   \n",
            "0    15    1.091213   0.979451         460         0.0100            0   \n",
            "0    11    1.050557   1.009866         460         0.0100      0.00001   \n",
            "0    15    0.984137   0.913991         460         0.0100       0.0001   \n",
            "0    49    0.098461   0.098461         575         0.0001            0   \n",
            "0    49    0.154609   0.111148         575         0.0001      0.00001   \n",
            "0    49    0.114225   0.114225         575         0.0001       0.0001   \n",
            "0    26    0.089577   0.017151         575         0.0010            0   \n",
            "0    31    0.127186   0.029265         575         0.0010      0.00001   \n",
            "0    23    0.059654   0.040690         575         0.0010       0.0001   \n",
            "0    17    1.073808   1.035658         575         0.0100            0   \n",
            "0    22    1.038244   1.023963         575         0.0100      0.00001   \n",
            "0    13    1.109291   1.047121         575         0.0100       0.0001   \n",
            "\n",
            "   accuracy                         sensitivity  \\\n",
            "0  0.903226  [0.85, 0.9375, 0.9230769230769231]   \n",
            "0  0.903226  [0.85, 0.9375, 0.9230769230769231]   \n",
            "0  0.887097   [0.8, 0.9375, 0.9230769230769231]   \n",
            "0  0.935484  [0.95, 0.9375, 0.9230769230769231]   \n",
            "0  0.919355   [1.0, 0.9375, 0.8461538461538461]   \n",
            "0  0.951613                  [0.9, 0.9375, 1.0]   \n",
            "0  0.596774    [0.95, 0.5, 0.38461538461538464]   \n",
            "0  0.612903  [0.35, 0.8125, 0.6923076923076923]   \n",
            "0  0.548387   [0.35, 0.125, 0.9615384615384616]   \n",
            "0  0.919355   [0.9, 0.9375, 0.9230769230769231]   \n",
            "0  0.919355  [0.85, 0.9375, 0.9615384615384616]   \n",
            "0  0.870968  [0.85, 0.9375, 0.8461538461538461]   \n",
            "0  0.887097  [0.95, 0.9375, 0.8076923076923077]   \n",
            "0  0.935484                 [0.85, 0.9375, 1.0]   \n",
            "0  0.838710   [0.85, 0.875, 0.8076923076923077]   \n",
            "0  0.548387   [0.1, 0.4375, 0.9615384615384616]   \n",
            "0  0.532258   [0.15, 0.375, 0.9230769230769231]   \n",
            "0  0.564516  [0.35, 0.3125, 0.8846153846153846]   \n",
            "0  0.887097   [0.9, 0.9375, 0.8461538461538461]   \n",
            "0  0.919355  [0.85, 0.9375, 0.9615384615384616]   \n",
            "0  0.887097  [0.85, 0.9375, 0.8846153846153846]   \n",
            "0  0.887097    [0.9, 0.875, 0.8846153846153846]   \n",
            "0  0.854839   [0.8, 0.9375, 0.8461538461538461]   \n",
            "0  0.903226  [0.85, 0.9375, 0.9230769230769231]   \n",
            "0  0.403226     [0.15, 0.0, 0.8461538461538461]   \n",
            "0  0.467742     [0.0, 0.25, 0.9615384615384616]   \n",
            "0  0.451613                   [0.0, 0.125, 1.0]   \n",
            "\n",
            "                                         specificity  \\\n",
            "0  [0.9318181818181818, 0.9782608695652174, 0.941...   \n",
            "0  [0.9318181818181818, 0.9782608695652174, 0.941...   \n",
            "0  [0.9111111111111111, 0.9782608695652174, 0.939...   \n",
            "0  [0.975609756097561, 0.9787234042553191, 0.9444...   \n",
            "0      [1.0, 0.9787234042553191, 0.8974358974358975]   \n",
            "0      [0.9545454545454546, 0.9787234042553191, 1.0]   \n",
            "0  [0.9523809523809523, 0.8518518518518519, 0.673...   \n",
            "0     [0.7291666666666666, 0.9318181818181818, 0.75]   \n",
            "0      [0.7592592592592593, 0.7666666666666667, 0.9]   \n",
            "0  [0.9523809523809523, 0.9787234042553191, 0.942...   \n",
            "0  [0.9318181818181818, 0.9787234042553191, 0.969...   \n",
            "0  [0.9285714285714286, 0.9782608695652174, 0.888...   \n",
            "0  [0.9743589743589743, 0.9782608695652174, 0.871...   \n",
            "0      [0.9333333333333333, 0.9787234042553191, 1.0]   \n",
            "0    [0.925, 0.9574468085106383, 0.8648648648648649]   \n",
            "0                     [0.7, 0.8333333333333334, 0.9]   \n",
            "0  [0.7017543859649122, 0.8181818181818182, 0.833...   \n",
            "0      [0.7547169811320755, 0.8035714285714286, 0.8]   \n",
            "0  [0.9512195121951219, 0.9782608695652174, 0.891...   \n",
            "0  [0.9318181818181818, 0.9787234042553191, 0.969...   \n",
            "0  [0.9302325581395349, 0.9782608695652174, 0.914...   \n",
            "0     [0.95, 0.9583333333333334, 0.9166666666666666]   \n",
            "0  [0.9047619047619048, 0.9782608695652174, 0.888...   \n",
            "0  [0.9302325581395349, 0.9787234042553191, 0.941...   \n",
            "0  [0.6909090909090909, 0.7419354838709677, 0.428...   \n",
            "0      [0.6774193548387096, 0.7894736842105263, 0.8]   \n",
            "0      [0.6774193548387096, 0.7666666666666667, 1.0]   \n",
            "\n",
            "                                           precision  \n",
            "0   [0.9444444444444444, 0.9375, 0.8571428571428571]  \n",
            "0   [0.9444444444444444, 0.9375, 0.8571428571428571]  \n",
            "0   [0.9411764705882353, 0.9375, 0.8275862068965517]  \n",
            "0      [0.9047619047619048, 1.0, 0.9230769230769231]  \n",
            "0      [0.8333333333333334, 1.0, 0.9565217391304348]  \n",
            "0                      [1.0, 1.0, 0.896551724137931]  \n",
            "0      [0.4634146341463415, 1.0, 0.7692307692307693]  \n",
            "0                     [0.5, 0.7222222222222222, 0.6]  \n",
            "0                   [0.875, 1.0, 0.4807692307692308]  \n",
            "0                     [0.9, 1.0, 0.8888888888888888]  \n",
            "0      [0.9444444444444444, 1.0, 0.8620689655172413]  \n",
            "0                 [0.85, 0.9375, 0.8461538461538461]  \n",
            "0   [0.8260869565217391, 0.9375, 0.9130434782608695]  \n",
            "0                     [1.0, 1.0, 0.8666666666666667]  \n",
            "0     [0.7727272727272727, 0.9333333333333333, 0.84]  \n",
            "0                   [1.0, 0.875, 0.4807692307692308]  \n",
            "0                    [0.6, 0.8571428571428571, 0.48]  \n",
            "0  [0.7777777777777778, 0.8333333333333334, 0.489...  \n",
            "0                 [0.8571428571428571, 0.9375, 0.88]  \n",
            "0      [0.9444444444444444, 1.0, 0.8620689655172413]  \n",
            "0   [0.8947368421052632, 0.9375, 0.8518518518518519]  \n",
            "0      [0.8181818181818182, 1.0, 0.8846153846153846]  \n",
            "0                  [0.8, 0.9375, 0.8461538461538461]  \n",
            "0      [0.8947368421052632, 1.0, 0.8571428571428571]  \n",
            "0                    [0.42857142857142855, nan, 0.4]  \n",
            "0                    [nan, 0.8, 0.43859649122807015]  \n",
            "0                    [nan, 1.0, 0.43333333333333335]  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-22903269d615>:34: RuntimeWarning: invalid value encountered in divide\n",
            "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "input_size = train_dataset.tensors[0].shape[1]  # Get the number of features from your dataset\n",
        "output_size = 4   # 3 labels\n",
        "batch_size = 32\n",
        "epochs = 50  # Adjust based on your runtime requirement\n",
        "early_stopping_factor = 10\n",
        "clip_value = 1  # for gradient clipping\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Hyperparameters to tune\n",
        "hidden_sizes = [input_size*3, input_size*4, input_size*5]\n",
        "learning_rates = [0.0001, 0.001, 0.01]\n",
        "weight_decays = [0, 1e-5, 1e-4]  # L2 regularization\n",
        "\n",
        "# Load validation data\n",
        "validation_data = pd.read_csv('DF_Radiomics_noduls_with_diagnose_test_data_scaled.csv')\n",
        "\n",
        "# Create the tensor dataset\n",
        "X_test = validation_data.drop(['Patient', 'Node', 'Labels'], axis=1).values\n",
        "y_test = validation_data['Labels'].values\n",
        "validation_dataset = TensorDataset(torch.tensor(X_test).float(), torch.tensor(y_test).float())\n",
        "\n",
        "# Use the function\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Initialize DataFrame to store results\n",
        "results = pd.DataFrame(columns=[\"epoch\", \"epoch_loss\", \"best_loss\", \"hidden_size\", \"learning_rate\", \"weight_decay\", \"accuracy\", \"sensitivity\", \"specificity\", \"precision\"])\n",
        "\n",
        "# Grid search\n",
        "for hidden_size in hidden_sizes:\n",
        "    for learning_rate in learning_rates:\n",
        "        for weight_decay in weight_decays:\n",
        "            # Initialize model, loss function, and optimizer\n",
        "            model = FCNN(input_size, hidden_size, output_size).cuda()\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "            # DataLoader\n",
        "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "                        # Initialize best loss to infinity for comparison in the first epoch\n",
        "            best_loss = float('inf')\n",
        "\n",
        "            # Patience counter\n",
        "            patience_counter = 0\n",
        "\n",
        "            # Patience limit\n",
        "            patience_limit = 5\n",
        "\n",
        "            # Training loop (as before)...\n",
        "            model.train()\n",
        "            for epoch in range(epochs):\n",
        "                epoch_loss = 0\n",
        "                for inputs, targets in train_loader:\n",
        "\n",
        "                    # Move inputs and targets to the device\n",
        "                    inputs = inputs.to(device)\n",
        "                    targets = targets.to(device)\n",
        "\n",
        "                    targets = targets.long()\n",
        "\n",
        "                    # Zero the gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # Forward pass\n",
        "                    outputs = model(inputs)\n",
        "\n",
        "                    # Compute loss\n",
        "                    loss = criterion(outputs, targets)\n",
        "\n",
        "                    # Backward pass and optimize\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    epoch_loss += loss.item()\n",
        "\n",
        "                # Average epoch loss\n",
        "                epoch_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "                # If the training loss has improved, save the model and reset the patience counter\n",
        "                if epoch_loss < best_loss:\n",
        "                    best_loss = epoch_loss\n",
        "                    patience_counter = 0\n",
        "                    #torch.save(model.state_dict(), 'best_model.pth')\n",
        "                    #change to realtive path according to the hidden size, learning rate and weight decay\n",
        "                    torch.save(model.state_dict(), f'models/best_model_{hidden_size}_{str(learning_rate).replace(\".\", \"_\")}_{weight_decay}.pth')\n",
        "\n",
        "\n",
        "                else:\n",
        "                    # If the training loss has not improved, increment the patience counter\n",
        "                    patience_counter += 1\n",
        "                    if patience_counter >= patience_limit:\n",
        "                        print(f\"Early stopping at epoch {epoch+1}/{epochs}, best loss: {best_loss}\")\n",
        "                        break\n",
        "\n",
        "                print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss}\")\n",
        "\n",
        "            # Load the best model\n",
        "            model.load_state_dict(torch.load(f'models/best_model_{hidden_size}_{str(learning_rate).replace(\".\", \"_\")}_{weight_decay}.pth'))\n",
        "\n",
        "            # Evaluate the model\n",
        "            accuracy, sensitivity, specificity, precision = evaluate(model, validation_loader, device)\n",
        "\n",
        "            # Write results to DataFrame\n",
        "            # Check if results is a DataFrame with concat\n",
        "            results = pd.concat([results, pd.DataFrame([[epoch, epoch_loss, best_loss, hidden_size, learning_rate, weight_decay, accuracy, sensitivity, specificity, precision]], columns=results.columns)])\n",
        "\n",
        "\n",
        "# Print the results\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1542
        },
        "id": "r6kG-fqv2FEw",
        "outputId": "9e2f082d-c8a7-47ba-ef59-8a28652f00fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  epoch  epoch_loss  best_loss hidden_size  learning_rate weight_decay  \\\n",
              "0    28    0.137882   0.028255         345         0.0010       0.0001   \n",
              "0    28    0.106571   0.024568         460         0.0010      0.00001   \n",
              "0    37    0.030471   0.013947         345         0.0010            0   \n",
              "0    24    0.107460   0.056430         345         0.0010      0.00001   \n",
              "0    49    0.154609   0.111148         575         0.0001      0.00001   \n",
              "0    49    0.288013   0.229149         460         0.0001      0.00001   \n",
              "0    49    0.175154   0.175154         460         0.0001            0   \n",
              "0    23    0.059654   0.040690         575         0.0010       0.0001   \n",
              "0    49    0.424810   0.397997         345         0.0001      0.00001   \n",
              "0    49    0.409795   0.361865         345         0.0001            0   \n",
              "0    24    0.172472   0.026947         460         0.0010            0   \n",
              "0    49    0.400627   0.400627         345         0.0001       0.0001   \n",
              "0    26    0.089577   0.017151         575         0.0010            0   \n",
              "0    49    0.098461   0.098461         575         0.0001            0   \n",
              "0    49    0.114225   0.114225         575         0.0001       0.0001   \n",
              "0    49    0.197302   0.197302         460         0.0001       0.0001   \n",
              "0    31    0.127186   0.029265         575         0.0010      0.00001   \n",
              "0    21    0.125465   0.071760         460         0.0010       0.0001   \n",
              "0    27    0.978319   0.871926         345         0.0100            0   \n",
              "0    15    1.091213   0.979451         460         0.0100            0   \n",
              "0    11    0.977758   0.977589         345         0.0100       0.0001   \n",
              "0    14    0.950245   0.900957         345         0.0100      0.00001   \n",
              "0    15    0.984137   0.913991         460         0.0100       0.0001   \n",
              "0    11    1.050557   1.009866         460         0.0100      0.00001   \n",
              "0    17    1.073808   1.035658         575         0.0100            0   \n",
              "0    22    1.038244   1.023963         575         0.0100      0.00001   \n",
              "0    13    1.109291   1.047121         575         0.0100       0.0001   \n",
              "\n",
              "   accuracy                         sensitivity  \\\n",
              "0  0.951613                  [0.9, 0.9375, 1.0]   \n",
              "0  0.935484                 [0.85, 0.9375, 1.0]   \n",
              "0  0.935484  [0.95, 0.9375, 0.9230769230769231]   \n",
              "0  0.919355   [1.0, 0.9375, 0.8461538461538461]   \n",
              "0  0.919355  [0.85, 0.9375, 0.9615384615384616]   \n",
              "0  0.919355  [0.85, 0.9375, 0.9615384615384616]   \n",
              "0  0.919355   [0.9, 0.9375, 0.9230769230769231]   \n",
              "0  0.903226  [0.85, 0.9375, 0.9230769230769231]   \n",
              "0  0.903226  [0.85, 0.9375, 0.9230769230769231]   \n",
              "0  0.903226  [0.85, 0.9375, 0.9230769230769231]   \n",
              "0  0.887097  [0.95, 0.9375, 0.8076923076923077]   \n",
              "0  0.887097   [0.8, 0.9375, 0.9230769230769231]   \n",
              "0  0.887097    [0.9, 0.875, 0.8846153846153846]   \n",
              "0  0.887097   [0.9, 0.9375, 0.8461538461538461]   \n",
              "0  0.887097  [0.85, 0.9375, 0.8846153846153846]   \n",
              "0  0.870968  [0.85, 0.9375, 0.8461538461538461]   \n",
              "0  0.854839   [0.8, 0.9375, 0.8461538461538461]   \n",
              "0  0.838710   [0.85, 0.875, 0.8076923076923077]   \n",
              "0  0.596774    [0.95, 0.5, 0.38461538461538464]   \n",
              "0  0.548387   [0.1, 0.4375, 0.9615384615384616]   \n",
              "0  0.548387   [0.35, 0.125, 0.9615384615384616]   \n",
              "0  0.612903  [0.35, 0.8125, 0.6923076923076923]   \n",
              "0  0.564516  [0.35, 0.3125, 0.8846153846153846]   \n",
              "0  0.532258   [0.15, 0.375, 0.9230769230769231]   \n",
              "0  0.403226     [0.15, 0.0, 0.8461538461538461]   \n",
              "0  0.467742     [0.0, 0.25, 0.9615384615384616]   \n",
              "0  0.451613                   [0.0, 0.125, 1.0]   \n",
              "\n",
              "                                         specificity  \\\n",
              "0      [0.9545454545454546, 0.9787234042553191, 1.0]   \n",
              "0      [0.9333333333333333, 0.9787234042553191, 1.0]   \n",
              "0  [0.975609756097561, 0.9787234042553191, 0.9444...   \n",
              "0      [1.0, 0.9787234042553191, 0.8974358974358975]   \n",
              "0  [0.9318181818181818, 0.9787234042553191, 0.969...   \n",
              "0  [0.9318181818181818, 0.9787234042553191, 0.969...   \n",
              "0  [0.9523809523809523, 0.9787234042553191, 0.942...   \n",
              "0  [0.9302325581395349, 0.9787234042553191, 0.941...   \n",
              "0  [0.9318181818181818, 0.9782608695652174, 0.941...   \n",
              "0  [0.9318181818181818, 0.9782608695652174, 0.941...   \n",
              "0  [0.9743589743589743, 0.9782608695652174, 0.871...   \n",
              "0  [0.9111111111111111, 0.9782608695652174, 0.939...   \n",
              "0     [0.95, 0.9583333333333334, 0.9166666666666666]   \n",
              "0  [0.9512195121951219, 0.9782608695652174, 0.891...   \n",
              "0  [0.9302325581395349, 0.9782608695652174, 0.914...   \n",
              "0  [0.9285714285714286, 0.9782608695652174, 0.888...   \n",
              "0  [0.9047619047619048, 0.9782608695652174, 0.888...   \n",
              "0    [0.925, 0.9574468085106383, 0.8648648648648649]   \n",
              "0  [0.9523809523809523, 0.8518518518518519, 0.673...   \n",
              "0                     [0.7, 0.8333333333333334, 0.9]   \n",
              "0      [0.7592592592592593, 0.7666666666666667, 0.9]   \n",
              "0     [0.7291666666666666, 0.9318181818181818, 0.75]   \n",
              "0      [0.7547169811320755, 0.8035714285714286, 0.8]   \n",
              "0  [0.7017543859649122, 0.8181818181818182, 0.833...   \n",
              "0  [0.6909090909090909, 0.7419354838709677, 0.428...   \n",
              "0      [0.6774193548387096, 0.7894736842105263, 0.8]   \n",
              "0      [0.6774193548387096, 0.7666666666666667, 1.0]   \n",
              "\n",
              "                                           precision     score  \n",
              "0                      [1.0, 1.0, 0.896551724137931]  9.618933  \n",
              "0                     [1.0, 1.0, 0.8666666666666667]  9.501707  \n",
              "0      [0.9047619047619048, 1.0, 0.9230769230769231]  9.472677  \n",
              "0      [0.8333333333333334, 1.0, 0.9565217391304348]  9.369023  \n",
              "0      [0.9444444444444444, 1.0, 0.8620689655172413]  9.355145  \n",
              "0      [0.9444444444444444, 1.0, 0.8620689655172413]  9.355145  \n",
              "0                     [0.9, 1.0, 0.8888888888888888]  9.342782  \n",
              "0      [0.8947368421052632, 1.0, 0.8571428571428571]  9.215815  \n",
              "0   [0.9444444444444444, 0.9375, 0.8571428571428571]  9.204146  \n",
              "0   [0.9444444444444444, 0.9375, 0.8571428571428571]  9.204146  \n",
              "0   [0.8260869565217391, 0.9375, 0.9130434782608695]  9.083334  \n",
              "0   [0.9411764705882353, 0.9375, 0.8275862068965517]  9.082702  \n",
              "0      [0.8181818181818182, 1.0, 0.8846153846153846]  9.074509  \n",
              "0                 [0.8571428571428571, 0.9375, 0.88]  9.066766  \n",
              "0   [0.8947368421052632, 0.9375, 0.8518518518518519]  9.066080  \n",
              "0                 [0.85, 0.9375, 0.8461538461538461]  8.933997  \n",
              "0                  [0.8, 0.9375, 0.8461538461538461]  8.794058  \n",
              "0     [0.7727272727272727, 0.9333333333333333, 0.84]  8.664774  \n",
              "0      [0.4634146341463415, 1.0, 0.7692307692307693]  7.141737  \n",
              "0                   [1.0, 0.875, 0.4807692307692308]  6.836528  \n",
              "0                   [0.875, 1.0, 0.4807692307692308]  6.766621  \n",
              "0                     [0.5, 0.7222222222222222, 0.6]  6.700918  \n",
              "0  [0.7777777777777778, 0.8333333333333334, 0.489...  6.570393  \n",
              "0                    [0.6, 0.8571428571428571, 0.48]  6.270747  \n",
              "0                    [0.42857142857142855, nan, 0.4]       NaN  \n",
              "0                    [nan, 0.8, 0.43859649122807015]       NaN  \n",
              "0                    [nan, 1.0, 0.43333333333333335]       NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-997a3db2-0bcf-4eb8-84e8-5d2c6148ebd4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>epoch_loss</th>\n",
              "      <th>best_loss</th>\n",
              "      <th>hidden_size</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>sensitivity</th>\n",
              "      <th>specificity</th>\n",
              "      <th>precision</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>0.137882</td>\n",
              "      <td>0.028255</td>\n",
              "      <td>345</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.951613</td>\n",
              "      <td>[0.9, 0.9375, 1.0]</td>\n",
              "      <td>[0.9545454545454546, 0.9787234042553191, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 0.896551724137931]</td>\n",
              "      <td>9.618933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>0.106571</td>\n",
              "      <td>0.024568</td>\n",
              "      <td>460</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.935484</td>\n",
              "      <td>[0.85, 0.9375, 1.0]</td>\n",
              "      <td>[0.9333333333333333, 0.9787234042553191, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 0.8666666666666667]</td>\n",
              "      <td>9.501707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37</td>\n",
              "      <td>0.030471</td>\n",
              "      <td>0.013947</td>\n",
              "      <td>345</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0</td>\n",
              "      <td>0.935484</td>\n",
              "      <td>[0.95, 0.9375, 0.9230769230769231]</td>\n",
              "      <td>[0.975609756097561, 0.9787234042553191, 0.9444...</td>\n",
              "      <td>[0.9047619047619048, 1.0, 0.9230769230769231]</td>\n",
              "      <td>9.472677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24</td>\n",
              "      <td>0.107460</td>\n",
              "      <td>0.056430</td>\n",
              "      <td>345</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.919355</td>\n",
              "      <td>[1.0, 0.9375, 0.8461538461538461]</td>\n",
              "      <td>[1.0, 0.9787234042553191, 0.8974358974358975]</td>\n",
              "      <td>[0.8333333333333334, 1.0, 0.9565217391304348]</td>\n",
              "      <td>9.369023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49</td>\n",
              "      <td>0.154609</td>\n",
              "      <td>0.111148</td>\n",
              "      <td>575</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.919355</td>\n",
              "      <td>[0.85, 0.9375, 0.9615384615384616]</td>\n",
              "      <td>[0.9318181818181818, 0.9787234042553191, 0.969...</td>\n",
              "      <td>[0.9444444444444444, 1.0, 0.8620689655172413]</td>\n",
              "      <td>9.355145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49</td>\n",
              "      <td>0.288013</td>\n",
              "      <td>0.229149</td>\n",
              "      <td>460</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.919355</td>\n",
              "      <td>[0.85, 0.9375, 0.9615384615384616]</td>\n",
              "      <td>[0.9318181818181818, 0.9787234042553191, 0.969...</td>\n",
              "      <td>[0.9444444444444444, 1.0, 0.8620689655172413]</td>\n",
              "      <td>9.355145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49</td>\n",
              "      <td>0.175154</td>\n",
              "      <td>0.175154</td>\n",
              "      <td>460</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0</td>\n",
              "      <td>0.919355</td>\n",
              "      <td>[0.9, 0.9375, 0.9230769230769231]</td>\n",
              "      <td>[0.9523809523809523, 0.9787234042553191, 0.942...</td>\n",
              "      <td>[0.9, 1.0, 0.8888888888888888]</td>\n",
              "      <td>9.342782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>0.059654</td>\n",
              "      <td>0.040690</td>\n",
              "      <td>575</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.903226</td>\n",
              "      <td>[0.85, 0.9375, 0.9230769230769231]</td>\n",
              "      <td>[0.9302325581395349, 0.9787234042553191, 0.941...</td>\n",
              "      <td>[0.8947368421052632, 1.0, 0.8571428571428571]</td>\n",
              "      <td>9.215815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49</td>\n",
              "      <td>0.424810</td>\n",
              "      <td>0.397997</td>\n",
              "      <td>345</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.903226</td>\n",
              "      <td>[0.85, 0.9375, 0.9230769230769231]</td>\n",
              "      <td>[0.9318181818181818, 0.9782608695652174, 0.941...</td>\n",
              "      <td>[0.9444444444444444, 0.9375, 0.8571428571428571]</td>\n",
              "      <td>9.204146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49</td>\n",
              "      <td>0.409795</td>\n",
              "      <td>0.361865</td>\n",
              "      <td>345</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0</td>\n",
              "      <td>0.903226</td>\n",
              "      <td>[0.85, 0.9375, 0.9230769230769231]</td>\n",
              "      <td>[0.9318181818181818, 0.9782608695652174, 0.941...</td>\n",
              "      <td>[0.9444444444444444, 0.9375, 0.8571428571428571]</td>\n",
              "      <td>9.204146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24</td>\n",
              "      <td>0.172472</td>\n",
              "      <td>0.026947</td>\n",
              "      <td>460</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0</td>\n",
              "      <td>0.887097</td>\n",
              "      <td>[0.95, 0.9375, 0.8076923076923077]</td>\n",
              "      <td>[0.9743589743589743, 0.9782608695652174, 0.871...</td>\n",
              "      <td>[0.8260869565217391, 0.9375, 0.9130434782608695]</td>\n",
              "      <td>9.083334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49</td>\n",
              "      <td>0.400627</td>\n",
              "      <td>0.400627</td>\n",
              "      <td>345</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.887097</td>\n",
              "      <td>[0.8, 0.9375, 0.9230769230769231]</td>\n",
              "      <td>[0.9111111111111111, 0.9782608695652174, 0.939...</td>\n",
              "      <td>[0.9411764705882353, 0.9375, 0.8275862068965517]</td>\n",
              "      <td>9.082702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26</td>\n",
              "      <td>0.089577</td>\n",
              "      <td>0.017151</td>\n",
              "      <td>575</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0</td>\n",
              "      <td>0.887097</td>\n",
              "      <td>[0.9, 0.875, 0.8846153846153846]</td>\n",
              "      <td>[0.95, 0.9583333333333334, 0.9166666666666666]</td>\n",
              "      <td>[0.8181818181818182, 1.0, 0.8846153846153846]</td>\n",
              "      <td>9.074509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49</td>\n",
              "      <td>0.098461</td>\n",
              "      <td>0.098461</td>\n",
              "      <td>575</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0</td>\n",
              "      <td>0.887097</td>\n",
              "      <td>[0.9, 0.9375, 0.8461538461538461]</td>\n",
              "      <td>[0.9512195121951219, 0.9782608695652174, 0.891...</td>\n",
              "      <td>[0.8571428571428571, 0.9375, 0.88]</td>\n",
              "      <td>9.066766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49</td>\n",
              "      <td>0.114225</td>\n",
              "      <td>0.114225</td>\n",
              "      <td>575</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.887097</td>\n",
              "      <td>[0.85, 0.9375, 0.8846153846153846]</td>\n",
              "      <td>[0.9302325581395349, 0.9782608695652174, 0.914...</td>\n",
              "      <td>[0.8947368421052632, 0.9375, 0.8518518518518519]</td>\n",
              "      <td>9.066080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49</td>\n",
              "      <td>0.197302</td>\n",
              "      <td>0.197302</td>\n",
              "      <td>460</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.870968</td>\n",
              "      <td>[0.85, 0.9375, 0.8461538461538461]</td>\n",
              "      <td>[0.9285714285714286, 0.9782608695652174, 0.888...</td>\n",
              "      <td>[0.85, 0.9375, 0.8461538461538461]</td>\n",
              "      <td>8.933997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31</td>\n",
              "      <td>0.127186</td>\n",
              "      <td>0.029265</td>\n",
              "      <td>575</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.854839</td>\n",
              "      <td>[0.8, 0.9375, 0.8461538461538461]</td>\n",
              "      <td>[0.9047619047619048, 0.9782608695652174, 0.888...</td>\n",
              "      <td>[0.8, 0.9375, 0.8461538461538461]</td>\n",
              "      <td>8.794058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>0.125465</td>\n",
              "      <td>0.071760</td>\n",
              "      <td>460</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.838710</td>\n",
              "      <td>[0.85, 0.875, 0.8076923076923077]</td>\n",
              "      <td>[0.925, 0.9574468085106383, 0.8648648648648649]</td>\n",
              "      <td>[0.7727272727272727, 0.9333333333333333, 0.84]</td>\n",
              "      <td>8.664774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27</td>\n",
              "      <td>0.978319</td>\n",
              "      <td>0.871926</td>\n",
              "      <td>345</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0</td>\n",
              "      <td>0.596774</td>\n",
              "      <td>[0.95, 0.5, 0.38461538461538464]</td>\n",
              "      <td>[0.9523809523809523, 0.8518518518518519, 0.673...</td>\n",
              "      <td>[0.4634146341463415, 1.0, 0.7692307692307693]</td>\n",
              "      <td>7.141737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15</td>\n",
              "      <td>1.091213</td>\n",
              "      <td>0.979451</td>\n",
              "      <td>460</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0</td>\n",
              "      <td>0.548387</td>\n",
              "      <td>[0.1, 0.4375, 0.9615384615384616]</td>\n",
              "      <td>[0.7, 0.8333333333333334, 0.9]</td>\n",
              "      <td>[1.0, 0.875, 0.4807692307692308]</td>\n",
              "      <td>6.836528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>0.977758</td>\n",
              "      <td>0.977589</td>\n",
              "      <td>345</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.548387</td>\n",
              "      <td>[0.35, 0.125, 0.9615384615384616]</td>\n",
              "      <td>[0.7592592592592593, 0.7666666666666667, 0.9]</td>\n",
              "      <td>[0.875, 1.0, 0.4807692307692308]</td>\n",
              "      <td>6.766621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14</td>\n",
              "      <td>0.950245</td>\n",
              "      <td>0.900957</td>\n",
              "      <td>345</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.612903</td>\n",
              "      <td>[0.35, 0.8125, 0.6923076923076923]</td>\n",
              "      <td>[0.7291666666666666, 0.9318181818181818, 0.75]</td>\n",
              "      <td>[0.5, 0.7222222222222222, 0.6]</td>\n",
              "      <td>6.700918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15</td>\n",
              "      <td>0.984137</td>\n",
              "      <td>0.913991</td>\n",
              "      <td>460</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.564516</td>\n",
              "      <td>[0.35, 0.3125, 0.8846153846153846]</td>\n",
              "      <td>[0.7547169811320755, 0.8035714285714286, 0.8]</td>\n",
              "      <td>[0.7777777777777778, 0.8333333333333334, 0.489...</td>\n",
              "      <td>6.570393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>1.050557</td>\n",
              "      <td>1.009866</td>\n",
              "      <td>460</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.532258</td>\n",
              "      <td>[0.15, 0.375, 0.9230769230769231]</td>\n",
              "      <td>[0.7017543859649122, 0.8181818181818182, 0.833...</td>\n",
              "      <td>[0.6, 0.8571428571428571, 0.48]</td>\n",
              "      <td>6.270747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17</td>\n",
              "      <td>1.073808</td>\n",
              "      <td>1.035658</td>\n",
              "      <td>575</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0</td>\n",
              "      <td>0.403226</td>\n",
              "      <td>[0.15, 0.0, 0.8461538461538461]</td>\n",
              "      <td>[0.6909090909090909, 0.7419354838709677, 0.428...</td>\n",
              "      <td>[0.42857142857142855, nan, 0.4]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>1.038244</td>\n",
              "      <td>1.023963</td>\n",
              "      <td>575</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.467742</td>\n",
              "      <td>[0.0, 0.25, 0.9615384615384616]</td>\n",
              "      <td>[0.6774193548387096, 0.7894736842105263, 0.8]</td>\n",
              "      <td>[nan, 0.8, 0.43859649122807015]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13</td>\n",
              "      <td>1.109291</td>\n",
              "      <td>1.047121</td>\n",
              "      <td>575</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.451613</td>\n",
              "      <td>[0.0, 0.125, 1.0]</td>\n",
              "      <td>[0.6774193548387096, 0.7666666666666667, 1.0]</td>\n",
              "      <td>[nan, 1.0, 0.43333333333333335]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-997a3db2-0bcf-4eb8-84e8-5d2c6148ebd4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-997a3db2-0bcf-4eb8-84e8-5d2c6148ebd4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-997a3db2-0bcf-4eb8-84e8-5d2c6148ebd4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e64f1c0b-a2ae-42cf-9894-5d4f53107c29\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e64f1c0b-a2ae-42cf-9894-5d4f53107c29')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e64f1c0b-a2ae-42cf-9894-5d4f53107c29 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "#calculate a score from accuracy, sensitivity and specificity wher sensitivity and specificity are a list of 3 values\n",
        "results['score'] = results['accuracy'] + results['sensitivity'].apply(lambda x: sum(x)) + results['specificity'].apply(lambda x: sum(x)) + results['precision'].apply(lambda x: sum(x))\n",
        "#sort by score\n",
        "results = results.sort_values(by=['score'], ascending=False)\n",
        "results"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}